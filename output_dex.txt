
æ–‡ä»¶è·¯å¾„: cmd/main.go
æ–‡ä»¶å†…å®¹:
package main

import (...)

// è¡¨ç¤ºä¸€ä¸ªèŠ‚ç‚¹å®ä¾‹
type NodeInstance struct {
	ID               int
	PrivateKey       string
	Address          string
	Port             string
	DataPath         string
	Server           *http.Server
	ConsensusManager *consensus.ConsensusNodeManager
	DBManager        *db.Manager
	Cancel           context.CancelFunc
	TxPool           *txpool.TxPool
	SenderManager    *sender.SenderManager
	HandlerManager   *handlers.HandlerManager // æ–°å¢
}

// TestValidator ç®€å•çš„äº¤æ˜“éªŒè¯å™¨
type TestValidator struct{}

// åœ¨ cmd/main.go æ–‡ä»¶çš„importåé¢ï¼ŒNodeInstanceç»“æ„ä½“å‰é¢æ·»åŠ ï¼š

// æ¥å£è°ƒç”¨ç»Ÿè®¡ç»“æ„ä½“
type APICallStats struct {
	sync.RWMutex
	// è®°å½•æ¯ä¸ªæ¥å£çš„ç´¯è®¡è°ƒç”¨æ¬¡æ•°
	CallCounts map[string]uint64
	// è®°å½•æ¯ä¸ªèŠ‚ç‚¹æ¯ä¸ªæ¥å£çš„è°ƒç”¨æ¬¡æ•°
	NodeCallCounts map[int]map[string]uint64
}

// å…¨å±€æ¥å£è°ƒç”¨ç»Ÿè®¡
var globalAPIStats = &APICallStats{
	CallCounts:     make(map[string]uint64),
	NodeCallCounts: make(map[int]map[string]uint64),
}

func monitorMetrics(nodes []*NodeInstance) {
	ticker := time.NewTicker(20 * time.Second)
	defer ticker.Stop()

	// ç”¨äºè®°å½•æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ¬¡çš„è°ƒç”¨æ¬¡æ•°ï¼Œè®¡ç®—å¢é‡
	lastCallCounts := make(map[int]map[string]uint64)

	for range ticker.C {
		// ä¸´æ—¶å­˜å‚¨å½“å‰å‘¨æœŸçš„ç»Ÿè®¡æ•°æ®
		currentStats := make(map[string]uint64)
		nodeStats := make(map[int]map[string]uint64)

		for _, node := range nodes {
			if node == nil || node.SenderManager == nil {
				continue
			}

			// 1. å‘é€é˜Ÿåˆ—é•¿åº¦
			sendQueueLen := len(node.SenderManager.SendQueue.TaskChan)

			// 2. æ¯ç›®æ ‡åœ¨é€”è¯·æ±‚
			node.SenderManager.SendQueue.InflightMutex.RLock()
			inflightCopy := make(map[string]int32)
			totalInflight := int32(0)
			for k, v := range node.SenderManager.SendQueue.InflightMap {
				inflightCopy[k] = v
				totalInflight += v
			}
			node.SenderManager.SendQueue.InflightMutex.RUnlock()

			// 3. æ¥æ”¶é˜Ÿåˆ—é•¿åº¦
			recvQueueLen := 0
			if node.ConsensusManager != nil && node.ConsensusManager.Transport != nil {
				// æ ¹æ®ä½ çš„å®é™…Transportç±»å‹è°ƒæ•´
				// if rt, ok := node.ConsensusManager.Transport.(*consensus.ReliableTransport); ok {
				//     recvQueueLen = rt.GetRecvQueueLength()
				// }
			}

			// 4. æ¥å£è°ƒç”¨ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
			if node.HandlerManager != nil {
				apiStats := node.HandlerManager.Stats.GetAPICallStats()

				// è®°å½•å½“å‰èŠ‚ç‚¹çš„APIè°ƒç”¨ç»Ÿè®¡
				nodeStats[node.ID] = apiStats

				// è®¡ç®—å¢é‡å¹¶æ›´æ–°å…¨å±€ç»Ÿè®¡
				if lastCallCounts[node.ID] == nil {
					lastCallCounts[node.ID] = make(map[string]uint64)
				}

				for apiName, currentCount := range apiStats {
					// è®¡ç®—è¿™ä¸ªå‘¨æœŸçš„å¢é‡
					delta := currentCount
					if lastCount, exists := lastCallCounts[node.ID][apiName]; exists {
						delta = currentCount - lastCount
					}

					// æ›´æ–°å…¨å±€ç»Ÿè®¡
					currentStats[apiName] += delta

					// æ›´æ–°ä¸Šæ¬¡è®°å½•
					lastCallCounts[node.ID][apiName] = currentCount
				}
			}

			// æ‰“å°èŠ‚ç‚¹æŒ‡æ ‡
			if sendQueueLen > 0 || totalInflight > 0 || recvQueueLen > 0 {
				fmt.Printf("[Metrics] Node %d: SendQ=%d, Inflight=%d, RecvQ=%d\n",
					node.ID, sendQueueLen, totalInflight, recvQueueLen)
			}
		}

		// æ›´æ–°å…¨å±€APIè°ƒç”¨ç»Ÿè®¡
		globalAPIStats.Lock()
		for apiName, delta := range currentStats {
			globalAPIStats.CallCounts[apiName] += delta
		}
		for nodeID, apis := range nodeStats {
			globalAPIStats.NodeCallCounts[nodeID] = apis
		}
		globalAPIStats.Unlock()

		printAPICallStatistics()
	}
}

// æ‰“å°APIè°ƒç”¨ç»Ÿè®¡
func printAPICallStatistics() {
	globalAPIStats.RLock()
	defer globalAPIStats.RUnlock()

	if len(globalAPIStats.CallCounts) == 0 {
		return
	}

	fmt.Println("\n========== API Call Statistics ==========")
	fmt.Println("Global API Call Counts:")

	// æŒ‰æ¥å£åç§°æ’åº
	var apiNames []string
	for apiName := range globalAPIStats.CallCounts {
		apiNames = append(apiNames, apiName)
	}
	sort.Strings(apiNames)

	// æ‰“å°å…¨å±€ç»Ÿè®¡
	totalCalls := uint64(0)
	for _, apiName := range apiNames {
		count := globalAPIStats.CallCounts[apiName]
		totalCalls += count
		fmt.Printf("  %-30s: %10d calls\n", apiName, count)
	}
	fmt.Printf("  %-30s: %10d calls\n", "TOTAL", totalCalls)

	// æ‰“å°æ¯ä¸ªèŠ‚ç‚¹çš„ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
	if len(globalAPIStats.NodeCallCounts) > 0 {
		//fmt.Println("\nPer-Node API Call Distribution:")

		// æŒ‰èŠ‚ç‚¹IDæ’åº
		var nodeIDs []int
		for nodeID := range globalAPIStats.NodeCallCounts {
			nodeIDs = append(nodeIDs, nodeID)
		}
		sort.Ints(nodeIDs)

		for _, nodeID := range nodeIDs {
			apis := globalAPIStats.NodeCallCounts[nodeID]
			if len(apis) == 0 {
				continue
			}

			nodeTotalCalls := uint64(0)
			//fmt.Printf("\n  Node %d:\n", nodeID)

			// æŒ‰æ¥å£åç§°æ’åº
			var nodeAPINames []string
			for apiName := range apis {
				nodeAPINames = append(nodeAPINames, apiName)
			}
			sort.Strings(nodeAPINames)

			for _, apiName := range nodeAPINames {
				count := apis[apiName]
				nodeTotalCalls += count
				//fmt.Printf("    %-28s: %8d\n", apiName, count)
			}
			//fmt.Printf("    %-28s: %8d\n", "Node Total", nodeTotalCalls)
		}
	}

	// æ‰“å°APIè°ƒç”¨é¢‘ç‡åˆ†æ
	fmt.Println("\nAPI Call Frequency Analysis:")
	if totalCalls > 0 {
		for _, apiName := range apiNames {
			count := globalAPIStats.CallCounts[apiName]
			percentage := float64(count) * 100.0 / float64(totalCalls)

			// åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¡å½¢å›¾
			barLength := int(percentage / 2)
			if barLength > 40 {
				barLength = 40
			}
			bar := strings.Repeat("â–ˆ", barLength)

			fmt.Printf("  %-25s: %6.2f%% %s\n", apiName, percentage, bar)
		}
	}

	fmt.Println("==========================================\n")
}
func (v *TestValidator) CheckAnyTx(tx *pb.AnyTx) error {
	if tx == nil {
		return fmt.Errorf("nil transaction")
	}
	base := tx.GetBase()
	if base == nil {
		return fmt.Errorf("missing base message")
	}
	if base.TxId == "" {
		return fmt.Errorf("empty tx id")
	}
	return nil
}
func main() {
	// åŠ è½½é…ç½®
	cfg := config.DefaultConfig()
	// é…ç½®å‚æ•°
	numNodes := cfg.Network.DefaultNumNodes
	basePort := cfg.Network.BasePort

	fmt.Printf("ğŸš€ Starting %d real consensus nodes...\n", numNodes)

	// ç”ŸæˆèŠ‚ç‚¹ç§é’¥
	privateKeys := generatePrivateKeys(numNodes)

	// åˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
	nodes := make([]*NodeInstance, numNodes)
	var wg sync.WaitGroup

	// ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåˆ›å»ºæ•°æ®åº“å’ŒåŸºç¡€è®¾æ–½ï¼‰
	fmt.Println("ğŸ“¦ Phase 1: Initializing all nodes...")
	for i := 0; i < numNodes; i++ {
		node := &NodeInstance{
			Address:    fmt.Sprintf("0x000%d", i),
			ID:         i,
			PrivateKey: privateKeys[i],
			Port:       fmt.Sprintf("%d", basePort+i),
			DataPath:   fmt.Sprintf("./data/data_node_%d", i),
		}

		// æ¸…ç†æ—§æ•°æ®
		os.RemoveAll(node.DataPath)

		// åˆå§‹åŒ–èŠ‚ç‚¹
		if err := initializeNode(node); err != nil {
			logs.Error("Failed to initialize node %d: %v", i, err)
			continue
		}

		nodes[i] = node
		fmt.Printf("  âœ” Node %d initialized (port %s)\n", i, node.Port)
	}

	// ç­‰å¾…ä¸€ä¸‹è®©æ‰€æœ‰æ•°æ®åº“å®Œæˆåˆå§‹åŒ–
	time.Sleep(2 * time.Second)

	// ç¬¬äºŒé˜¶æ®µï¼šæ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹åˆ°æ•°æ®åº“ï¼ˆè®©èŠ‚ç‚¹äº’ç›¸çŸ¥é“ï¼‰
	fmt.Println("ğŸ”— Phase 2: Registering all nodes...")
	registerAllNodes(nodes)

	// ç¬¬ä¸‰é˜¶æ®µï¼šå¯åŠ¨æ‰€æœ‰HTTPæœåŠ¡å™¨
	fmt.Println("ğŸŒ Phase 3: Starting HTTP servers...")

	// åˆ›å»ºä¸€ä¸ªchannelæ¥æ”¶é›†æœåŠ¡å™¨å¯åŠ¨å®Œæˆçš„ä¿¡å·
	serverReadyChan := make(chan int, numNodes)
	serverErrorChan := make(chan error, numNodes)

	for _, node := range nodes {
		if node == nil {
			continue
		}
		wg.Add(1)
		go func(n *NodeInstance) {
			defer wg.Done()

			// å¯åŠ¨HTTPæœåŠ¡å™¨å¹¶å‘é€å°±ç»ªä¿¡å·
			if err := startHTTPServerWithSignal(n, serverReadyChan, serverErrorChan); err != nil {
				serverErrorChan <- fmt.Errorf("node %d failed to start: %v", n.ID, err)
			}
		}(node)

		// ç¨å¾®é”™å¼€å¯åŠ¨æ—¶é—´ï¼Œé¿å…èµ„æºäº‰æŠ¢
		time.Sleep(50 * time.Millisecond)
	}

	// ç­‰å¾…æ‰€æœ‰HTTPæœåŠ¡å™¨å¯åŠ¨å®Œæˆ
	fmt.Println("â³ Waiting for all HTTP/3 servers to be ready...")
	readyCount := 0
	successfulNodes := 0

	// è®¾ç½®è¶…æ—¶æ—¶é—´
	timeout := time.After(30 * time.Second)

	for readyCount < len(nodes) {
		select {
		case nodeID := <-serverReadyChan:
			successfulNodes++
			fmt.Printf("  âœ… Node %d HTTP/3 server is ready (%d/%d)\n",
				nodeID, successfulNodes, len(nodes))

		case err := <-serverErrorChan:
			fmt.Printf("  âŒ Error: %v\n", err)

		case <-timeout:
			fmt.Printf("  âš ï¸ Timeout waiting for servers. %d/%d started successfully\n",
				successfulNodes, len(nodes))
			goto ContinueWithConsensus
		}

		readyCount++
	}

	fmt.Printf("âœ… All %d HTTP/3 servers are ready!\n", successfulNodes)

ContinueWithConsensus:
	// é¢å¤–ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æœåŠ¡å™¨å®Œå…¨ç¨³å®š
	time.Sleep(1 * time.Second)
	// æ–°å¢ï¼šç¬¬3.5é˜¶æ®µ - å¯åŠ¨å…±è¯†å¼•æ“
	fmt.Println("ğŸ”§ Phase 3.5: Starting consensus engines...")
	for _, node := range nodes {
		if node != nil && node.ConsensusManager != nil {
			node.ConsensusManager.Start()
			fmt.Printf("  âœ“ Node %d consensus engine started\n", node.ID)
		}
	}
	// Create initial transactions
	fmt.Println("ğŸ“ Creating initial transactions...")
	for _, node := range nodes {
		if node != nil && node.ConsensusManager != nil {
			generateTransactions(node)
		}
	}
	time.Sleep(2 * time.Second)

	// ç¬¬å››é˜¶æ®µï¼šå¯åŠ¨å…±è¯†
	fmt.Println("ğŸ¯ Phase 4: Starting consensus engines...")
	for _, node := range nodes {
		if node != nil && node.ConsensusManager != nil {
			// è§¦å‘åˆå§‹æŸ¥è¯¢
			go func(n *NodeInstance) {
				time.Sleep(time.Duration(n.ID*100) * time.Millisecond) // é”™å¼€å¯åŠ¨
				n.ConsensusManager.StartQuery()
			}(node)
		}
	}
	// å¯åŠ¨æŒ‡æ ‡ç›‘æ§
	go monitorMetrics(nodes)
	// ç›‘æ§è¿›åº¦
	go monitorProgress(nodes)

	// ç­‰å¾…ä¿¡å·é€€å‡º
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

	fmt.Println("\nâœ… All nodes started! Press Ctrl+C to stop...")
	fmt.Println("ğŸ“Š Monitoring consensus progress...")

	<-sigChan

	// ä¼˜é›…å…³é—­
	fmt.Println("\nğŸ›‘ Shutting down all nodes...")
	shutdownAllNodes(nodes)

	wg.Wait()
	fmt.Println("ğŸ‘‹ All nodes stopped. Goodbye!")
}

// æ–°å¢ï¼šå¸¦ä¿¡å·çš„HTTPæœåŠ¡å™¨å¯åŠ¨å‡½æ•°
func startHTTPServerWithSignal(node *NodeInstance, readyChan chan<- int, errorChan chan<- error) error {
	// åˆ›å»ºHTTPè·¯ç”±
	mux := http.NewServeMux()

	// ä½¿ç”¨HandlerManageræ³¨å†Œè·¯ç”±
	node.HandlerManager.RegisterRoutes(mux)

	// åº”ç”¨ä¸­é—´ä»¶
	handler := middleware.RateLimit(mux)

	// ç”Ÿæˆè‡ªç­¾åè¯ä¹¦
	certFile := fmt.Sprintf("server_%d.crt", node.ID)
	keyFile := fmt.Sprintf("server_%d.key", node.ID)

	if err := generateSelfSignedCert(certFile, keyFile); err != nil {
		errorChan <- fmt.Errorf("Node %d: Failed to generate certificate: %v", node.ID, err)
		return err
	}

	// åˆ›å»ºTLSé…ç½®
	tlsConfig := &tls.Config{
		Certificates: []tls.Certificate{},
		MinVersion:   tls.VersionTLS13,
		MaxVersion:   tls.VersionTLS13,
		// æ·»åŠ ALPNåè®®æ”¯æŒ - è¿™æ˜¯å…³é”®ä¿®å¤
		NextProtos: []string{"h3", "h3-29", "h3-28", "h3-27"}, // HTTP/3åè®®æ ‡è¯†ç¬¦
	}

	cert, err := tls.LoadX509KeyPair(certFile, keyFile)
	if err != nil {
		errorChan <- fmt.Errorf("Node %d: Failed to load certificate: %v", node.ID, err)
		return err
	}
	tlsConfig.Certificates = append(tlsConfig.Certificates, cert)

	// åˆ›å»ºQUICé…ç½®
	quicConfig := &quic.Config{
		KeepAlivePeriod: 10 * time.Second,
		MaxIdleTimeout:  5 * time.Minute,
		Allow0RTT:       true,
	}

	// åˆ›å»ºHTTP/3æœåŠ¡å™¨
	server := &http3.Server{
		Addr:       ":" + node.Port,
		Handler:    handler,
		TLSConfig:  tlsConfig,
		QUICConfig: quicConfig,
	}

	node.Server = &http.Server{
		Addr:    ":" + node.Port,
		Handler: handler,
	}

	// åˆ›å»ºQUICç›‘å¬å™¨
	listener, err := quic.ListenAddr(":"+node.Port, tlsConfig, quicConfig)
	if err != nil {
		errorChan <- fmt.Errorf("Node %d: Failed to create QUIC listener: %v", node.ID, err)
		return err
	}

	logs.Info("Node %d: Starting HTTP/3 server on port %s", node.ID, node.Port)

	// æœåŠ¡å™¨æˆåŠŸåˆ›å»ºç›‘å¬å™¨ï¼Œå‘é€å°±ç»ªä¿¡å·
	readyChan <- node.ID

	// å¯åŠ¨æœåŠ¡å™¨ï¼ˆè¿™æ˜¯é˜»å¡è°ƒç”¨ï¼‰
	if err := server.ServeListener(listener); err != nil {
		logs.Error("Node %d: HTTP/3 Server error: %v", node.ID, err)
		return err
	}

	return nil
}

// generatePrivateKeys ç”ŸæˆæŒ‡å®šæ•°é‡çš„ç§é’¥
func generatePrivateKeys(count int) []string {
	keys := make([]string, count)
	for i := 0; i < count; i++ {
		priv, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)
		if err != nil {
			logs.Error("Failed to generate key %d: %v", i, err)
			continue
		}

		// è½¬æ¢ä¸ºhexæ ¼å¼
		privBytes := priv.D.Bytes()
		keys[i] = hex.EncodeToString(privBytes)
	}
	return keys
}

// åˆå§‹åŒ–å•ä¸ªèŠ‚ç‚¹
func initializeNode(node *NodeInstance) error {
	// 1. åˆå§‹åŒ–å¯†é’¥ç®¡ç†å™¨
	keyMgr := utils.GetKeyManager()
	if err := keyMgr.InitKey(node.PrivateKey); err != nil {
		return fmt.Errorf("failed to init key: %v", err)
	}
	node.Address = keyMgr.GetAddress()

	// 2. è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæŸäº›æ¨¡å—å¯èƒ½éœ€è¦ï¼‰
	utils.Port = node.Port

	// 3. åˆå§‹åŒ–æ•°æ®åº“
	dbManager, err := db.NewManager(node.DataPath)
	if err != nil {
		return fmt.Errorf("failed to init db: %v", err)
	}
	node.DBManager = dbManager

	// åˆå§‹åŒ–æ•°æ®åº“å†™é˜Ÿåˆ—
	dbManager.InitWriteQueue(100, 200*time.Millisecond)

	// 4. åˆ›å»ºéªŒè¯å™¨
	validator := &TestValidator{}

	// 5. åˆ›å»ºå¹¶å¯åŠ¨TxPoolï¼ˆä¸å†ä½¿ç”¨å•ä¾‹ï¼‰
	txPool, err := txpool.NewTxPool(dbManager, validator)
	if err != nil {
		return fmt.Errorf("failed to create TxPool: %v", err)
	}
	if err := txPool.Start(); err != nil {
		return fmt.Errorf("failed to start TxPool: %v", err)
	}
	node.TxPool = txPool

	// 6. åˆ›å»ºå‘é€ç®¡ç†å™¨
	senderManager := sender.NewSenderManager(dbManager, node.Address, txPool, node.ID)
	node.SenderManager = senderManager

	// 7. åˆå§‹åŒ–å…±è¯†ç³»ç»Ÿ
	nodeID := types.NodeID(node.Address)
	config := consensus.DefaultConfig()

	// è°ƒæ•´é…ç½®
	config.Network.NumNodes = 100
	config.Network.NumByzantineNodes = 0
	config.Consensus.NumHeights = 10     // è¿è¡Œ10ä¸ªé«˜åº¦
	config.Consensus.BlocksPerHeight = 3 // æ¯ä¸ªé«˜åº¦3ä¸ªå€™é€‰å—
	config.Consensus.K = 10              // é‡‡æ ·10ä¸ªèŠ‚ç‚¹
	config.Consensus.Alpha = 7           // éœ€è¦7ä¸ªå›åº”
	config.Consensus.Beta = 5            // 5æ¬¡è¿ç»­æŠ•ç¥¨ç¡®è®¤
	config.Node.ProposalInterval = 5 * time.Second

	// åˆ›å»ºå…±è¯†ç®¡ç†å™¨
	consensusManager := consensus.InitConsensusManager(
		nodeID,
		dbManager,
		config,
		senderManager,
		txPool,
	)
	node.ConsensusManager = consensusManager

	// 8. åˆ›å»ºHandlerç®¡ç†å™¨
	handlerManager := handlers.NewHandlerManager(
		dbManager,
		consensusManager,
		node.Port,
		node.Address,
		senderManager,
		txPool,
	)
	node.HandlerManager = handlerManager

	// ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯åˆ°æ•°æ®åº“
	nodeInfo := &pb.NodeInfo{
		PublicKey: keyMgr.GetPublicKey(),
		Ip:        fmt.Sprintf("127.0.0.1:%s", node.Port),
		IsOnline:  true,
	}

	if err := dbManager.SaveNodeInfo(nodeInfo); err != nil {
		return fmt.Errorf("failed to save node info: %v", err)
	}

	// åˆ›å»ºè´¦æˆ·
	account := &pb.Account{
		Address:   node.Address,
		PublicKey: keyMgr.GetPublicKey(),
		Ip:        fmt.Sprintf("127.0.0.1:%s", node.Port),
		Index:     uint64(node.ID),
		IsMiner:   true,
		Balances:  make(map[string]*pb.TokenBalance),
	}

	// åˆå§‹åŒ–FBä»£å¸ä½™é¢
	account.Balances["FB"] = &pb.TokenBalance{
		Balance:            "1000000",
		MinerLockedBalance: "100000",
	}

	if err := dbManager.SaveAccount(account); err != nil {
		return fmt.Errorf("failed to save account: %v", err)
	}
	// ä¿å­˜ç´¢å¼•æ˜ å°„
	indexKey := db.KeyIndexToAccount(account.Index)
	accountKey := db.KeyAccount(account.Address)
	dbManager.EnqueueSet(indexKey, accountKey)
	// Force flush to ensure miner registration is persisted
	dbManager.ForceFlush()
	return nil
}

// Option 2: Generate transactions continuously
func generateTransactions(node *NodeInstance) {
	go func() {
		ticker := time.NewTicker(200 * time.Millisecond)
		defer ticker.Stop()

		txID := 0
		for range ticker.C {
			// Generate multiple transactions
			for i := 0; i < 2; i++ {
				tx := &pb.Transaction{
					Base: &pb.BaseMessage{
						TxId:        fmt.Sprintf("%d%d", i, time.Now().UnixNano()),
						FromAddress: node.Address,
						Status:      pb.Status_PENDING,
						Nonce:       uint64(i),
					},
					To:           node.Address,
					TokenAddress: "FB",
					Amount:       "100",
				}
				anyTx := &pb.AnyTx{
					Content: &pb.AnyTx_Transaction{Transaction: tx},
				}
				// Add to transaction pool
				if err := node.TxPool.StoreAnyTx(anyTx); err == nil {
					logs.Trace("Added transaction %s to pool", tx.Base.TxId)
				}
			}
			txID++
		}
	}()
}

// æ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„æ•°æ®åº“
func registerAllNodes(nodes []*NodeInstance) {
	for i, node := range nodes {
		if node == nil || node.DBManager == nil {
			continue
		}

		// åœ¨å½“å‰èŠ‚ç‚¹çš„æ•°æ®åº“ä¸­æ³¨å†Œæ‰€æœ‰å…¶ä»–èŠ‚ç‚¹
		for j, otherNode := range nodes {
			if otherNode == nil || i == j {
				continue
			}

			// ä¿å­˜å…¶ä»–èŠ‚ç‚¹çš„è´¦æˆ·ä¿¡æ¯
			account := &pb.Account{
				Address:   otherNode.Address,
				PublicKey: utils.GetKeyManager().GetPublicKey(), // è¿™é‡Œç®€åŒ–å¤„ç†
				Ip:        fmt.Sprintf("127.0.0.1:%s", otherNode.Port),
				Index:     uint64(j),
				IsMiner:   true,
				Balances:  make(map[string]*pb.TokenBalance),
			}

			account.Balances["FB"] = &pb.TokenBalance{
				Balance:            "1000000",
				MinerLockedBalance: "100000",
			}

			node.DBManager.SaveAccount(account)

			// ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯
			nodeInfo := &pb.NodeInfo{
				PublicKey: fmt.Sprintf("node_%d_pub", j),
				Ip:        fmt.Sprintf("127.0.0.1:%s", otherNode.Port),
				IsOnline:  true,
			}
			node.DBManager.SaveNodeInfo(nodeInfo)
			// ä¿å­˜ç´¢å¼•æ˜ å°„
			indexKey := db.KeyIndexToAccount(uint64(j))
			accountKey := db.KeyAccount(otherNode.Address)
			node.DBManager.EnqueueSet(indexKey, accountKey)

		}
		// Force flush to ensure all registrations are persisted
		node.DBManager.ForceFlush()
		time.Sleep(100 * time.Millisecond) // ç¡®ä¿å†™å…¥å®Œæˆ

		// é‡æ–°æ‰«ææ•°æ®åº“é‡å»º bitmap
		if err := node.DBManager.IndexMgr.RebuildBitmapFromDB(); err != nil {
			logs.Error("Failed to rebuild bitmap: %v", err)
		}
	}
}

// ç”Ÿæˆè‡ªç­¾åè¯ä¹¦
func generateSelfSignedCert(certFile, keyFile string) error {
	priv, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)
	if err != nil {
		return err
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		DNSNames:     []string{"localhost"},
	}

	certDER, err := x509.CreateCertificate(
		rand.Reader,
		&template,
		&template,
		&priv.PublicKey,
		priv,
	)
	if err != nil {
		return err
	}

	// ä¿å­˜è¯ä¹¦
	certOut, err := os.Create(certFile)
	if err != nil {
		return err
	}
	defer certOut.Close()

	pem.Encode(certOut, &pem.Block{Type: "CERTIFICATE", Bytes: certDER})

	// ä¿å­˜ç§é’¥
	keyOut, err := os.Create(keyFile)
	if err != nil {
		return err
	}
	defer keyOut.Close()

	privBytes, err := x509.MarshalECPrivateKey(priv)
	if err != nil {
		return err
	}

	pem.Encode(keyOut, &pem.Block{Type: "EC PRIVATE KEY", Bytes: privBytes})

	return nil
}

// ç›‘æ§å…±è¯†è¿›åº¦
func monitorProgress(nodes []*NodeInstance) {
	ticker := time.NewTicker(20 * time.Second)
	defer ticker.Stop()

	for range ticker.C {
		fmt.Println("\n========== Progress Monitor ==========")
		fmt.Printf("Time: %s\n", time.Now().Format("15:04:05"))

		var minHeight, maxHeight uint64
		activeNodes := 0

		for _, node := range nodes {
			if node == nil || node.ConsensusManager == nil {
				continue
			}
			activeNodes++
			_, height := node.ConsensusManager.GetLastAccepted()
			if minHeight == 0 || height < minHeight {
				minHeight = height
			}
			if height > maxHeight {
				maxHeight = height
			}
		}

		fmt.Printf("\nğŸ“ˆ Progress: Active=%d, MinHeight=%d, MaxHeight=%d\n",
			activeNodes, minHeight, maxHeight)

		// æ‰“å°æ¯ä¸ªèŠ‚ç‚¹çš„å®Œæ•´ç»Ÿè®¡ä¿¡æ¯
		fmt.Println("\nNode Statistics:")
		for i, node := range nodes {
			if node == nil || node.ConsensusManager == nil {
				fmt.Printf("Node %d: inactive\n", i)
				continue
			}

			stats := node.ConsensusManager.GetStats()
			if stats == nil {
				fmt.Printf("Node %d: no stats\n", i)
				continue
			}

			lastAccepted, height := node.ConsensusManager.GetLastAccepted()

			// è·å–æ‰€æœ‰ç»Ÿè®¡æ•°æ®
			stats.Mu.Lock()
			fmt.Printf("\nNode %d:\n", i)
			fmt.Printf("  Last Accepted: %s (height=%d)\n", lastAccepted, height)
			fmt.Printf("  Queries Sent: %d\n", stats.QueriesSent)
			fmt.Printf("  Queries Received: %d\n", stats.QueriesReceived)
			fmt.Printf("  Chits Responded: %d\n", stats.ChitsResponded)
			fmt.Printf("  Blocks Proposed: %d\n", stats.BlocksProposed)
			fmt.Printf("  Gossips Received: %d\n", stats.GossipsReceived)
			fmt.Printf("  Snapshots Used: %d\n", stats.SnapshotsUsed)
			fmt.Printf("  Snapshots Served: %d\n", stats.SnapshotsServed)
			fmt.Printf("  GetPreferenceSwitchHistory: %+v\n", stats.GetPreferenceSwitchHistory())
			fmt.Printf("  Consensus API handler: %+v\n", node.HandlerManager.Stats.GetAPICallStats())
			rt, ok := node.ConsensusManager.Transport.(*consensus.RealTransport) // å®‰å…¨æ–­è¨€
			if !ok {
				return
			}
			if rt == nil {
				return
			}
			fmt.Printf("  Consensus API send: %+v\n", rt.Stats.GetAPICallStats())
			// æ˜¾ç¤ºæ¯ä¸ªé«˜åº¦çš„æŸ¥è¯¢æ•°
			if len(stats.QueriesPerHeight) > 0 {
				fmt.Printf("  Queries Per Height:\n")
				for h, count := range stats.QueriesPerHeight {
					fmt.Printf("    Height %d: %d\n", h, count)
				}
			}
			stats.Mu.Unlock()
		}

		fmt.Println()
	}
}

// å…³é—­æ‰€æœ‰èŠ‚ç‚¹
func shutdownAllNodes(nodes []*NodeInstance) {
	var wg sync.WaitGroup

	for _, node := range nodes {
		if node == nil {
			continue
		}

		wg.Add(1)
		go func(n *NodeInstance) {
			defer wg.Done()

			// åœæ­¢å…±è¯†
			if n.ConsensusManager != nil {
				n.ConsensusManager.Stop()
			}

			// åœæ­¢Handlerç®¡ç†å™¨ï¼ˆæ–°å¢ï¼‰
			if n.HandlerManager != nil {
				n.HandlerManager.Stop()
			}

			// åœæ­¢Senderç®¡ç†å™¨
			if n.SenderManager != nil {
				n.SenderManager.Stop()
			}

			// åœæ­¢TxPool
			if n.TxPool != nil {
				n.TxPool.Stop()
			}

			// åœæ­¢HTTPæœåŠ¡å™¨
			if n.Server != nil {
				ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
				defer cancel()
				n.Server.Shutdown(ctx)
			}

			// å…³é—­æ•°æ®åº“
			if n.DBManager != nil {
				n.DBManager.Close()
			}

			fmt.Printf("  âœ“ Node %d stopped\n", n.ID)
		}(node)
	}

	wg.Wait()
}


æ–‡ä»¶è·¯å¾„: cmd/tes.go
æ–‡ä»¶å†…å®¹:
package main

//func main() {
//	consensus.RunLoop()
//dbMgr, err := db.NewManager("data/data_node_0")
//if err != nil {
//	logs.Error("CheckAuth GetInstance err : %v", err)
//
//}
//maxBytes := dbMgr.Db.MaxBatchSize()
//maxCount := dbMgr.Db.MaxBatchCount()
//fmt.Println("maxBytes:", maxBytes)
//fmt.Println("maxCount:", maxCount)
//}


æ–‡ä»¶è·¯å¾„: config/config.go
æ–‡ä»¶å†…å®¹:
// config/config.go
package config

import (...)

// Config ä¸»é…ç½®ç»“æ„
type Config struct {
	Server   ServerConfig
	Database DatabaseConfig
	Network  NetworkConfig
	TxPool   TxPoolConfig
	Sender   SenderConfig
	Auth     AuthConfig
}

// ServerConfig HTTP/3æœåŠ¡å™¨é…ç½®
type ServerConfig struct {
	// TLSé…ç½®
	TLSMinVersion string // "1.3"
	TLSMaxVersion string // "1.3"

	// QUICé…ç½®
	QUICKeepAlivePeriod time.Duration // 10 * time.Second
	QUICMaxIdleTimeout  time.Duration // 5 * time.Minute
	QUICAllow0RTT       bool          // true

	// HTTPé…ç½®
	HTTPTimeout        time.Duration // 30 * time.Second
	MaxRequestBodySize int64         // 10 << 20 (10MB)

	// è¯ä¹¦é…ç½®
	CertValidityDays    int // 365
	TLSSessionCacheSize int // 128
}

// DatabaseConfig æ•°æ®åº“é…ç½®
type DatabaseConfig struct {
	// BadgerDBé…ç½®
	ValueLogFileSize int64         // 64 << 20 (64MB)
	MaxBatchSize     int           // 100
	FlushInterval    time.Duration // 200 * time.Millisecond

	// å†™é˜Ÿåˆ—é…ç½®
	WriteQueueSize      int   // 100000
	WriteBatchSoftLimit int64 // 8 * 1024 * 1024 (8MB)
	MaxCountPerTxn      int   // 500
	PerEntryOverhead    int   // 32

	// ç¼“å­˜é…ç½®
	BlockCacheSize    int    // 10
	SequenceBandwidth uint64 // 1000
}

// NetworkConfig ç½‘ç»œé…ç½®
type NetworkConfig struct {
	// åŸºç¡€ç½‘ç»œé…ç½®
	BasePort        int // 6000
	MaxNodes        int // 100
	DefaultNumNodes int // 100
	ByzantineNodes  int // 0

	// è¿æ¥æ± é…ç½®
	PeerSampleSize     int // 10
	RandomMinerCount   int // 3
	BroadcastPeerCount int // 5
	MaxBroadcastPeers  int // 20

	// è¶…æ—¶é…ç½®
	NetworkLatency    time.Duration // 100 * time.Millisecond
	ConnectionTimeout time.Duration // 5 * time.Second
	HandshakeTimeout  time.Duration // 10 * time.Second
}

// TxPoolConfig äº¤æ˜“æ± é…ç½®
type TxPoolConfig struct {
	// ç¼“å­˜å¤§å°
	PendingTxCacheSize      int // 100000
	ShortPendingTxCacheSize int // 100000
	CacheTxSize             int // 100000
	ShortTxCacheSize        int // 100000

	// é˜Ÿåˆ—é…ç½®
	MessageQueueSize int // 10000
	MaxPendingTxs    int // 10000

	// äº¤æ˜“å¤„ç†
	MaxTxsPerBlock    int // 2500
	TxPerMerkleTree   int // 1000
	ShortHashSize     int // 8
	MinTxsForProposal int // 1

	// æ—¶é—´é…ç½®
	TxExpirationTime time.Duration // 24 * time.Hour
}

// SenderConfig å‘é€å™¨é…ç½®
type SenderConfig struct {
	// é˜Ÿåˆ—é…ç½®
	WorkerCount   int // 100
	QueueCapacity int // 10000

	// é‡è¯•é…ç½®
	DefaultMaxRetries int // 3
	ControlMaxRetries int // 2
	DataMaxRetries    int // 1

	// è¶…æ—¶é…ç½®
	BaseRetryDelay      time.Duration // 1 * time.Second
	MaxRetryDelay       time.Duration // 30 * time.Second
	ControlTaskTimeout  time.Duration // 80 * time.Millisecond
	DataTaskDropTimeout time.Duration // 0 (ç«‹å³ä¸¢å¼ƒ)

}

// AuthConfig è®¤è¯é…ç½®
type AuthConfig struct {
	AuthEnabled     bool   // false
	ServerChallenge string // "server_challenge_123456"
}

// MinerConfig çŸ¿å·¥ç›¸å…³é…ç½®
type MinerConfig struct {
	// ç´¢å¼•ç®¡ç†
	MaxMinerIndex  uint64 // å¯é…ç½®çš„æœ€å¤§çŸ¿å·¥ç´¢å¼•
	IndexCacheSize int    // ç´¢å¼•ç¼“å­˜å¤§å°

	// Stakeé…ç½®
	MaxStake            string // "1e30"
	StakeIndexPadLength int    // 32

	// BLSç­¾åç¼“å­˜
	BLSSignCacheSize int // 100
}

// DefaultConfig è¿”å›é»˜è®¤é…ç½®
func DefaultConfig() *Config {
	return &Config{
		Server: ServerConfig{
			TLSMinVersion:       "1.3",
			TLSMaxVersion:       "1.3",
			QUICKeepAlivePeriod: 10 * time.Second,
			QUICMaxIdleTimeout:  5 * time.Minute,
			QUICAllow0RTT:       true,
			HTTPTimeout:         30 * time.Second,
			MaxRequestBodySize:  10 << 20,
			CertValidityDays:    365,
			TLSSessionCacheSize: 128,
		},
		Database: DatabaseConfig{
			ValueLogFileSize:    64 << 20,
			MaxBatchSize:        100,
			FlushInterval:       200 * time.Millisecond,
			WriteQueueSize:      100000,
			WriteBatchSoftLimit: 8 * 1024 * 1024,
			MaxCountPerTxn:      500,
			PerEntryOverhead:    32,
			BlockCacheSize:      10,
			SequenceBandwidth:   1000,
		},
		Network: NetworkConfig{
			BasePort:           6000,
			MaxNodes:           100,
			DefaultNumNodes:    20,
			ByzantineNodes:     0,
			PeerSampleSize:     10,
			RandomMinerCount:   3,
			BroadcastPeerCount: 5,
			MaxBroadcastPeers:  20,
			NetworkLatency:     100 * time.Millisecond,
			ConnectionTimeout:  5 * time.Second,
			HandshakeTimeout:   10 * time.Second,
		},
		TxPool: TxPoolConfig{
			PendingTxCacheSize:      100000,
			ShortPendingTxCacheSize: 100000,
			CacheTxSize:             100000,
			ShortTxCacheSize:        100000,
			MessageQueueSize:        10000,
			MaxPendingTxs:           10000,
			MaxTxsPerBlock:          2500,
			TxPerMerkleTree:         1000,
			ShortHashSize:           8,
			MinTxsForProposal:       1,
			TxExpirationTime:        24 * time.Hour,
		},
		Sender: SenderConfig{
			WorkerCount:         10000,
			QueueCapacity:       10000,
			DefaultMaxRetries:   3,
			ControlMaxRetries:   2,
			DataMaxRetries:      1,
			BaseRetryDelay:      1 * time.Second,
			MaxRetryDelay:       30 * time.Second,
			ControlTaskTimeout:  180 * time.Millisecond,
			DataTaskDropTimeout: 0,
		},
		Auth: AuthConfig{
			AuthEnabled:     false,
			ServerChallenge: "server_challenge_123456",
		},
	}
}

// LoadFromFile ä»æ–‡ä»¶åŠ è½½é…ç½®ï¼ˆå¯é€‰å®ç°ï¼‰
func LoadFromFile(path string) (*Config, error) {
	// å¯ä»¥å®ç°ä»JSON/YAMLæ–‡ä»¶åŠ è½½é…ç½®
	// è¿™é‡Œä»…è¿”å›é»˜è®¤é…ç½®ä½œä¸ºç¤ºä¾‹
	return DefaultConfig(), nil
}

// Validate éªŒè¯é…ç½®åˆæ³•æ€§
func (c *Config) Validate() error {
	// æ·»åŠ é…ç½®éªŒè¯é€»è¾‘
	if c.Network.MaxNodes <= 0 {
		return fmt.Errorf("MaxNodes must be positive")
	}
	if c.TxPool.MaxTxsPerBlock <= 0 {
		return fmt.Errorf("MaxTxsPerBlock must be positive")
	}
	// ... å…¶ä»–éªŒè¯
	return nil
}


æ–‡ä»¶è·¯å¾„: consensus/adapter.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// é›†ä¸­å¤„ç†å…±è¯†å±‚ä¸å¤–éƒ¨çš„æ‰€æœ‰æ•°æ®è½¬æ¢
type ConsensusAdapter struct {
	dbManager *db.Manager
}

func NewConsensusAdapter(dbMgr *db.Manager) *ConsensusAdapter {
	return &ConsensusAdapter{
		dbManager: dbMgr,
	}
}

// ============================================
// DBBlock -> Consensus Types è½¬æ¢
// ============================================

// DBBlockToConsensus å°†åŒºå—è½¬æ¢ä¸ºå…±è¯†åŒºå—ç±»å‹
func (a *ConsensusAdapter) DBBlockToConsensus(dbBlock *pb.Block) (*types.Block, error) {
	if dbBlock == nil {
		return nil, fmt.Errorf("nil db block")
	}
	return &types.Block{
		ID:       dbBlock.BlockHash,
		Height:   dbBlock.Height,
		ParentID: dbBlock.PrevBlockHash,
		Data:     fmt.Sprintf("TxCount: %d, TxsHash: %s", len(dbBlock.Body), dbBlock.TxsHash),
		Proposer: dbBlock.Miner, // ç›´æ¥å°±æ˜¯åœ°å€
		Round:    a.parseRoundFromBlockHash(dbBlock.BlockHash),
	}, nil
}

// ConsensusBlockToDB å°†å…±è¯†åŒºå—è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
func (a *ConsensusAdapter) ConsensusBlockToDB(block *types.Block, txs []*pb.AnyTx) *pb.Block {
	return &pb.Block{
		Height:        block.Height,
		BlockHash:     block.ID,
		PrevBlockHash: block.ParentID,
		Miner:         block.Proposer, // ç›´æ¥å­˜åœ°å€
		Body:          txs,
		TxsHash:       a.extractTxsHashFromData(block.Data),
	}
}

// ============================================
// Message è½¬æ¢
// ============================================

// å°†å…±è¯†æ¶ˆæ¯è½¬æ¢ä¸ºPushQuery
func (a *ConsensusAdapter) ConsensusMessageToPushQuery(msg types.Message, address string) (*pb.PushQuery, error) {
	container, isBlock := a.prepareContainer(msg)

	return &pb.PushQuery{
		Address:          address,
		Deadline:         a.calculateDeadline(3),
		ContainerIsBlock: isBlock,
		Container:        container,
		RequestedHeight:  msg.Height,
		BlockId:          msg.BlockID,
		RequestId:        msg.RequestID,
	}, nil
}

// PushQueryToConsensusMessage å°†PushQueryè½¬æ¢ä¸ºå…±è¯†æ¶ˆæ¯
func (a *ConsensusAdapter) PushQueryToConsensusMessage(pq *pb.PushQuery, from types.NodeID) (types.Message, error) {
	msg := types.Message{
		Type:      types.MsgPushQuery,
		From:      from,
		BlockID:   pq.BlockId,
		Height:    pq.RequestedHeight,
		RequestID: pq.RequestId,
	}

	if pq.ContainerIsBlock {
		var block pb.Block
		if err := proto.Unmarshal(pq.Container, &block); err != nil {
			return msg, err
		}
		consensusBlock, err := a.DBBlockToConsensus(&block)
		if err != nil {
			return msg, err
		}
		msg.Block = consensusBlock
	}

	return msg, nil
}

// DBChits -> ConsensusChits
func (a *ConsensusAdapter) ChitsToConsensusMessage(chits *pb.Chits, from types.NodeID) types.Message {
	return types.Message{
		Type:              types.MsgChits,
		From:              from,
		RequestID:         chits.RequestId,
		PreferredID:       chits.PreferredBlock,
		PreferredIDHeight: chits.PreferredBlockAtHeight,
		AcceptedID:        chits.AcceptedBlock,
		AcceptedHeight:    chits.AcceptedHeight,
	}
}

// å°†å…±è¯†æ¶ˆæ¯è½¬æ¢ä¸ºDBChits
func (a *ConsensusAdapter) ConsensusMessageToChits(msg types.Message) *pb.Chits {
	return &pb.Chits{
		RequestId:              msg.RequestID,
		PreferredBlock:         msg.PreferredID,
		AcceptedBlock:          msg.AcceptedID,
		PreferredBlockAtHeight: msg.PreferredIDHeight,
		AcceptedHeight:         msg.AcceptedHeight,
		Bitmap:                 a.generateBitmap(),
	}
}

// ============================================
// Transaction è½¬æ¢
// ============================================

// PrepareBlockContainer å‡†å¤‡åŒºå—å®¹å™¨æ•°æ®
func (a *ConsensusAdapter) PrepareBlockContainer(blockID string, height uint64) ([]byte, bool, error) {
	// é¦–å…ˆæ£€æŸ¥ç¼“å­˜
	cfg := config.DefaultConfig()
	if cachedBlock, exists := GetCachedBlock(blockID); exists {
		if len(cachedBlock.Body) < cfg.TxPool.MaxTxsPerBlock {
			data, err := proto.Marshal(cachedBlock)
			return data, true, err
		}
		return cachedBlock.ShortTxs, false, nil
	}

	// ä»æ•°æ®åº“è·å–
	block, err := a.dbManager.GetBlock(height)
	if err != nil {
		return nil, false, err
	}

	if block.BlockHash != blockID {
		return nil, false, fmt.Errorf("block ID mismatch")
	}

	if len(block.Body) < cfg.TxPool.MaxTxsPerBlock {
		data, err := proto.Marshal(block)
		return data, true, err
	}

	return block.ShortTxs, false, nil
}

// ProcessReceivedContainer å¤„ç†æ¥æ”¶åˆ°çš„å®¹å™¨æ•°æ®
func (a *ConsensusAdapter) ProcessReceivedContainer(container []byte, isBlock bool, height uint64, blockID string) (*pb.Block, error) {
	if isBlock {
		var block pb.Block
		if err := proto.Unmarshal(container, &block); err != nil {
			return nil, err
		}
		return &block, nil
	}

	// å¤„ç†çŸ­å“ˆå¸Œåˆ—è¡¨
	txs, err := a.resolveShorHashesToTxs(container)
	if err != nil {
		return nil, err
	}

	return &pb.Block{
		Height:    height,
		BlockHash: blockID,
		Body:      txs,
		ShortTxs:  container,
	}, nil
}

// ============================================
// è¾…åŠ©æ–¹æ³•
// ============================================

func (a *ConsensusAdapter) parseMinerToNodeID(miner string) types.NodeID {
	var nodeID int
	fmt.Sscanf(miner, db.KeyNode()+"%d", &nodeID)
	return types.NodeID(strconv.Itoa(nodeID))
}

func (a *ConsensusAdapter) parseRoundFromBlockHash(blockHash string) int {
	// ä» block-<height>-<node>-r<round>-<hash> æ ¼å¼è§£æ
	var height, node, round int
	fmt.Sscanf(blockHash, "block-%d-%d-r%d", &height, &node, &round)
	return round
}

func (a *ConsensusAdapter) extractTxsHashFromData(data string) string {
	// ä» Data å­—æ®µè§£æ TxsHash
	var txCount int
	var txsHash string
	fmt.Sscanf(data, "TxCount: %d, TxsHash: %s", &txCount, &txsHash)
	return txsHash
}

func (a *ConsensusAdapter) calculateDeadline(seconds int) uint64 {
	return uint64(time.Now().Add(time.Duration(seconds) * time.Second).UnixNano())
}

func (a *ConsensusAdapter) generateBitmap() []byte {
	// å®ç°ä½å›¾ç”Ÿæˆé€»è¾‘
	bitmap := make([]byte, 128)
	// TODO: å®é™…çš„ä½å›¾ç”Ÿæˆé€»è¾‘
	return bitmap
}

func (a *ConsensusAdapter) prepareContainer(msg types.Message) ([]byte, bool) {
	// å‡†å¤‡å®¹å™¨æ•°æ®çš„é€»è¾‘
	if msg.Block != nil {
		dbBlock := a.ConsensusBlockToDB(msg.Block, nil)
		data, _ := proto.Marshal(dbBlock)
		return data, true
	}
	return nil, false
}

func (a *ConsensusAdapter) resolveShorHashesToTxs(shortHashes []byte) ([]*pb.AnyTx, error) {
	// TODO: å®ç°çŸ­å“ˆå¸Œåˆ°äº¤æ˜“çš„è§£æ
	return nil, nil
}


æ–‡ä»¶è·¯å¾„: consensus/config.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)
// ============================================
// é…ç½®ç®¡ç†
// ============================================

type Config struct {
	Network   NetworkConfig
	Consensus ConsensusConfig
	Node      NodeConfig
	Sync      SyncConfig
	Gossip    GossipConfig
	Snapshot  SnapshotConfig // æ–°å¢
}

type NetworkConfig struct {
	NumNodes          int
	NumByzantineNodes int
	NetworkLatency    time.Duration
	PacketLossRate    float64 //ä¸¢åŒ…ç‡ï¼ŒèŒƒå›´ 0.0 åˆ° 1.0
}

type ConsensusConfig struct {
	K                    int
	Alpha                int
	Beta                 int
	QueryTimeout         time.Duration
	MaxConcurrentQueries int
	NumHeights           int
	BlocksPerHeight      int
}

type NodeConfig struct {
	ProposalInterval time.Duration
}

type SyncConfig struct {
	CheckInterval     time.Duration
	BehindThreshold   uint64
	BatchSize         uint64
	Timeout           time.Duration
	SnapshotThreshold uint64 // æ–°å¢ï¼šè½åå¤šå°‘é«˜åº¦æ—¶ä½¿ç”¨å¿«ç…§
}

type GossipConfig struct {
	Fanout   int
	Interval time.Duration
}

// æ–°å¢ï¼šå¿«ç…§é…ç½®
type SnapshotConfig struct {
	Interval     uint64 // æ¯å¤šå°‘ä¸ªåŒºå—åˆ›å»ºä¸€æ¬¡å¿«ç…§
	MaxSnapshots int    // æœ€å¤šä¿ç•™å¤šå°‘ä¸ªå¿«ç…§
	Enabled      bool   // æ˜¯å¦å¯ç”¨å¿«ç…§åŠŸèƒ½
}

func DefaultConfig() *Config {
	return &Config{
		Network: NetworkConfig{
			NumNodes:          100,
			NumByzantineNodes: 10,
			NetworkLatency:    100 * time.Millisecond,
			PacketLossRate:    0.1, // 10% ä¸¢åŒ…ç‡
		},
		Consensus: ConsensusConfig{
			K:                    20,
			Alpha:                15,
			Beta:                 15,
			QueryTimeout:         3 * time.Second,
			MaxConcurrentQueries: 20,
			NumHeights:           10,
			BlocksPerHeight:      5,
		},
		Node: NodeConfig{
			ProposalInterval: 1200 * time.Millisecond,
		},
		Sync: SyncConfig{
			CheckInterval:     2 * time.Second,
			BehindThreshold:   2,
			BatchSize:         10,
			Timeout:           5 * time.Second,
			SnapshotThreshold: 100, // æ–°å¢ï¼šè½å100ä¸ªé«˜åº¦æ—¶ä½¿ç”¨å¿«ç…§
		},
		Gossip: GossipConfig{
			Fanout:   15,
			Interval: 50 * time.Millisecond,
		},
		Snapshot: SnapshotConfig{
			Interval:     100,  // æ¯100ä¸ªåŒºå—ä¸€ä¸ªå¿«ç…§
			MaxSnapshots: 10,   // æœ€å¤šä¿ç•™10ä¸ªå¿«ç…§
			Enabled:      true, // å¯ç”¨å¿«ç…§
		},
	}
}


æ–‡ä»¶è·¯å¾„: consensus/consensusEngine.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// å…±è¯†å¼•æ“
// ============================================

type SnowmanEngine struct {
	mu            sync.RWMutex
	nodeID        types.NodeID
	store         interfaces.BlockStore
	config        *ConsensusConfig
	events        interfaces.EventBus
	snowballs     map[uint64]*Snowball
	activeQueries map[string]*QueryContext
	preferences   map[uint64]string
}

type QueryContext struct {
	queryKey  string
	blockID   string
	votes     map[string]int
	voters    map[types.NodeID]bool
	responded int
	startTime time.Time
	height    uint64
}

func NewSnowmanEngine(nodeID types.NodeID, store interfaces.BlockStore, config *ConsensusConfig, events interfaces.EventBus) interfaces.ConsensusEngine {
	return &SnowmanEngine{
		nodeID:        nodeID,
		store:         store,
		config:        config,
		events:        events,
		snowballs:     make(map[uint64]*Snowball),
		activeQueries: make(map[string]*QueryContext),
		preferences:   make(map[uint64]string),
	}
}

func (e *SnowmanEngine) Start(ctx context.Context) error {
	// åˆå§‹åŒ–åˆ›ä¸–åŒºå—çš„Snowball
	e.mu.Lock()
	genesisSB := NewSnowball(e.events)
	genesisSB.Finalize()
	e.snowballs[0] = genesisSB
	e.preferences[0] = "genesis"
	e.mu.Unlock()

	// å®šæœŸæ£€æŸ¥è¶…æ—¶
	go func() {
		ticker := time.NewTicker(1 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				e.checkTimeouts()
			case <-ctx.Done():
				return
			}
		}
	}()

	return nil
}

func (e *SnowmanEngine) RegisterQuery(nodeID types.NodeID, requestID uint32, blockID string, height uint64) string {
	e.mu.Lock()
	defer e.mu.Unlock()

	queryKey := fmt.Sprintf("%s-%d", nodeID, requestID)
	e.activeQueries[queryKey] = &QueryContext{
		queryKey:  queryKey,
		blockID:   blockID,
		votes:     make(map[string]int),
		voters:    make(map[types.NodeID]bool),
		responded: 0,
		startTime: time.Now(),
		height:    height,
	}

	return queryKey
}

func (e *SnowmanEngine) SubmitChit(nodeID types.NodeID, queryKey string, preferredID string) {
	e.mu.Lock()
	defer e.mu.Unlock()

	ctx, exists := e.activeQueries[queryKey]
	if !exists || ctx.voters[nodeID] {
		return
	}

	ctx.voters[nodeID] = true
	ctx.votes[preferredID]++
	ctx.responded++

	if ctx.responded >= e.config.Alpha {
		e.processVotes(ctx)
		delete(e.activeQueries, queryKey)
		e.events.PublishAsync(types.BaseEvent{
			EventType: types.EventQueryComplete,
			EventData: QueryCompleteData{Reason: "success", QueryKeys: []string{queryKey}},
		})
	}
}

func (e *SnowmanEngine) processVotes(ctx *QueryContext) {
	sb, exists := e.snowballs[ctx.height]
	if !exists {
		sb = NewSnowball(e.events)
		e.snowballs[ctx.height] = sb
	}

	// å€™é€‰åŒºå—
	candidates := make([]string, 0)
	blocks := e.store.GetByHeight(ctx.height)
	for _, block := range blocks {
		candidates = append(candidates, block.ID)
	}
	//æ ¸å¿ƒï¼šç»Ÿè®¡æŠ•ç¥¨
	sb.RecordVote(candidates, ctx.votes, e.config.Alpha)

	newPreference := sb.GetPreference()
	if newPreference != "" {
		e.preferences[ctx.height] = newPreference
	}

	if sb.CanFinalize(e.config.Beta) && newPreference != "" {
		e.finalizeBlock(ctx.height, newPreference)
	}
}

func (e *SnowmanEngine) finalizeBlock(height uint64, blockID string) {
	e.store.SetFinalized(height, blockID)

	sb := e.snowballs[height]
	if sb != nil {
		sb.Finalize()
	}

	if block, exists := e.store.Get(blockID); exists {
		Logf("[Engine] ğŸ‰ Finalized block %s at height %d\n", blockID, height)
		e.events.PublishAsync(types.BaseEvent{
			EventType: types.EventBlockFinalized,
			EventData: block,
		})
	}
}

type QueryCompleteData struct {
	Reason    string   // "success" | "timeout"
	QueryKeys []string // ç»“æŸçš„æŸ¥è¯¢é”®ï¼ˆå¯é€‰ï¼‰
}

func (e *SnowmanEngine) checkTimeouts() {
	e.mu.Lock()
	now := time.Now()
	var expired []string
	for k, ctx := range e.activeQueries {
		if now.Sub(ctx.startTime) > e.config.QueryTimeout {
			expired = append(expired, k)
			delete(e.activeQueries, k)
		}
	}
	e.mu.Unlock()

	if len(expired) > 0 {
		e.events.PublishAsync(types.BaseEvent{
			EventType: types.EventQueryComplete,
			EventData: QueryCompleteData{Reason: "timeout", QueryKeys: expired},
		})
	}
}

func (e *SnowmanEngine) GetActiveQueryCount() int {
	e.mu.RLock()
	defer e.mu.RUnlock()
	return len(e.activeQueries)
}

func (e *SnowmanEngine) GetPreference(height uint64) string {
	e.mu.RLock()
	defer e.mu.RUnlock()

	if pref, exists := e.preferences[height]; exists {
		return pref
	}

	if sb, exists := e.snowballs[height]; exists {
		return sb.GetPreference()
	}

	return ""
}


æ–‡ä»¶è·¯å¾„: consensus/eventBus.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

type EventBus struct {
	mu       sync.RWMutex
	handlers map[types.EventType][]interfaces.EventHandler
}

func NewEventBus() interfaces.EventBus {
	return &EventBus{
		handlers: make(map[types.EventType][]interfaces.EventHandler),
	}
}

func (eb *EventBus) Subscribe(topic types.EventType, handler interfaces.EventHandler) {
	eb.mu.Lock()
	defer eb.mu.Unlock()
	eb.handlers[topic] = append(eb.handlers[topic], handler)
}

func (eb *EventBus) Publish(event interfaces.Event) {
	eb.mu.RLock()
	handlers := eb.handlers[event.Type()]
	eb.mu.RUnlock()

	for _, handler := range handlers {
		handler(event)
	}
}

func (eb *EventBus) PublishAsync(event interfaces.Event) {
	go eb.Publish(event)
}


æ–‡ä»¶è·¯å¾„: consensus/gossipManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// Gossipç®¡ç†å™¨
// ============================================

type GossipManager struct {
	nodeID     types.NodeID
	node       *Node
	transport  interfaces.Transport
	store      interfaces.BlockStore
	config     *GossipConfig
	events     interfaces.EventBus
	seenBlocks map[string]bool
	mu         sync.RWMutex
}

func NewGossipManager(nodeID types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, config *GossipConfig, events interfaces.EventBus) *GossipManager {
	gm := &GossipManager{
		nodeID:     nodeID,
		transport:  transport,
		store:      store,
		config:     config,
		events:     events,
		seenBlocks: make(map[string]bool),
	}

	events.Subscribe(types.EventNewBlock, func(e interfaces.Event) {
		if block, ok := e.Data().(*types.Block); ok {
			gm.gossipBlock(block)
		}
	})

	return gm
}

func (gm *GossipManager) Start(ctx context.Context) {
	go func() {
		ticker := time.NewTicker(gm.config.Interval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				gm.gossipNewBlocks()
			case <-ctx.Done():
				return
			}
		}
	}()
}

func (gm *GossipManager) gossipNewBlocks() {
	_, currentHeight := gm.store.GetLastAccepted()
	curMax := gm.store.GetCurrentHeight()
	// å¦‚æœé“¾ä¸Šè¿˜æ²¡åˆ° next/next+1ï¼Œå°±åˆ«å» GetByHeightï¼Œé¿å…è§¦å‘ DB å›é€€
	if curMax <= currentHeight {
		return
	}

	blocks := make([]*types.Block, 0, 4) //åˆå§‹0ï¼Œæœ€å¤šå®¹çº³4ä¸ªå…ƒç´ 
	blocks = append(blocks, gm.store.GetByHeight(currentHeight+1)...)
	if curMax >= currentHeight+2 { //æ§åˆ¶å¹¿æ’­çš„èŒƒå›´ï¼Œ
		blocks = append(blocks, gm.store.GetByHeight(currentHeight+2)...)
	}

	for _, block := range blocks {
		if block.ID == "genesis" {
			continue
		}
		gm.mu.RLock()
		seen := gm.seenBlocks[block.ID]
		gm.mu.RUnlock()
		if !seen {
			gm.gossipBlock(block)
		}
	}
}

func (gm *GossipManager) gossipBlock(block *types.Block) {
	gm.mu.Lock()
	if gm.seenBlocks[block.ID] { // å·²è½¬å‘è¿‡ï¼Ÿé‚£å°±ä¸å†å‘
		gm.mu.Unlock()
		return
	}
	gm.seenBlocks[block.ID] = true
	gm.mu.Unlock()

	peers := gm.transport.SamplePeers(gm.nodeID, gm.config.Fanout)
	msg := types.Message{
		Type:    types.MsgGossip,
		From:    gm.nodeID,
		Block:   block,
		BlockID: block.ID,
		Height:  block.Height,
	}

	gm.transport.Broadcast(msg, peers)
}

func (gm *GossipManager) HandleGossip(msg types.Message) {
	if msg.Block == nil {
		return
	}

	if gm.node != nil {
		gm.node.stats.Mu.Lock()
		gm.node.stats.GossipsReceived++
		gm.node.stats.Mu.Unlock()
	}

	gm.mu.RLock()
	alreadySeen := gm.seenBlocks[msg.Block.ID]
	gm.mu.RUnlock()

	if alreadySeen {
		return
	}

	gm.mu.Lock()
	gm.seenBlocks[msg.Block.ID] = true
	gm.mu.Unlock()

	isNew, err := gm.store.Add(msg.Block)
	if err != nil {
		return
	}

	if isNew {
		logs.Debug("[Node %d] Received new block %s via gossip from Node %d\n",
			gm.nodeID, msg.Block.ID, msg.From)

		gm.events.PublishAsync(types.BaseEvent{
			EventType: types.EventBlockReceived,
			EventData: msg.Block,
		})

		go func() {
			time.Sleep(time.Duration(50+rand.Intn(100)) * time.Millisecond)
			gm.gossipBlock(msg.Block)
		}()
	}
}


æ–‡ä»¶è·¯å¾„: consensus/loop.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// ä¸»å‡½æ•°
// ============================================

func RunLoop() {
	rand.Seed(time.Now().UnixNano())

	config := DefaultConfig()

	// å¯ä»¥è°ƒæ•´å¿«ç…§é…ç½®è¿›è¡Œæµ‹è¯•
	// config.Sync.SnapshotThreshold = 50  // è½å50ä¸ªå—å°±ç”¨å¿«ç…§
	// config.Snapshot.Interval = 50        // æ¯50ä¸ªå—åˆ›å»ºä¸€ä¸ªå¿«ç…§

	fmt.Println("Starting Decoupled Snowman Consensus (With Snapshot Support)...")
	Logf("Network: %d nodes (%d honest, %d byzantine)\n",
		config.Network.NumNodes,
		config.Network.NumNodes-config.Network.NumByzantineNodes,
		config.Network.NumByzantineNodes)
	Logf("Heights: %d, Blocks per height: %d\n",
		config.Consensus.NumHeights,
		config.Consensus.BlocksPerHeight)

	if config.Snapshot.Enabled {
		Logf("Snapshot: Enabled (interval=%d, threshold=%d)\n",
			config.Snapshot.Interval,
			config.Sync.SnapshotThreshold)
	}

	network := NewNetworkManager(config)
	network.CreateNodes()

	programStart := time.Now()
	network.Start()

	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	lastHeight := uint64(0)
	for {
		select {
		case <-ticker.C:
			minHeight, allDone := network.CheckProgress()
			if minHeight > lastHeight {
				Logf("\nâœ… All honest nodes reached consensus on height %d\n", minHeight)
				lastHeight = minHeight
			}

			if allDone {
				totalTime := time.Since(programStart)
				Logf("\nğŸ‰ All heights completed! Total time: %v\n", totalTime)

				time.Sleep(1 * time.Second)

				fmt.Println("\n\n===== FINAL RESULTS =====")
				network.PrintStatus()
				network.PrintFinalResults()

				fmt.Println("\n--- Time Statistics ---")
				Logf("Total Time: %v\n", totalTime)
				Logf("Average/Height: %v\n", totalTime/time.Duration(config.Consensus.NumHeights))

				return
			}
		}
	}
}


æ–‡ä»¶è·¯å¾„: consensus/messageHandler.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// æ¶ˆæ¯å¤„ç†å™¨
// ============================================

type MessageHandler struct {
	nodeID          types.NodeID
	node            *Node
	isByzantine     bool
	transport       interfaces.Transport
	store           interfaces.BlockStore
	engine          interfaces.ConsensusEngine
	queryManager    *QueryManager
	gossipManager   *GossipManager
	syncManager     *SyncManager
	snapshotManager *SnapshotManager
	events          interfaces.EventBus
	config          *ConsensusConfig
	// å­˜å‚¨å¾…å›å¤çš„PullQuery
	pendingQueries   map[uint32]types.Message
	pendingQueriesMu sync.RWMutex
	stats            *stats.Stats
}

func NewMessageHandler(nodeID types.NodeID, isByzantine bool, transport interfaces.Transport, store interfaces.BlockStore, engine interfaces.ConsensusEngine, events interfaces.EventBus, config *ConsensusConfig) *MessageHandler {
	return &MessageHandler{
		nodeID:         nodeID,
		isByzantine:    isByzantine,
		transport:      transport,
		store:          store,
		engine:         engine,
		events:         events,
		config:         config,
		pendingQueries: make(map[uint32]types.Message),
		stats:          stats.NewStats(),
	}
}

func (h *MessageHandler) SetManagers(qm *QueryManager, gm *GossipManager, sm *SyncManager, snapMgr *SnapshotManager) {
	h.queryManager = qm
	h.gossipManager = gm
	h.syncManager = sm
	h.snapshotManager = snapMgr
}

func (h *MessageHandler) HandleMsg(msg types.Message) {
	h.stats.RecordAPICall(string(msg.Type))
	if h.isByzantine && (msg.Type == types.MsgPullQuery || msg.Type == types.MsgPushQuery) {
		if h.node != nil {
			h.node.stats.Mu.Lock()
			h.node.stats.QueriesReceived++
			h.node.stats.Mu.Unlock()
		}
		return
	}

	switch msg.Type {
	case types.MsgPullQuery:
		h.handlePullQuery(msg)
	case types.MsgPushQuery:
		h.handlePushQuery(msg)
	case types.MsgChits:
		h.queryManager.HandleChit(msg)
	case types.MsgGet:
		h.handleGet(msg)
	case types.MsgPut:
		h.handlePut(msg)
	case types.MsgGossip:
		h.gossipManager.HandleGossip(msg)
	case types.MsgSyncRequest:
		h.syncManager.HandleSyncRequest(msg)
	case types.MsgSyncResponse:
		h.syncManager.HandleSyncResponse(msg)
	case types.MsgHeightQuery:
		h.syncManager.HandleHeightQuery(msg)
	case types.MsgHeightResponse:
		h.syncManager.HandleHeightResponse(msg)
	case types.MsgSnapshotRequest: // æ–°å¢
		h.syncManager.HandleSnapshotRequest(msg)
	case types.MsgSnapshotResponse: // æ–°å¢
		h.syncManager.HandleSnapshotResponse(msg)
	}
}

func (h *MessageHandler) handlePullQuery(msg types.Message) {
	if h.node != nil {
		h.node.stats.Mu.Lock()
		h.node.stats.QueriesReceived++
		h.node.stats.Mu.Unlock()
	}

	// æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰è¯¥åŒºå—
	block, exists := h.store.Get(msg.BlockID)
	if !exists {
		// æœ¬åœ°æ²¡æœ‰åŒºå—ï¼Œå‘å‘é€è€…è¯·æ±‚
		logs.Debug("[Node %s] Don't have block %s, requesting from %s",
			h.nodeID, msg.BlockID, msg.From)

		// å‘é€Getæ¶ˆæ¯è¯·æ±‚åŒºå—æ•°æ®
		h.transport.Send(types.NodeID(msg.From), types.Message{
			Type:      types.MsgGet,
			From:      h.nodeID,
			RequestID: msg.RequestID,
			BlockID:   msg.BlockID,
			Height:    msg.Height,
		})

		// å¯ä»¥é€‰æ‹©å­˜å‚¨å¾…å›å¤çš„æŸ¥è¯¢ï¼Œç­‰æ”¶åˆ°åŒºå—åå†å›å¤chits
		h.storePendingQuery(msg)
		return
	}

	// æœ‰åŒºå—ï¼Œç›´æ¥å‘é€chitsæŠ•ç¥¨
	h.sendChits(types.NodeID(msg.From), msg.RequestID, block.Height)
}

type PendingQueryKey struct {
	BlockID   string `json:"block_id"`
	RequestID uint32 `json:"request_id"`
}

// æ·»åŠ å­˜å‚¨å¾…å›å¤æŸ¥è¯¢çš„æ–¹æ³•
func (h *MessageHandler) storePendingQuery(msg types.Message) {
	// å¯ä»¥åœ¨MessageHandlerä¸­æ·»åŠ ä¸€ä¸ªpendingQueries map
	// å½“æ”¶åˆ°Putæ¶ˆæ¯åï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¾…å›å¤çš„æŸ¥è¯¢
	if h.pendingQueries == nil {
		h.pendingQueries = make(map[uint32]types.Message)
	}
	h.pendingQueriesMu.Lock()
	h.pendingQueries[msg.RequestID] = msg
	h.pendingQueriesMu.Unlock()
}

func (h *MessageHandler) handlePushQuery(msg types.Message) {
	if h.node != nil {
		h.node.stats.Mu.Lock()
		h.node.stats.QueriesReceived++
		h.node.stats.Mu.Unlock()
	}

	if msg.Block != nil {
		isNew, err := h.store.Add(msg.Block)
		if err != nil {
			return
		}

		if isNew {
			logs.Debug("[Node %d] Received new block %s via PushQuery\n", h.nodeID, msg.Block.ID)
			h.events.PublishAsync(types.BaseEvent{
				EventType: types.EventNewBlock,
				EventData: msg.Block,
			})
		}

		h.sendChits(types.NodeID(msg.From), msg.RequestID, msg.Block.Height)
	}
}

func (h *MessageHandler) sendChits(to types.NodeID, requestID uint32, queryHeight uint64) {
	preferred := h.engine.GetPreference(queryHeight)

	// NEW: åªæœ‰å½“æœ¬åœ° (h-1) å·²æœ€ç»ˆåŒ–ï¼Œæ‰å…è®¸å¯¹ h è¡¨æ€
	if preferred == "" {
		if parent, ok := h.store.GetFinalizedAtHeight(queryHeight - 1); ok {
			// åªåœ¨â€œçˆ¶=æœ¬åœ°æœ€ç»ˆåŒ–çˆ¶â€çš„å­©å­é‡Œé€‰åå¥½
			blocks := h.store.GetByHeight(queryHeight)
			cand := make([]string, 0, len(blocks))
			for _, b := range blocks {
				if b.ParentID == parent.ID {
					cand = append(cand, b.ID)
				}
			}
			if len(cand) > 0 {
				sort.Strings(cand)
				preferred = cand[len(cand)-1]
			}
		}
	}

	// ä¸å…è®¸ç”¨â€œå…¨ä½“å—é‡Œå­—å…¸åºæœ€å¤§â€çš„å…œåº•ï¼›çˆ¶æœªå®šå°±å¼ƒæƒ
	// if still "", treat as abstain

	accepted, acceptedHeight := h.store.GetLastAccepted()
	logs.Debug("[sendChits] to=%s req=%d h=%d preferred=%v accepted=%v",
		to, requestID, queryHeight, preferred, accepted)

	h.transport.Send(to, types.Message{
		Type: types.MsgChits, From: h.nodeID, RequestID: requestID,
		PreferredID:       preferred,
		PreferredIDHeight: queryHeight,
		AcceptedID:        accepted, AcceptedHeight: acceptedHeight,
	})
}

func (h *MessageHandler) handleGet(msg types.Message) {
	// è¯·æ±‚æ–¹éœ€è¦åŒºå—æ•°æ®ï¼Œå°±æŸ¥æœ¬åœ°ï¼Œå‘ç»™ä»–
	if block, exists := h.store.Get(msg.BlockID); exists {
		err := h.transport.Send(types.NodeID(msg.From), types.Message{
			Type:      types.MsgPut,
			From:      h.nodeID,
			RequestID: msg.RequestID,
			Block:     block,
			Height:    block.Height,
		})
		if err != nil {
			return
		}
	}
}

func (h *MessageHandler) handlePut(msg types.Message) {
	if msg.Block != nil {
		isNew, err := h.store.Add(msg.Block)
		if err != nil {
			return
		}

		if isNew {
			logs.Debug("[Node %d] Received new block %s via Put from Node %d",
				h.nodeID, msg.Block.ID, msg.From)
			h.events.PublishAsync(types.BaseEvent{
				EventType: types.EventBlockReceived,
				EventData: msg.Block,
			})

			// æ£€æŸ¥æ˜¯å¦æœ‰å¾…å›å¤çš„PullQuery
			h.checkPendingQueries(msg.RequestID)
		}
	}
}

// æ·»åŠ æ£€æŸ¥å¾…å›å¤æŸ¥è¯¢çš„æ–¹æ³•
func (h *MessageHandler) checkPendingQueries(requestId uint32) {
	h.pendingQueriesMu.Lock()
	if pendingMsg, exists := h.pendingQueries[requestId]; exists {
		blockID := pendingMsg.BlockID
		delete(h.pendingQueries, requestId)
		h.pendingQueriesMu.Unlock()

		// ç°åœ¨æœ‰äº†åŒºå—ï¼Œå¯ä»¥å›å¤chits
		// TODO:æ’æŸ¥ä¸ºä»€ä¹ˆå¯èƒ½æ˜¯nil
		block, _ := h.store.Get(blockID)
		h.sendChits(types.NodeID(pendingMsg.From), pendingMsg.RequestID, block.Height)
	} else {
		h.pendingQueriesMu.Unlock()
	}
}


æ–‡ä»¶è·¯å¾„: consensus/node.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// èŠ‚ç‚¹å®ç°
// ============================================

type Node struct {
	ID              types.NodeID
	IsByzantine     bool
	transport       interfaces.Transport
	store           interfaces.BlockStore
	engine          interfaces.ConsensusEngine
	events          interfaces.EventBus
	messageHandler  *MessageHandler
	queryManager    *QueryManager
	gossipManager   *GossipManager
	SyncManager     *SyncManager
	snapshotManager *SnapshotManager
	proposalManager *ProposalManager
	ctx             context.Context
	cancel          context.CancelFunc
	config          *Config
	stats           *NodeStats
}

func NewNode(id types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, byzantine bool, config *Config) *Node {
	ctx, cancel := context.WithCancel(context.Background())

	events := NewEventBus()
	engine := NewSnowmanEngine(id, store, &config.Consensus, events)

	node := &Node{
		ID:          id,
		IsByzantine: byzantine,
		transport:   transport,
		store:       store, // ä½¿ç”¨ä¼ å…¥çš„ store
		engine:      engine,
		events:      events,
		ctx:         ctx,
		cancel:      cancel,
		config:      config,
		stats:       NewNodeStats(events),
	}

	messageHandler := NewMessageHandler(id, byzantine, transport, store, engine, events, &config.Consensus)
	messageHandler.node = node

	queryManager := NewQueryManager(id, transport, store, engine, &config.Consensus, events)
	queryManager.node = node

	gossipManager := NewGossipManager(id, transport, store, &config.Gossip, events)
	gossipManager.node = node

	syncManager := NewSyncManager(id, transport, store, &config.Sync, &config.Snapshot, events)
	syncManager.node = node

	snapshotManager := NewSnapshotManager(id, store, &config.Snapshot, events) // æ–°å¢

	proposalManager := NewProposalManager(id, transport, store, &config.Node, events)
	proposalManager.node = node

	messageHandler.SetManagers(queryManager, gossipManager, syncManager, snapshotManager)

	node.messageHandler = messageHandler
	node.queryManager = queryManager
	node.gossipManager = gossipManager
	node.SyncManager = syncManager
	node.snapshotManager = snapshotManager
	node.proposalManager = proposalManager

	return node
}

func (n *Node) Start() {
	go func() {
		for {
			select {
			case msg := <-n.transport.Receive():
				n.messageHandler.HandleMsg(msg)
			case <-n.ctx.Done():
				return
			}
		}
	}()

	n.engine.Start(n.ctx)
	n.queryManager.Start(n.ctx)
	n.gossipManager.Start(n.ctx)
	n.SyncManager.Start(n.ctx)
	n.snapshotManager.Start(n.ctx)

	if !n.IsByzantine {
		n.proposalManager.Start(n.ctx)
	}
}

func (n *Node) Stop() {
	n.cancel()
}


æ–‡ä»¶è·¯å¾„: consensus/nodeStats.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

/* ----------------- ç»“æ„å®šä¹‰ ----------------- */

type PreferenceSwitch struct {
	BlockID    string // è¢«åˆ‡æ¢çš„åŒºå—ID
	Confidence int    // åˆ‡æ¢æ—¶çš„ç½®ä¿¡åº¦
	Winner     string
	Alpha      int
}

type NodeStats struct {
	Mu               sync.Mutex
	QueriesSent      uint32
	QueriesReceived  uint32
	ChitsResponded   uint32
	QueriesPerHeight map[uint64]uint32
	BlocksProposed   uint32
	GossipsReceived  uint32
	SnapshotsUsed    uint32
	SnapshotsServed  uint32
	events           interfaces.EventBus

	// ---- ç¯å½¢ç¼“å†²åŒºå®ç° ----
	prefHistBuf  []PreferenceSwitch // å›ºå®šå®¹é‡ç¼“å†²åŒº
	prefHistCap  int                // å®¹é‡ï¼ˆå¸¸é‡/å¯é…ç½®ï¼‰
	prefHistHead int                // ä¸‹ä¸€ä¸ªå†™å…¥ä½ç½®ï¼ˆ0..cap-1ï¼‰
	prefHistLen  int                // å½“å‰å·²æœ‰å…ƒç´ ä¸ªæ•°ï¼ˆ<= capï¼‰
}

func NewNodeStats(events interfaces.EventBus) *NodeStats {

	historyCap := 256
	stats := &NodeStats{
		QueriesPerHeight: make(map[uint64]uint32),
		events:           events,
		prefHistCap:      historyCap,
	}
	stats.prefHistBuf = make([]PreferenceSwitch, historyCap)

	stats.events.Subscribe(types.EventPreferenceChanged, func(e interfaces.Event) {
		if preferenceSwitch, ok := e.Data().(PreferenceSwitch); ok {
			stats.pushPreferenceSwitch(preferenceSwitch)
		}
	})
	return stats
}

/* ----------------- å†…éƒ¨æ–¹æ³• ----------------- */

// O(1) å†™å…¥ï¼›æ»¡äº†è¦†ç›–æœ€æ—§ã€‚
func (s *NodeStats) pushPreferenceSwitch(ps PreferenceSwitch) {
	if s.prefHistCap == 0 {
		return // å…³é—­å†å²è®°å½•
	}
	s.Mu.Lock()
	s.prefHistBuf[s.prefHistHead] = ps
	s.prefHistHead = (s.prefHistHead + 1) % s.prefHistCap
	if s.prefHistLen < s.prefHistCap {
		s.prefHistLen++
	}
	s.Mu.Unlock()
}

// è¯»å–ã€Œä»æ—§åˆ°æ–°ã€çš„å¿«ç…§å‰¯æœ¬ï¼Œé¿å…å¤–éƒ¨æ”¹åŠ¨å†…éƒ¨ç¼“å†²ã€‚
func (s *NodeStats) GetPreferenceSwitchHistory() []PreferenceSwitch {
	return s.prefHistBuf
}


æ–‡ä»¶è·¯å¾„: consensus/proposalManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

type ProposalManager struct {
	nodeID         types.NodeID
	node           *Node
	transport      interfaces.Transport
	store          interfaces.BlockStore
	config         *NodeConfig
	events         interfaces.EventBus
	proposedBlocks map[string]bool
	proposalRound  int
	mu             sync.Mutex
	proposer       interfaces.BlockProposer // æ–°å¢ï¼šæ³¨å…¥çš„ææ¡ˆè€…æ¥å£
}

// NewProposalManager åˆ›å»ºæ–°çš„ææ¡ˆç®¡ç†å™¨ï¼ˆä½¿ç”¨é»˜è®¤ææ¡ˆè€…ï¼‰
func NewProposalManager(nodeID types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, config *NodeConfig, events interfaces.EventBus) *ProposalManager {
	return NewProposalManagerWithProposer(nodeID, transport, store, config, events, NewDefaultBlockProposer())
}

// NewProposalManagerWithProposer åˆ›å»ºæ–°çš„ææ¡ˆç®¡ç†å™¨ï¼ˆå¯æ³¨å…¥è‡ªå®šä¹‰ææ¡ˆè€…ï¼‰
func NewProposalManagerWithProposer(nodeID types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, config *NodeConfig, events interfaces.EventBus, proposer interfaces.BlockProposer) *ProposalManager {
	return &ProposalManager{
		nodeID:         nodeID,
		transport:      transport,
		store:          store,
		config:         config,
		events:         events,
		proposedBlocks: make(map[string]bool),
		proposer:       proposer,
	}
}

func (pm *ProposalManager) Start(ctx context.Context) {
	go func() {
		ticker := time.NewTicker(pm.config.ProposalInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				pm.proposeBlock()
			case <-ctx.Done():
				return
			}
		}
	}()
}

func (pm *ProposalManager) proposeBlock() {
	pm.mu.Lock()
	pm.proposalRound++
	currentRound := pm.proposalRound
	pm.mu.Unlock()

	lastAcceptedID, lastHeight := pm.store.GetLastAccepted()
	targetHeight := lastHeight + 1

	currentBlocks := len(pm.store.GetByHeight(targetHeight))

	// ä¿®æ”¹ç‚¹ï¼šä¼ å…¥ currentHeight (lastHeight) å’Œ proposeHeight (targetHeight) å‚æ•°
	if !pm.proposer.ShouldPropose(pm.nodeID, currentRound, currentBlocks, int(lastHeight), int(targetHeight)) {
		return
	}

	block, err := pm.proposer.ProposeBlock(lastAcceptedID, targetHeight, pm.nodeID, currentRound)
	if err != nil {
		Logf("[Node %d] Failed to propose block: %v\n", pm.nodeID, err)
		return
	}
	if block == nil {
		logs.Debug("[ProposalManager] no block proposed (pending txs=0?) at height=%d round=%d",
			targetHeight, currentRound)
		return
	}

	pm.mu.Lock()
	if pm.proposedBlocks[block.ID] {
		pm.mu.Unlock()
		return
	}
	pm.proposedBlocks[block.ID] = true
	pm.mu.Unlock()

	isNew, err := pm.store.Add(block)
	if err != nil || !isNew {
		return
	}

	if pm.node != nil {
		pm.node.stats.Mu.Lock()
		pm.node.stats.BlocksProposed++
		pm.node.stats.Mu.Unlock()
	}

	Logf("[Node %d] Proposing %s on parent %s\n", pm.nodeID, block, lastAcceptedID)

	pm.events.PublishAsync(types.BaseEvent{
		EventType: types.EventNewBlock,
		EventData: block,
	})

	// æè®®è€…ç«‹å³å‘èµ·PushQueryæ¥ä¼ æ’­è‡ªå·±çš„åŒºå—
	if pm.node != nil && pm.node.queryManager != nil {
		go func() {
			pm.node.queryManager.tryIssueQuery()
		}()
	}
}

// SetProposer å…è®¸è¿è¡Œæ—¶æ›´æ¢ææ¡ˆè€…å®ç°
func (pm *ProposalManager) SetProposer(proposer interfaces.BlockProposer) {
	pm.mu.Lock()
	defer pm.mu.Unlock()
	pm.proposer = proposer
}


æ–‡ä»¶è·¯å¾„: consensus/queryManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// æŸ¥è¯¢ç®¡ç†å™¨
// ============================================

type QueryManager struct {
	nodeID      types.NodeID
	node        *Node
	transport   interfaces.Transport
	store       interfaces.BlockStore
	engine      interfaces.ConsensusEngine
	config      *ConsensusConfig
	events      interfaces.EventBus
	activePolls sync.Map
	nextReqID   uint32
	mu          sync.Mutex
}

type Poll struct {
	requestID uint32
	blockID   string
	queryKey  string
	startTime time.Time
	height    uint64
}

func NewQueryManager(nodeID types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, engine interfaces.ConsensusEngine, config *ConsensusConfig, events interfaces.EventBus) *QueryManager {
	qm := &QueryManager{
		nodeID:    nodeID,
		transport: transport,
		store:     store,
		engine:    engine,
		config:    config,
		events:    events,
	}

	events.Subscribe(types.EventQueryComplete, func(e interfaces.Event) {
		//åªæœ‰timeoutæ‰éœ€è¦æ¸…ç†
	})

	events.Subscribe(types.EventSyncComplete, func(e interfaces.Event) {
		qm.tryIssueQuery()
	})

	// æ–°å¢ï¼šå¿«ç…§åŠ è½½åä¹Ÿè§¦å‘æŸ¥è¯¢
	events.Subscribe(types.EventSnapshotLoaded, func(e interfaces.Event) {
		qm.tryIssueQuery()
	})

	events.Subscribe(types.EventBlockReceived, func(e interfaces.Event) {
		qm.tryIssueQuery()
	})

	return qm
}

// å°è¯•å‘èµ·æŸ¥è¯¢
func (qm *QueryManager) tryIssueQuery() {
	qm.mu.Lock()
	defer qm.mu.Unlock()

	_, currentHeight := qm.store.GetLastAccepted()
	nextHeight := currentHeight + 1

	blocks := qm.store.GetByHeight(nextHeight)
	if len(blocks) == 0 {
		return
	}

	if qm.engine.GetActiveQueryCount() >= qm.config.MaxConcurrentQueries {
		return
	}

	qm.issueQuery()
}

func (qm *QueryManager) issueQuery() {
	_, currentHeight := qm.store.GetLastAccepted()
	nextHeight := currentHeight + 1

	blocks := qm.store.GetByHeight(nextHeight)
	if len(blocks) == 0 {
		return
	}

	// è·å–åå¥½åŒºå—ID
	blockID := qm.engine.GetPreference(nextHeight)
	if blockID == "" {
		candidates := make([]string, 0, len(blocks))
		for _, b := range blocks {
			candidates = append(candidates, b.ID)
		}
		sort.Strings(candidates)
		blockID = candidates[len(candidates)-1]
	}

	block, exists := qm.store.Get(blockID)
	if !exists {
		return
	}
	requestID, _ := secureRandUint32()
	queryKey := qm.engine.RegisterQuery(qm.nodeID, requestID, blockID, block.Height)

	poll := &Poll{
		requestID: requestID,
		blockID:   blockID,
		queryKey:  queryKey,
		startTime: time.Now(),
		height:    block.Height,
	}
	qm.activePolls.Store(requestID, poll)

	peers := qm.transport.SamplePeers(qm.nodeID, qm.config.K)

	// åˆ¤æ–­è‡ªå·±æ˜¯å¦æ˜¯è¯¥åŒºå—çš„æè®®è€…
	isProposer := (block.Proposer == string(qm.nodeID))

	var msg types.Message
	if isProposer {
		// åªæœ‰æè®®è€…å‘é€PushQueryï¼ˆæºå¸¦å®Œæ•´åŒºå—ï¼‰
		msg = types.Message{
			Type:      types.MsgPushQuery,
			From:      qm.nodeID,
			RequestID: requestID,
			BlockID:   blockID,
			Block:     block, // æºå¸¦å®Œæ•´åŒºå—æ•°æ®
			Height:    block.Height,
		}
		logs.Debug("[Node %s] Sending PushQuery for block %s (I'm the proposer)",
			qm.nodeID, blockID)
	} else {
		// éæè®®è€…å‘é€PullQueryï¼ˆåªæºå¸¦åŒºå—IDï¼‰
		msg = types.Message{
			Type:      types.MsgPullQuery,
			From:      qm.nodeID,
			RequestID: requestID,
			BlockID:   blockID,
			Height:    block.Height,
		}
		logs.Debug("[Node %s] Sending PullQuery for block %s",
			qm.nodeID, blockID)
	}

	qm.transport.Broadcast(msg, peers)

	if qm.node != nil {
		qm.node.stats.Mu.Lock()
		qm.node.stats.QueriesSent++
		qm.node.stats.QueriesPerHeight[block.Height]++
		qm.node.stats.Mu.Unlock()
	}
}

// è¿”å› [0, 2^32-1] èŒƒå›´å†…çš„å®‰å…¨éšæœº uint32
func secureRandUint32() (uint32, error) {
	var b [4]byte
	if _, err := rand.Read(b[:]); err != nil {
		return 0, err
	}
	return binary.BigEndian.Uint32(b[:]), nil
}

func (qm *QueryManager) HandleChit(msg types.Message) {
	if poll, ok := qm.activePolls.Load(msg.RequestID); ok {
		p := poll.(*Poll)
		qm.engine.SubmitChit(types.NodeID(msg.From), p.queryKey, msg.PreferredID)
	}
}

func (qm *QueryManager) Start(ctx context.Context) {
	go func() {
		time.Sleep(100 * time.Millisecond)
		for i := 0; i < qm.config.MaxConcurrentQueries; i++ {
			qm.tryIssueQuery()
		}
	}()

	go func() {
		ticker := time.NewTicker(107 * time.Millisecond)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				qm.tryIssueQuery()
			case <-ctx.Done():
				return
			}
		}
	}()
}


æ–‡ä»¶è·¯å¾„: consensus/realBlockStore.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// RealBlockStore ä½¿ç”¨æ•°æ®åº“çš„çœŸå®åŒºå—å­˜å‚¨å®ç°
type RealBlockStore struct {
	mu        sync.RWMutex
	dbManager *db.Manager
	pool      *txpool.TxPool
	adapter   *ConsensusAdapter
	// å†…å­˜ç¼“å­˜
	blockCache         map[string]*types.Block
	heightIndex        map[uint64][]*types.Block
	finalizedBlocks    map[uint64]*types.Block
	lastAccepted       *types.Block
	lastAcceptedHeight uint64
	maxHeight          uint64

	// å¿«ç…§ç®¡ç†
	snapshots       map[uint64]*types.Snapshot
	snapshotHeights []uint64
	maxSnapshots    int
}

// åˆ›å»ºçœŸå®çš„åŒºå—å­˜å‚¨
func NewRealBlockStore(dbManager *db.Manager, maxSnapshots int, pool *txpool.TxPool) interfaces.BlockStore {
	store := &RealBlockStore{
		dbManager:       dbManager,
		pool:            pool,
		blockCache:      make(map[string]*types.Block),
		heightIndex:     make(map[uint64][]*types.Block),
		finalizedBlocks: make(map[uint64]*types.Block),
		snapshots:       make(map[uint64]*types.Snapshot),
		snapshotHeights: make([]uint64, 0),
		maxSnapshots:    maxSnapshots,
		maxHeight:       0,
		adapter:         NewConsensusAdapter(dbManager),
	}

	// åˆå§‹åŒ–åˆ›ä¸–åŒºå—
	genesis := &types.Block{
		ID:       "genesis",
		Height:   0,
		ParentID: "",
		Data:     "Genesis Block",
		Proposer: "-1",
	}

	store.blockCache[genesis.ID] = genesis
	store.heightIndex[0] = []*types.Block{genesis}
	store.lastAccepted = genesis
	store.lastAcceptedHeight = 0
	store.finalizedBlocks[0] = genesis

	// å°†åˆ›ä¸–åŒºå—ä¿å­˜åˆ°æ•°æ®åº“
	store.saveBlockToDB(genesis)

	// ä»æ•°æ®åº“åŠ è½½å·²æœ‰åŒºå—
	store.loadFromDB()

	return store
}

// Add æ·»åŠ æ–°åŒºå—
func (s *RealBlockStore) Add(block *types.Block) (bool, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if _, exists := s.blockCache[block.ID]; exists {
		return false, nil
	}

	if err := s.validateBlock(block); err != nil {
		return false, err
	}

	// æ·»åŠ åˆ°å†…å­˜ç¼“å­˜
	s.blockCache[block.ID] = block
	s.heightIndex[block.Height] = append(s.heightIndex[block.Height], block)

	if block.Height > s.maxHeight {
		s.maxHeight = block.Height
		// æ›´æ–°æ•°æ®åº“ä¸­çš„æœ€æ–°é«˜åº¦
		s.dbManager.EnqueueSet(db.KeyLatestHeight(), strconv.FormatUint(block.Height, 10))
	}

	// å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆéæœ€ç»ˆåŒ–çš„åŒºå—æš‚æ—¶åªåœ¨å†…å­˜ä¸­ï¼‰
	go s.saveBlockToDB(block)

	logs.Debug("[RealBlockStore] Added block %s at height %d", block.ID, block.Height)

	return true, nil
}

// Get è·å–åŒºå—
func (s *RealBlockStore) Get(id string) (*types.Block, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// å…ˆä»å†…å­˜ç¼“å­˜æŸ¥æ‰¾
	if block, exists := s.blockCache[id]; exists {
		return block, true
	}

	// ä»æ•°æ®åº“é€šè¿‡IDæŸ¥æ‰¾
	dbBlock, err := s.dbManager.GetBlockByID(id)
	if err != nil || dbBlock == nil {
		logs.Debug("[RealBlockStore] Block %s not found: %v", id, err)
		return nil, false
	}

	// è½¬æ¢ä¸ºtypes.Block
	block := s.convertDBBlockToTypes(dbBlock)
	if block != nil {
		// åŠ å…¥ç¼“å­˜ä»¥åŠ é€Ÿåç»­è®¿é—®
		s.blockCache[id] = block
		return block, true
	}

	return nil, false
}

// GetByHeight è·å–æŒ‡å®šé«˜åº¦çš„æ‰€æœ‰åŒºå—
func (s *RealBlockStore) GetByHeight(height uint64) []*types.Block {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// å…ˆä»å†…å­˜æŸ¥æ‰¾
	if blocks, exists := s.heightIndex[height]; exists {
		result := make([]*types.Block, len(blocks))
		copy(result, blocks)
		return result
	}
	// NEW: å¦‚æœè¯·æ±‚çš„é«˜åº¦è¿˜æ²¡è¢«ä»»ä½•åŒºå—è¦†ç›–ï¼Œå°±ç›´æ¥è¿”å›ç©ºï¼Œé¿å…æ‰“ DB
	if height > s.maxHeight {
		return []*types.Block{}
	}
	// ä»æ•°æ®åº“æŸ¥æ‰¾
	dbBlock, err := s.dbManager.GetBlock(height)
	if err != nil || dbBlock == nil {
		return []*types.Block{}
	}

	// è½¬æ¢ä¸ºtypes.Block
	block := s.convertDBBlockToTypes(dbBlock)
	if block != nil {
		s.blockCache[block.ID] = block
		s.heightIndex[height] = []*types.Block{block}
		return []*types.Block{block}
	}

	return []*types.Block{}
}

// GetLastAccepted è·å–æœ€åæ¥å—çš„åŒºå—
func (s *RealBlockStore) GetLastAccepted() (string, uint64) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if s.lastAccepted != nil {
		return s.lastAccepted.ID, s.lastAcceptedHeight
	}

	// ä»æ•°æ®åº“è·å–æœ€æ–°é«˜åº¦
	height, err := s.dbManager.GetLatestBlockHeight()
	if err == nil && height > 0 {
		if block, err := s.dbManager.GetBlock(height); err == nil && block != nil {
			return block.BlockHash, height
		}
	}

	return "genesis", 0
}

// GetFinalizedAtHeight è·å–æŒ‡å®šé«˜åº¦çš„æœ€ç»ˆåŒ–åŒºå—
func (s *RealBlockStore) GetFinalizedAtHeight(height uint64) (*types.Block, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// ä»å†…å­˜æŸ¥æ‰¾
	if block, exists := s.finalizedBlocks[height]; exists {
		return block, true
	}

	// ä»æ•°æ®åº“æŸ¥æ‰¾
	dbBlock, err := s.dbManager.GetBlock(height)
	if err != nil || dbBlock == nil {
		return nil, false
	}

	block := s.convertDBBlockToTypes(dbBlock)
	if block != nil {
		s.finalizedBlocks[height] = block
		return block, true
	}

	return nil, false
}

// è·å–æŒ‡å®šé«˜åº¦èŒƒå›´çš„åŒºå—
func (s *RealBlockStore) GetBlocksFromHeight(from, to uint64) []*types.Block {
	s.mu.RLock()
	defer s.mu.RUnlock()

	blocks := make([]*types.Block, 0)
	for h := from; h <= to && h <= s.maxHeight; h++ {
		if heightBlocks, exists := s.heightIndex[h]; exists {
			blocks = append(blocks, heightBlocks...)
		} else {
			// ä»æ•°æ®åº“åŠ è½½
			if dbBlock, err := s.dbManager.GetBlock(h); err == nil && dbBlock != nil {
				block := s.convertDBBlockToTypes(dbBlock)
				if block != nil {
					blocks = append(blocks, block)
				}
			}
		}
	}
	return blocks
}

// GetCurrentHeight è·å–å½“å‰æœ€å¤§é«˜åº¦
func (s *RealBlockStore) GetCurrentHeight() uint64 {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// ä¼˜å…ˆè¿”å›å†…å­˜ä¸­çš„æœ€å¤§é«˜åº¦
	if s.maxHeight > 0 {
		return s.maxHeight
	}

	// ä»æ•°æ®åº“è·å–
	height, _ := s.dbManager.GetLatestBlockHeight()
	return height
}

// è®¾ç½®åŒºå—ä¸ºæœ€ç»ˆåŒ–çŠ¶æ€ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
func (s *RealBlockStore) SetFinalized(height uint64, blockID string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	block, exists := s.blockCache[blockID]
	if !exists {
		// ä»æ•°æ®åº“é€šè¿‡IDåŠ è½½
		if dbBlock, err := s.dbManager.GetBlockByID(blockID); err == nil && dbBlock != nil {
			block = s.convertDBBlockToTypes(dbBlock)
			s.blockCache[blockID] = block
		}
	}

	if block != nil {
		s.finalizedBlocks[height] = block
		s.lastAccepted = block
		s.lastAcceptedHeight = height

		// æ¸…ç†åŒé«˜åº¦å…¶ä»–åŒºå—
		newBlocks := make([]*types.Block, 0, 1)
		for _, b := range s.heightIndex[height] {
			if b.ID == blockID {
				newBlocks = append(newBlocks, b)
			} else {
				delete(s.blockCache, b.ID)
			}
		}
		s.heightIndex[height] = newBlocks

		// æœ€ç»ˆåŒ–åŒºå—ï¼ŒåŒ…å«å…¶äº¤æ˜“
		s.finalizeBlockWithTxs(block)

		logs.Info("[RealBlockStore] Finalized block %s at height %d", blockID, height)
	}
}

// CreateSnapshot åˆ›å»ºå¿«ç…§
func (s *RealBlockStore) CreateSnapshot(height uint64) (*types.Snapshot, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if height > s.lastAcceptedHeight {
		return nil, fmt.Errorf("cannot create snapshot beyond last accepted height")
	}

	snapshot := &types.Snapshot{
		Height:             height,
		Timestamp:          time.Now(),
		FinalizedBlocks:    make(map[uint64]*types.Block),
		LastAcceptedID:     s.lastAccepted.ID,
		LastAcceptedHeight: s.lastAcceptedHeight,
		BlockHashes:        make(map[string]bool),
	}

	// å¤åˆ¶æ‰€æœ‰å·²æœ€ç»ˆåŒ–çš„åŒºå—
	for h := uint64(0); h <= height; h++ {
		if block, exists := s.finalizedBlocks[h]; exists {
			snapshot.FinalizedBlocks[h] = block
			snapshot.BlockHashes[block.ID] = true
		}
	}

	// å­˜å‚¨å¿«ç…§
	s.snapshots[height] = snapshot
	s.snapshotHeights = append(s.snapshotHeights, height)

	// é™åˆ¶å¿«ç…§æ•°é‡
	if len(s.snapshotHeights) > s.maxSnapshots {
		oldestHeight := s.snapshotHeights[0]
		delete(s.snapshots, oldestHeight)
		s.snapshotHeights = s.snapshotHeights[1:]
	}

	// æŒä¹…åŒ–å¿«ç…§åˆ°æ•°æ®åº“
	go s.saveSnapshotToDB(snapshot)

	logs.Info("[RealBlockStore] Created snapshot at height %d", height)

	return snapshot, nil
}

// LoadSnapshot åŠ è½½å¿«ç…§
func (s *RealBlockStore) LoadSnapshot(snapshot *types.Snapshot) error {
	if snapshot == nil {
		return fmt.Errorf("nil snapshot")
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	// æ¸…ç©ºç°æœ‰æ•°æ®
	s.blockCache = make(map[string]*types.Block)
	s.heightIndex = make(map[uint64][]*types.Block)
	s.finalizedBlocks = make(map[uint64]*types.Block)

	// åŠ è½½å¿«ç…§æ•°æ®
	for height, block := range snapshot.FinalizedBlocks {
		s.blockCache[block.ID] = block
		s.heightIndex[height] = []*types.Block{block}
		s.finalizedBlocks[height] = block

		if height > s.maxHeight {
			s.maxHeight = height
		}
	}

	// æ¢å¤æœ€åæ¥å—çš„åŒºå—
	if lastBlock, exists := snapshot.FinalizedBlocks[snapshot.LastAcceptedHeight]; exists {
		s.lastAccepted = lastBlock
		s.lastAcceptedHeight = snapshot.LastAcceptedHeight
	}

	logs.Info("[RealBlockStore] Loaded snapshot at height %d with %d blocks",
		snapshot.Height, len(snapshot.FinalizedBlocks))

	return nil
}

// GetLatestSnapshot è·å–æœ€æ–°å¿«ç…§
func (s *RealBlockStore) GetLatestSnapshot() (*types.Snapshot, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if len(s.snapshotHeights) == 0 {
		return nil, false
	}

	latestHeight := s.snapshotHeights[len(s.snapshotHeights)-1]
	snapshot, exists := s.snapshots[latestHeight]
	return snapshot, exists
}

// GetSnapshotAtHeight è·å–æŒ‡å®šé«˜åº¦æˆ–ä¹‹å‰çš„æœ€è¿‘å¿«ç…§
func (s *RealBlockStore) GetSnapshotAtHeight(height uint64) (*types.Snapshot, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var bestHeight uint64
	found := false

	for i := len(s.snapshotHeights) - 1; i >= 0; i-- {
		if s.snapshotHeights[i] <= height {
			bestHeight = s.snapshotHeights[i]
			found = true
			break
		}
	}

	if !found {
		return nil, false
	}

	snapshot, exists := s.snapshots[bestHeight]
	return snapshot, exists
}

// å†…éƒ¨è¾…åŠ©æ–¹æ³•

func (s *RealBlockStore) validateBlock(block *types.Block) error {
	if block == nil || block.ID == "" {
		return fmt.Errorf("invalid block")
	}
	if block.Height == 0 && block.ID != "genesis" {
		return fmt.Errorf("invalid genesis block")
	}
	if block.Height > 0 && block.ParentID == "" {
		return fmt.Errorf("non-genesis block must have parent")
	}
	return nil
}

func (s *RealBlockStore) saveBlockToDB(block *types.Block) {
	// è·å–ç¼“å­˜çš„å®Œæ•´åŒºå—æ•°æ®
	if cachedBlock, exists := GetCachedBlock(block.ID); exists {
		// ä¿å­˜å®Œæ•´çš„åŒºå—æ•°æ®
		if err := s.dbManager.SaveBlock(cachedBlock); err != nil {
			logs.Error("[RealBlockStore] Failed to save block to DB: %v", err)
		} else {
			logs.Debug("[RealBlockStore] Saved block %s to DB", block.ID)
			s.dbManager.ForceFlush() // ç«‹åˆ»åˆ·ç›˜ï¼Œä¿è¯æœ€ç»ˆåŒ–çš„å—å¯è¢« DB å³æ—¶è¯»å–
		}
	} else {
		// åˆ›å»ºç®€å•çš„æ•°æ®åº“åŒºå—
		dbBlock := &pb.Block{
			Height:        block.Height,
			BlockHash:     block.ID,
			PrevBlockHash: block.ParentID,
			Miner:         fmt.Sprintf(db.KeyNode()+"%d", block.Proposer),
		}
		if err := s.dbManager.SaveBlock(dbBlock); err != nil {
			logs.Error("[RealBlockStore] Failed to save simple block to DB: %v", err)
		}
	}
}

func (s *RealBlockStore) loadFromDB() {
	// åŠ è½½æœ€æ–°é«˜åº¦
	height, err := s.dbManager.GetLatestBlockHeight()
	if err == nil {
		s.maxHeight = height

		// åŠ è½½æœ€è¿‘çš„ä¸€äº›åŒºå—åˆ°ç¼“å­˜
		startHeight := uint64(0)
		if height > 100 {
			startHeight = height - 100
		}

		for h := startHeight; h <= height; h++ {
			if dbBlock, err := s.dbManager.GetBlock(h); err == nil && dbBlock != nil {
				block := s.convertDBBlockToTypes(dbBlock)
				if block != nil {
					s.blockCache[block.ID] = block
					s.heightIndex[h] = []*types.Block{block}
					if h == height {
						s.lastAccepted = block
						s.lastAcceptedHeight = h
					}
				}
			}
		}

		logs.Info("[RealBlockStore] Loaded blocks from DB, latest height: %d", height)
	}
}

func (s *RealBlockStore) convertDBBlockToTypes(dbBlock *pb.Block) *types.Block {
	if s.adapter == nil {
		s.adapter = NewConsensusAdapter(s.dbManager)
	}
	block, err := s.adapter.DBBlockToConsensus(dbBlock)
	if err != nil {
		logs.Error("[RealBlockStore] Failed to convert block: %v", err)
		return nil
	}
	return block
}

func (s *RealBlockStore) finalizeBlockWithTxs(block *types.Block) {
	// è·å–è¯¥åŒºå—åŒ…å«çš„äº¤æ˜“
	if cachedBlock, exists := GetCachedBlock(block.ID); exists {
		// æ›´æ–°äº¤æ˜“çŠ¶æ€
		for _, tx := range cachedBlock.Body {
			base := tx.GetBase()
			if base != nil {
				base.Status = pb.Status_SUCCEED
				base.ExecutedHeight = block.Height

				// æ›´æ–°äº¤æ˜“æ± 
				s.pool.RemoveAnyTx(base.TxId)

				// ä¿å­˜åˆ°æ•°æ®åº“
				if err := s.dbManager.SaveAnyTx(tx); err != nil {
					logs.Error("[RealBlockStore] Failed to save finalized tx %s: %v", base.TxId, err)
				}
			}
		}

		// ä¿å­˜æœ€ç»ˆåŒ–çš„åŒºå—
		if err := s.dbManager.SaveBlock(cachedBlock); err != nil {
			logs.Error("[RealBlockStore] Failed to save finalized block: %v", err)
		}

		logs.Info("[RealBlockStore] Finalized block %s with %d txs", block.ID, len(cachedBlock.Body))
	}
}

func (s *RealBlockStore) saveSnapshotToDB(snapshot *types.Snapshot) {
	// è¿™é‡Œå¯ä»¥å®ç°å¿«ç…§çš„æŒä¹…åŒ–é€»è¾‘
	// ä¾‹å¦‚åºåˆ—åŒ–åä¿å­˜åˆ°æ•°æ®åº“çš„ç‰¹å®šé”®ä¸‹
	key := fmt.Sprintf("snapshot_%d", snapshot.Height)
	data, _ := json.Marshal(snapshot)
	s.dbManager.EnqueueSet(key, string(data))
	logs.Debug("[RealBlockStore] Snapshot saved at height %d", snapshot.Height)
}


æ–‡ä»¶è·¯å¾„: consensus/realManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ConsensusNodeManager ç®¡ç†å…±è¯†èŠ‚ç‚¹çš„å…¨å±€çŠ¶æ€
type ConsensusNodeManager struct {
	mu             sync.RWMutex
	Node           *Node
	engine         interfaces.ConsensusEngine
	store          interfaces.BlockStore
	Transport      interfaces.Transport
	messageHandler *MessageHandler
	queryManager   *QueryManager
	dbManager      *db.Manager
	senderManager  *sender.SenderManager
	adapter        *ConsensusAdapter
	txPool         *txpool.TxPool
}

func InitConsensusManager(
	nodeID types.NodeID,
	dbManager *db.Manager,
	config *Config,
	senderMgr *sender.SenderManager,
	txPool *txpool.TxPool,
) *ConsensusNodeManager {
	// åˆ›å»ºçœŸå®çš„ transport
	transport := NewRealTransport(nodeID, dbManager, senderMgr, context.Background())

	// æ›¿æ¢é»˜è®¤çš„ MemoryBlockStore ä¸º RealBlockStore
	realStore := NewRealBlockStore(dbManager, config.Snapshot.MaxSnapshots, txPool)
	node := NewNode(nodeID, transport, realStore, false, config)

	// é‡æ–°åˆ›å»º engineï¼Œä½¿ç”¨ realStore
	node.engine = NewSnowmanEngine(nodeID, realStore, &config.Consensus, node.events)

	// åˆ›å»ºä½¿ç”¨çœŸå® BlockProposer çš„ ProposalManager
	proposer := NewRealBlockProposer(dbManager, txPool)
	node.proposalManager.SetProposer(proposer)

	// åˆ›å»º ConsensusNodeManager
	consensusManager := &ConsensusNodeManager{
		Node:           node,
		engine:         node.engine,
		store:          node.store,
		Transport:      transport,
		messageHandler: node.messageHandler,
		queryManager:   node.queryManager,
		dbManager:      dbManager,
		senderManager:  senderMgr,
		txPool:         txPool,
		adapter:        NewConsensusAdapter(dbManager),
	}

	logs.Info("[ConsensusManager] Initialized with NodeID %s", nodeID)

	return consensusManager
}

func (m *ConsensusNodeManager) Start() {
	if m.Node != nil {
		m.Node.Start()
		logs.Info("[ConsensusManager] Started consensus engine")
	}
}
func (m *ConsensusNodeManager) GetActiveQueryCount() int {
	if m.engine != nil {
		return m.engine.GetActiveQueryCount()
	}
	return 0
}

// æ·»åŠ æ–°åŒºå—åˆ°å…±è¯†
func (m *ConsensusNodeManager) AddBlock(block *pb.Block) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	// è½¬æ¢ä¸ºtypes.Block
	typesBlock, err := m.adapter.DBBlockToConsensus(block)
	if err != nil {
		return err
	}

	// æ·»åŠ åˆ°å­˜å‚¨
	added, err := m.store.Add(typesBlock)
	if err != nil {
		return err
	}

	if added {
		// è§¦å‘æ–°åŒºå—äº‹ä»¶
		m.Node.events.PublishAsync(types.BaseEvent{
			EventType: types.EventNewBlock,
			EventData: typesBlock,
		})

		logs.Debug("[ConsensusManager] Added new block %s at height %d",
			block.BlockHash, block.Height)
	}

	return nil
}

// GetPreference è·å–æŒ‡å®šé«˜åº¦çš„åå¥½åŒºå—
func (m *ConsensusNodeManager) GetPreference(height uint64) string {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.engine.GetPreference(height)
}

// GetLastAccepted è·å–æœ€åæ¥å—çš„åŒºå—
func (m *ConsensusNodeManager) GetLastAccepted() (string, uint64) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.store.GetLastAccepted()
}

// HasBlock æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡å®šåŒºå—
func (m *ConsensusNodeManager) HasBlock(blockId string) bool {
	m.mu.RLock()
	defer m.mu.RUnlock()
	_, exists := m.store.Get(blockId)
	return exists
}

// StartQuery å‘èµ·æŸ¥è¯¢
func (m *ConsensusNodeManager) StartQuery() {
	m.queryManager.tryIssueQuery()
}

// è·å–èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
func (m *ConsensusNodeManager) GetStats() *NodeStats {
	return m.Node.stats
}

// CreateSnapshot åˆ›å»ºå¿«ç…§
func (m *ConsensusNodeManager) CreateSnapshot(height uint64) error {
	_, err := m.store.CreateSnapshot(height)
	if err != nil {
		return err
	}

	logs.Info("[ConsensusManager] Created snapshot at height %d", height)
	return nil
}

// LoadSnapshot åŠ è½½å¿«ç…§
func (m *ConsensusNodeManager) LoadSnapshot(snapshot *types.Snapshot) error {
	if err := m.store.LoadSnapshot(snapshot); err != nil {
		return err
	}

	logs.Info("[ConsensusManager] Loaded snapshot at height %d", snapshot.Height)
	return nil
}

// GetCurrentHeight è·å–å½“å‰é«˜åº¦
func (m *ConsensusNodeManager) GetCurrentHeight() uint64 {
	return m.store.GetCurrentHeight()
}

// IsReady æ£€æŸ¥å…±è¯†æ˜¯å¦å‡†å¤‡å°±ç»ª
func (m *ConsensusNodeManager) IsReady() bool {
	// æ£€æŸ¥å„ç»„ä»¶æ˜¯å¦å°±ç»ª
	if m.Node == nil || m.engine == nil {
		return false
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¯¹ç­‰èŠ‚ç‚¹
	peers := m.Transport.SamplePeers(m.Node.ID, 1)
	if len(peers) == 0 {
		return false
	}

	return true
}

// åœæ­¢å…±è¯†ç®¡ç†å™¨
func (m *ConsensusNodeManager) Stop() {
	if m.Node != nil {
		m.Node.cancel() // è§¦å‘ä¼˜é›…å…³é—­
		m.Node.Stop()
	}
	logs.Info("[ConsensusManager] Stopped")
}


æ–‡ä»¶è·¯å¾„: consensus/realProposer.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// RealBlockProposer çœŸå®çš„åŒºå—ææ¡ˆè€…å®ç°ï¼Œä»TxPoolè·å–äº¤æ˜“å¹¶ç”ŸæˆåŒºå—
type RealBlockProposer struct {
	maxBlocksPerHeight int
	maxTxsPerBlock     int
	pool               *txpool.TxPool
	dbManager          *db.Manager
}

// NewRealBlockProposer åˆ›å»ºçœŸå®çš„åŒºå—ææ¡ˆè€…
func NewRealBlockProposer(dbManager *db.Manager, pool *txpool.TxPool) interfaces.BlockProposer {
	cfg := config.DefaultConfig()
	return &RealBlockProposer{
		maxBlocksPerHeight: 3,
		maxTxsPerBlock:     cfg.TxPool.MaxTxsPerBlock,
		pool:               pool, // ä½¿ç”¨æ³¨å…¥çš„å®ä¾‹
		dbManager:          dbManager,
	}
}

// ç”ŸæˆåŒ…å«å®é™…äº¤æ˜“çš„åŒºå—
func (p *RealBlockProposer) ProposeBlock(parentID string, height uint64, proposer types.NodeID, round int) (*types.Block, error) {
	// 1. ä»TxPoolè·å–å¾…æ‰“åŒ…çš„äº¤æ˜“
	pendingTxs := p.pool.GetPendingTxs()
	if len(pendingTxs) == 0 {
		logs.Debug("[RealBlockProposer] no txs for height %d, skip", height)
		return nil, nil
	}
	// é™åˆ¶äº¤æ˜“æ•°é‡
	if len(pendingTxs) > p.maxTxsPerBlock {
		pendingTxs = pendingTxs[:p.maxTxsPerBlock]
	}

	// 2. å¯¹äº¤æ˜“è¿›è¡Œæ’åºï¼ˆæŒ‰FBä½™é¢æ’åºï¼‰
	sortedTxs, txsHash, err := txpool.SortTxsByFBBalanceAndComputeHash(p.dbManager, pendingTxs)
	if err != nil {
		logs.Error("[RealBlockProposer] Failed to sort txs: %v", err)
		// å¦‚æœæ’åºå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å“ˆå¸Œ
		txsHash = p.computeSimpleTxsHash(pendingTxs)
		sortedTxs = pendingTxs
	}

	// 3. ç”ŸæˆçŸ­äº¤æ˜“å“ˆå¸Œåˆ—è¡¨ï¼ˆç”¨äºSnowmanå…±è¯†ä¼ è¾“ï¼‰
	shortTxs := p.pool.ConcatFirst8Bytes(sortedTxs)

	// 4. ç”ŸæˆåŒºå—IDï¼ˆç»“åˆé«˜åº¦ã€ææ¡ˆè€…ã€è½®æ¬¡å’Œäº¤æ˜“å“ˆå¸Œï¼‰
	blockID := fmt.Sprintf("block-%d-%s-r%d-%s", height, proposer, round, txsHash[:8])

	// 5. æ„é€ å®é™…çš„åŒºå—
	block := &types.Block{
		ID:       blockID,
		Height:   height,
		ParentID: parentID,
		Data: fmt.Sprintf("Height %d, Proposer %s, Round %d, TxCount %d",
			height, proposer, round, len(sortedTxs)),
		Proposer: string(proposer),
		Round:    round,
	}

	// 6. å°†åŒºå—æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆåŒ…å«äº¤æ˜“ä¿¡æ¯ï¼‰
	dbBlock := &pb.Block{
		Height:        height,
		TxsHash:       txsHash,
		BlockHash:     blockID,
		PrevBlockHash: parentID,
		Miner:         fmt.Sprintf(db.KeyNode()+"%s", proposer),
		Body:          sortedTxs,
		ShortTxs:      shortTxs,
	}

	// ä¸´æ—¶å­˜å‚¨åˆ°å†…å­˜ï¼Œç­‰åŒºå—æœ€ç»ˆåŒ–åå†æŒä¹…åŒ–
	p.cacheBlock(blockID, dbBlock)

	logs.Info("[RealBlockProposer] Proposer:%s Proposed block %s with %d txs at height %d", proposer,
		blockID, len(sortedTxs), height)

	return block, nil
}

// å†³å®šæ˜¯å¦åº”è¯¥åœ¨å½“å‰è½®æ¬¡æå‡ºåŒºå—
func (p *RealBlockProposer) ShouldPropose(nodeID types.NodeID, round int, currentBlocks int, currentHeight int, proposeHeight int) bool {
	// æ–°å¢çš„é«˜åº¦æ£€æŸ¥é€»è¾‘ï¼šå½“å‰é«˜åº¦å¿…é¡»æ˜¯è¦æè®®é«˜åº¦å‡1
	if currentHeight != proposeHeight-1 {
		// å½“å‰é«˜åº¦ä¸æ˜¯ proposeHeight-1ï¼Œä¸å…è®¸æè®®
		logs.Debug("[RealBlockProposer] Height check failed: currentHeight=%d, proposeHeight=%d",
			currentHeight, proposeHeight)
		return false
	}

	// å¦‚æœå½“å‰é«˜åº¦å·²æœ‰è¶³å¤Ÿå¤šçš„åŒºå—ï¼Œä¸å†ææ¡ˆ
	if currentBlocks >= p.maxBlocksPerHeight {
		return false
	}

	// æ£€æŸ¥TxPoolä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¾…å¤„ç†äº¤æ˜“
	pendingCount := len(p.pool.GetPendingAnyTx())
	if pendingCount < 1 { // è‡³å°‘è¦æœ‰1ç¬”äº¤æ˜“æ‰ææ¡ˆ
		return false
	}

	// ä½¿ç”¨è½®æ¬¡å’ŒèŠ‚ç‚¹IDçš„ç»„åˆæ¥å†³å®šæ˜¯å¦ææ¡ˆ
	// è¿™é‡Œå¯ä»¥åŠ å…¥æ›´å¤æ‚çš„é€»è¾‘ï¼Œæ¯”å¦‚åŸºäºstakeçš„æ¦‚ç‡
	proposalProbability := 5 // 5%çš„æ¦‚ç‡

	return int(nodeID.Last2Mod100()+round)%100 < proposalProbability
}

// computeSimpleTxsHash è®¡ç®—ç®€å•çš„äº¤æ˜“å“ˆå¸Œï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
func (p *RealBlockProposer) computeSimpleTxsHash(txs []*pb.AnyTx) string {
	var allBytes []byte
	for _, tx := range txs {
		txID := tx.GetTxId()
		allBytes = append(allBytes, []byte(txID)...)
	}
	hash := utils.Sha256Hash(allBytes)
	return fmt.Sprintf("%x", hash)
}

// cacheBlock ä¸´æ—¶ç¼“å­˜åŒºå—ï¼Œç­‰å¾…æœ€ç»ˆåŒ–
var blockCache = make(map[string]*pb.Block)
var blockCacheMu sync.RWMutex

func (p *RealBlockProposer) cacheBlock(blockID string, block *pb.Block) {
	blockCacheMu.Lock()
	defer blockCacheMu.Unlock()
	blockCache[blockID] = block
}

// GetCachedBlock è·å–ç¼“å­˜çš„åŒºå—
func GetCachedBlock(blockID string) (*pb.Block, bool) {
	blockCacheMu.RLock()
	defer blockCacheMu.RUnlock()
	block, exists := blockCache[blockID]
	return block, exists
}


æ–‡ä»¶è·¯å¾„: consensus/realTransport.go
æ–‡ä»¶å†…å®¹:
// consensus/realTransport.go
package consensus

import (...)

// RealTransport å®ç°åŸºäºHTTP/3çš„çœŸå®ç½‘ç»œä¼ è¾“
type RealTransport struct {
	nodeID        types.NodeID
	address       string
	dbManager     *db.Manager
	ctx           context.Context
	mu            sync.RWMutex
	senderManager *sender.SenderManager
	adapter       *ConsensusAdapter

	inbox          chan types.Message
	receiveQueue   chan types.Message
	receiveWorkers int

	stopOnce sync.Once
	stopChan chan struct{}
	wg       sync.WaitGroup
	Stats    *stats.Stats
}

type NodeInfo struct {
	Address   string
	IP        string // åŒ…å«ç«¯å£çš„å®Œæ•´åœ°å€ï¼Œå¦‚ "127.0.0.1:6000"
	PublicKey string
	LastSeen  time.Time
	Index     uint64 // èŠ‚ç‚¹ç´¢å¼•
}

func NewRealTransport(nodeID types.NodeID, dbMgr *db.Manager, senderMgr *sender.SenderManager, ctx context.Context) interfaces.Transport {
	keyMgr := utils.GetKeyManager()
	rt := &RealTransport{
		nodeID:         nodeID,
		address:        keyMgr.GetAddress(),
		inbox:          make(chan types.Message, 100000),
		receiveQueue:   make(chan types.Message, 100000),
		receiveWorkers: 1000,
		dbManager:      dbMgr,
		senderManager:  senderMgr,
		ctx:            ctx,
		adapter:        NewConsensusAdapter(dbMgr),
		stopChan:       make(chan struct{}),
		Stats:          stats.NewStats(),
	}

	rt.startReceiveWorkers()
	return rt
}

// å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šèŠ‚ç‚¹
func (t *RealTransport) Send(to types.NodeID, msg types.Message) error {
	t.Stats.RecordAPICall(string(msg.Type))
	targetIP, err := t.getNodeIP(to)
	if err != nil {
		logs.Debug("[RealTransport] Failed to get IP for node %s: %v", to, err)
		return err
	}

	switch msg.Type {
	case types.MsgPushQuery:
		return t.sendPushQuery(targetIP, msg)
	case types.MsgPullQuery:
		return t.sendPullQuery(targetIP, msg)
	case types.MsgChits:
		return t.sendChits(targetIP, msg)
	case types.MsgGet:
		return t.sendGet(targetIP, msg)
	case types.MsgPut:
		return t.sendBlock(targetIP, msg)
	case types.MsgGossip:
		return t.sendGossip(targetIP, msg)
	case types.MsgSyncRequest:
		return t.sendSyncRequest(targetIP, msg)
	case types.MsgHeightQuery:
		return t.sendHeightQuery(targetIP, msg)
	case types.MsgSnapshotRequest:
		return t.sendSnapshotRequest(targetIP, msg)
	default:
		return fmt.Errorf("unknown message type: %v", msg.Type)
	}
}

func (t *RealTransport) getNodeIP(nodeID types.NodeID) (string, error) {
	acc, err := t.dbManager.GetAccount(string(nodeID))
	if err != nil || acc == nil || acc.Ip == "" {
		return "", fmt.Errorf("no IP for address %s", nodeID)
	}
	return acc.Ip, nil
}

// sendPushQuery ä½¿ç”¨senderManagerå‘é€
func (t *RealTransport) sendPushQuery(targetIP string, msg types.Message) error {
	pq, err := t.adapter.ConsensusMessageToPushQuery(msg, t.address)
	if err != nil {
		return fmt.Errorf("failed to convert message to PushQuery: %v", err)
	}

	t.senderManager.PushQuery(targetIP, pq)

	return nil
}

// ä½¿ç”¨senderManagerå‘é€
func (t *RealTransport) sendPullQuery(targetIP string, msg types.Message) error {
	pq := &pb.PullQuery{
		RequestId:       msg.RequestID,
		Address:         t.address,
		Deadline:        t.adapter.calculateDeadline(3),
		BlockId:         msg.BlockID,
		RequestedHeight: msg.Height,
	}

	t.senderManager.PullQuery(targetIP, pq)

	return nil
}

func (t *RealTransport) sendChits(targetIP string, msg types.Message) error {
	chits := t.adapter.ConsensusMessageToChits(msg)
	return t.senderManager.SendChits(targetIP, chits)
}

func (t *RealTransport) sendGet(targetIP string, msg types.Message) error {
	// ä½¿ç”¨æ–°çš„PullBlockByIDæ–¹æ³•
	t.senderManager.PullGet(targetIP, msg.BlockID, func(block *pb.Block) {
		if block != nil {
			// è½¬æ¢ä¸ºtypes.Block
			consensusBlock, err := t.adapter.DBBlockToConsensus(block)
			if err != nil {
				logs.Error("[RealTransport] Failed to convert block: %v", err)
				return
			}

			// æ„é€ Putæ¶ˆæ¯å“åº”
			putMsg := types.Message{
				RequestID: msg.RequestID,
				Type:      types.MsgPut,
				From:      t.nodeID,
				Block:     consensusBlock,
				Height:    consensusBlock.Height,
				BlockID:   consensusBlock.ID,
			}

			// å°†æ¶ˆæ¯æ”¾å…¥æ¥æ”¶é˜Ÿåˆ—
			if err := t.EnqueueReceivedMessage(putMsg); err != nil {
				logs.Debug("[RealTransport] Failed to enqueue Put message: %v", err)
			}

			logs.Debug("[RealTransport] Received block %s from %s", block.BlockHash, targetIP)
		}
	})
	return nil
}

func (t *RealTransport) sendBlock(targetIP string, msg types.Message) error {
	if msg.Block == nil {
		return fmt.Errorf("no block data to send")
	}

	dbBlock := t.adapter.ConsensusBlockToDB(msg.Block, nil)
	return t.senderManager.SendBlock(targetIP, dbBlock)
}

// ä¸€ä¸ªä¸“é—¨ç”¨äº Gossip ä¼ è¾“çš„ç±»å‹

func (t *RealTransport) sendGossip(targetIP string, msg types.Message) error {
	if msg.Block == nil {
		return fmt.Errorf("no block data to send")
	}

	payload := &types.GossipPayload{
		Block:     t.adapter.ConsensusBlockToDB(msg.Block, nil),
		RequestID: msg.RequestID,
	}
	return t.senderManager.BroadcastGossipToTarget(targetIP, payload)
}
func (t *RealTransport) sendSyncRequest(targetIP string, msg types.Message) error {
	for h := msg.FromHeight; h <= msg.ToHeight; h++ {
		t.senderManager.PullBlock(targetIP, h, func(dbBlock *pb.Block) {
			block, err := t.adapter.DBBlockToConsensus(dbBlock)
			if err != nil {
				logs.Error("[RealTransport] Failed to convert DB block: %v", err)
				return
			}

			t.inbox <- types.Message{
				Type:   types.MsgSyncResponse,
				From:   msg.From,
				Blocks: []*types.Block{block},
			}
		})
	}
	return nil
}

func (t *RealTransport) sendHeightQuery(targetIP string, msg types.Message) error {
	return t.senderManager.SendHeightQuery(targetIP, func(resp *pb.HeightResponse) {
		t.inbox <- types.Message{
			Type:          types.MsgHeightResponse,
			From:          msg.From,
			Height:        resp.LastAcceptedHeight,
			CurrentHeight: resp.CurrentHeight,
		}
	})
}

func (t *RealTransport) sendSnapshotRequest(targetIP string, msg types.Message) error {
	t.senderManager.PullBlock(targetIP, msg.Height, func(block *pb.Block) {
		logs.Info("[RealTransport] Received snapshot at height %d", block.Height)
	})
	return nil
}
func (t *RealTransport) GetReceiveQueueLen() int {
	return len(t.receiveQueue)
}
func (t *RealTransport) EnqueueReceivedMessage(msg types.Message) error {
	// æ ¹æ®æ¶ˆæ¯ç±»å‹åˆ¤æ–­ä¼˜å…ˆçº§
	isControlMessage := false
	switch msg.Type {
	case types.MsgPushQuery, types.MsgPullQuery, types.MsgChits:
		isControlMessage = true
	}

	if isControlMessage {
		// æ§åˆ¶é¢æ¶ˆæ¯ï¼šçŸ­æš‚ç­‰å¾…
		select {
		case t.receiveQueue <- msg:
			return nil
		case <-time.After(50 * time.Millisecond):
			logs.Warn("[RealTransport] Control message queue full, dropping from %s", msg.From)
			return fmt.Errorf("receive queue full for control message")
		}
	} else {
		// æ•°æ®é¢æ¶ˆæ¯ï¼šéé˜»å¡
		select {
		case t.receiveQueue <- msg:
			return nil
		default:
			logs.Debug("[RealTransport] Data message queue full, dropping from %s", msg.From)
			return fmt.Errorf("receive queue full for data message")
		}
	}
}

func (t *RealTransport) Receive() <-chan types.Message {
	return t.inbox
}

func (t *RealTransport) Broadcast(msg types.Message, peers []types.NodeID) {
	for _, peer := range peers {
		go func(p types.NodeID) {
			if err := t.Send(p, msg); err != nil {
				logs.Debug("[RealTransport] Failed to send to peer %s: %v", p, err)
			}
		}(peer)
	}
}

func (t *RealTransport) SamplePeers(exclude types.NodeID, count int) []types.NodeID {
	miners, err := t.dbManager.GetRandomMinersFast(count + 1)
	if err != nil {
		logs.Error("[RealTransport] Failed to get random miners: %v", err)
		return nil
	}

	peers := make([]types.NodeID, 0, count)
	for _, m := range miners {
		id := types.NodeID(m.Address)
		if id == exclude {
			continue
		}
		peers = append(peers, id)
		if len(peers) >= count {
			break
		}
	}
	return peers
}

func (t *RealTransport) startReceiveWorkers() {
	for i := 0; i < t.receiveWorkers; i++ {
		t.wg.Add(1)
		go t.receiveWorker(i)
	}

	logs.Info("[RealTransport] Started %d receive workers", t.receiveWorkers)
}

func (t *RealTransport) receiveWorker(workerID int) {
	defer t.wg.Done()

	for {
		select {
		case <-t.stopChan:
			return
		case msg := <-t.receiveQueue:
			if err := t.preprocessMessage(&msg); err != nil {
				logs.Debug("[RealTransport] Worker %d: Invalid message from %s: %v",
					workerID, msg.From, err)
				continue
			}

			select {
			case t.inbox <- msg:
				logs.Trace("[RealTransport] Worker %d: Processed message type %d from %s",
					workerID, msg.Type, msg.From)
			case <-time.After(5 * time.Second):
				logs.Warn("[RealTransport] Worker %d: Timeout sending to inbox, dropping message from %s",
					workerID, msg.From)
			case <-t.stopChan:
				return
			}
		}
	}
}

func (t *RealTransport) preprocessMessage(msg *types.Message) error {
	if msg == nil {
		return fmt.Errorf("nil message")
	}
	if msg.From == "" {
		return fmt.Errorf("empty sender ID")
	}
	return nil
}

func (t *RealTransport) Close() {
	t.stopOnce.Do(func() {
		close(t.stopChan)
		t.wg.Wait()
		close(t.receiveQueue)
		close(t.inbox)
		logs.Info("[RealTransport] Closed")
	})
}


æ–‡ä»¶è·¯å¾„: consensus/simulatedBlockStore.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// åŒºå—å­˜å‚¨æ¥å£ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒå¿«ç…§ï¼‰
// ============================================

type MemoryBlockStore struct {
	mu                 sync.RWMutex
	blocks             map[string]*types.Block
	heightIndex        map[uint64][]*types.Block
	lastAccepted       *types.Block
	lastAcceptedHeight uint64
	finalizedBlocks    map[uint64]*types.Block
	maxHeight          uint64

	// å¿«ç…§ç›¸å…³
	snapshots       map[uint64]*types.Snapshot
	snapshotHeights []uint64 // æœ‰åºçš„å¿«ç…§é«˜åº¦åˆ—è¡¨
	maxSnapshots    int
}

func NewMemoryBlockStore() interfaces.BlockStore {
	return NewMemoryBlockStoreWithConfig(10)
}

func NewMemoryBlockStoreWithConfig(maxSnapshots int) interfaces.BlockStore {
	store := &MemoryBlockStore{
		blocks:          make(map[string]*types.Block),
		heightIndex:     make(map[uint64][]*types.Block),
		finalizedBlocks: make(map[uint64]*types.Block),
		maxHeight:       0,
		snapshots:       make(map[uint64]*types.Snapshot),
		snapshotHeights: make([]uint64, 0),
		maxSnapshots:    maxSnapshots,
	}

	// åˆ›ä¸–åŒºå—
	genesis := &types.Block{
		ID:       "genesis",
		Height:   0,
		ParentID: "",
		Proposer: "-1",
	}
	store.blocks[genesis.ID] = genesis
	store.heightIndex[0] = []*types.Block{genesis}
	store.lastAccepted = genesis
	store.lastAcceptedHeight = 0
	store.finalizedBlocks[0] = genesis
	store.maxHeight = 0

	return store
}

func (s *MemoryBlockStore) Add(block *types.Block) (bool, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if _, exists := s.blocks[block.ID]; exists {
		return false, nil
	}

	if err := s.validateBlock(block); err != nil {
		return false, err
	}

	s.blocks[block.ID] = block
	s.heightIndex[block.Height] = append(s.heightIndex[block.Height], block)

	if block.Height > s.maxHeight {
		s.maxHeight = block.Height
	}

	return true, nil
}

func (s *MemoryBlockStore) validateBlock(block *types.Block) error {
	if block == nil || block.ID == "" {
		return fmt.Errorf("invalid block")
	}
	if block.Height == 0 && block.ID != "genesis" {
		return fmt.Errorf("invalid genesis block")
	}
	if block.Height > 0 && block.ParentID == "" {
		return fmt.Errorf("non-genesis block must have parent")
	}
	return nil
}

func (s *MemoryBlockStore) Get(id string) (*types.Block, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	block, exists := s.blocks[id]
	return block, exists
}

func (s *MemoryBlockStore) GetByHeight(height uint64) []*types.Block {
	s.mu.RLock()
	defer s.mu.RUnlock()
	blocks := s.heightIndex[height]
	result := make([]*types.Block, len(blocks))
	copy(result, blocks)
	return result
}

func (s *MemoryBlockStore) GetLastAccepted() (string, uint64) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.lastAccepted.ID, s.lastAcceptedHeight
}

func (s *MemoryBlockStore) GetFinalizedAtHeight(height uint64) (*types.Block, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	block, exists := s.finalizedBlocks[height]
	return block, exists
}

func (s *MemoryBlockStore) GetBlocksFromHeight(from, to uint64) []*types.Block {
	s.mu.RLock()
	defer s.mu.RUnlock()

	blocks := make([]*types.Block, 0)
	for h := from; h <= to && h <= s.maxHeight; h++ {
		if heightBlocks, exists := s.heightIndex[h]; exists {
			blocks = append(blocks, heightBlocks...)
		}
	}
	return blocks
}

func (s *MemoryBlockStore) GetCurrentHeight() uint64 {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.maxHeight
}

func (s *MemoryBlockStore) SetFinalized(height uint64, blockID string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if block, exists := s.blocks[blockID]; exists {
		s.finalizedBlocks[height] = block
		s.lastAccepted = block
		s.lastAcceptedHeight = height

		// æ¸…ç†åŒé«˜åº¦å…¶ä»–åŒºå—
		newBlocks := make([]*types.Block, 0, 1)
		for _, b := range s.heightIndex[height] {
			if b.ID == blockID {
				newBlocks = append(newBlocks, b)
			} else {
				delete(s.blocks, b.ID)
			}
		}
		s.heightIndex[height] = newBlocks
	}
}

// åˆ›å»ºå¿«ç…§
func (s *MemoryBlockStore) CreateSnapshot(height uint64) (*types.Snapshot, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	// åªåœ¨å·²æœ€ç»ˆåŒ–çš„é«˜åº¦åˆ›å»ºå¿«ç…§
	if height > s.lastAcceptedHeight {
		return nil, fmt.Errorf("cannot create snapshot beyond last accepted height")
	}

	snapshot := &types.Snapshot{
		Height:             height,
		Timestamp:          time.Now(),
		FinalizedBlocks:    make(map[uint64]*types.Block),
		LastAcceptedID:     s.lastAccepted.ID,
		LastAcceptedHeight: s.lastAcceptedHeight,
		BlockHashes:        make(map[string]bool),
	}

	// å¤åˆ¶æ‰€æœ‰å·²æœ€ç»ˆåŒ–çš„åŒºå—ï¼ˆåˆ°æŒ‡å®šé«˜åº¦ï¼‰
	for h := uint64(0); h <= height; h++ {
		if block, exists := s.finalizedBlocks[h]; exists {
			snapshot.FinalizedBlocks[h] = block
			snapshot.BlockHashes[block.ID] = true
		}
	}

	// å­˜å‚¨å¿«ç…§
	s.snapshots[height] = snapshot
	s.snapshotHeights = append(s.snapshotHeights, height)
	sort.Slice(s.snapshotHeights, func(i, j int) bool {
		return s.snapshotHeights[i] < s.snapshotHeights[j]
	})

	// é™åˆ¶å¿«ç…§æ•°é‡
	if len(s.snapshotHeights) > s.maxSnapshots {
		oldestHeight := s.snapshotHeights[0]
		delete(s.snapshots, oldestHeight)
		s.snapshotHeights = s.snapshotHeights[1:]
	}

	return snapshot, nil
}

// åŠ è½½å¿«ç…§ï¼ˆæ–°å¢ï¼‰
func (s *MemoryBlockStore) LoadSnapshot(snapshot *types.Snapshot) error {
	if snapshot == nil {
		return fmt.Errorf("nil snapshot")
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	// æ¸…ç©ºç°æœ‰æ•°æ®
	s.blocks = make(map[string]*types.Block)
	s.heightIndex = make(map[uint64][]*types.Block)
	s.finalizedBlocks = make(map[uint64]*types.Block)

	// åŠ è½½å¿«ç…§æ•°æ®
	for height, block := range snapshot.FinalizedBlocks {
		s.blocks[block.ID] = block
		s.heightIndex[height] = []*types.Block{block}
		s.finalizedBlocks[height] = block

		if height > s.maxHeight {
			s.maxHeight = height
		}
	}

	// æ¢å¤æœ€åæ¥å—çš„åŒºå—
	if lastBlock, exists := snapshot.FinalizedBlocks[snapshot.LastAcceptedHeight]; exists {
		s.lastAccepted = lastBlock
		s.lastAcceptedHeight = snapshot.LastAcceptedHeight
	}

	Logf("[Store] Loaded snapshot at height %d with %d blocks\n",
		snapshot.Height, len(snapshot.FinalizedBlocks))

	return nil
}

// è·å–æœ€æ–°å¿«ç…§ï¼ˆæ–°å¢ï¼‰
func (s *MemoryBlockStore) GetLatestSnapshot() (*types.Snapshot, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if len(s.snapshotHeights) == 0 {
		return nil, false
	}

	latestHeight := s.snapshotHeights[len(s.snapshotHeights)-1]
	snapshot, exists := s.snapshots[latestHeight]
	return snapshot, exists
}

// è·å–æŒ‡å®šé«˜åº¦æˆ–ä¹‹å‰çš„æœ€è¿‘å¿«ç…§ï¼ˆæ–°å¢ï¼‰
func (s *MemoryBlockStore) GetSnapshotAtHeight(height uint64) (*types.Snapshot, bool) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// æ‰¾åˆ°å°äºç­‰äºæŒ‡å®šé«˜åº¦çš„æœ€å¤§å¿«ç…§é«˜åº¦
	var bestHeight uint64
	found := false

	for i := len(s.snapshotHeights) - 1; i >= 0; i-- {
		if s.snapshotHeights[i] <= height {
			bestHeight = s.snapshotHeights[i]
			found = true
			break
		}
	}

	if !found {
		return nil, false
	}

	snapshot, exists := s.snapshots[bestHeight]
	return snapshot, exists
}


æ–‡ä»¶è·¯å¾„: consensus/simulatedManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// ç½‘ç»œç®¡ç†å™¨
// ============================================

type NetworkManager struct {
	nodes      map[types.NodeID]*Node
	transports map[types.NodeID]interfaces.Transport
	config     *Config
	startTime  time.Time
	mu         sync.RWMutex
}

func NewNetworkManager(config *Config) *NetworkManager {
	return &NetworkManager{
		nodes:      make(map[types.NodeID]*Node),
		transports: make(map[types.NodeID]interfaces.Transport),
		config:     config,
	}
}

func (nm *NetworkManager) CreateNodes() {
	byzantineMap := make(map[types.NodeID]bool)
	indices := rand.Perm(nm.config.Network.NumNodes)
	for i := 0; i < nm.config.Network.NumByzantineNodes; i++ {
		byzantineMap[types.NodeID(indices[i])] = true
	}

	ctx := context.Background()
	for i := 0; i < nm.config.Network.NumNodes; i++ {
		nodeID := types.NodeID(strconv.Itoa(i))
		transport := NewSimulatedTransport(nodeID, nm, ctx, nm.config.Network.NetworkLatency)
		nm.transports[nodeID] = transport
	}

	for i := 0; i < nm.config.Network.NumNodes; i++ {
		nodeID := types.NodeID(strconv.Itoa(i))
		// ä¸ºæ¨¡æ‹Ÿåœºæ™¯åˆ›å»º MemoryBlockStore
		store := NewMemoryBlockStoreWithConfig(nm.config.Snapshot.MaxSnapshots)
		node := NewNode(nodeID, nm.transports[nodeID], store, byzantineMap[nodeID], nm.config)
		nm.nodes[nodeID] = node
	}
}

func (nm *NetworkManager) GetTransport(nodeID types.NodeID) interfaces.Transport {
	nm.mu.RLock()
	defer nm.mu.RUnlock()
	return nm.transports[nodeID]
}

func (nm *NetworkManager) SamplePeers(exclude types.NodeID, count int) []types.NodeID {
	nm.mu.RLock()
	defer nm.mu.RUnlock()

	peers := make([]types.NodeID, 0, len(nm.nodes)-1)
	for id := range nm.nodes {
		if id != exclude {
			peers = append(peers, id)
		}
	}

	rand.Shuffle(len(peers), func(i, j int) {
		peers[i], peers[j] = peers[j], peers[i]
	})

	if count > len(peers) {
		count = len(peers)
	}

	return peers[:count]
}

func (nm *NetworkManager) Start() {
	nm.startTime = time.Now()
	for _, node := range nm.nodes {
		node.Start()
	}
}

func (nm *NetworkManager) CheckProgress() (minHeight uint64, allDone bool) {
	minHeight = ^uint64(0)
	honestCount := 0

	for _, node := range nm.nodes {
		if !node.IsByzantine {
			honestCount++
			_, height := node.store.GetLastAccepted()
			if height < minHeight {
				minHeight = height
			}
		}
	}

	allDone = minHeight >= uint64(nm.config.Consensus.NumHeights)
	return minHeight, allDone
}

func (nm *NetworkManager) PrintStatus() {
	fmt.Println("\n===== Network Status =====")
	consensusMap := make(map[uint64]map[string]int)

	for id, node := range nm.nodes {
		lastAccepted, lastHeight := node.store.GetLastAccepted()
		currentHeight := node.store.GetCurrentHeight()

		nodeType := "Honest"
		if node.IsByzantine {
			nodeType = "Byzantine"
		}

		Logf("Node %d (%s): LastAccepted=%d, Current=%d, Block=%s\n",
			id, nodeType, lastHeight, currentHeight, lastAccepted)

		if lastHeight > 0 {
			if consensusMap[lastHeight] == nil {
				consensusMap[lastHeight] = make(map[string]int)
			}
			consensusMap[lastHeight][lastAccepted]++
		}
	}

	fmt.Println("\n--- Consensus by Height ---")
	for height := uint64(1); height <= uint64(nm.config.Consensus.NumHeights); height++ {
		if blocks, exists := consensusMap[height]; exists {
			Logf("Height %d: ", height)
			for blockID, count := range blocks {
				fmt.Printf("%s(%d nodes) ", blockID, count)
			}
			fmt.Println()
		}
	}
}

func (nm *NetworkManager) PrintFinalResults() {
	chains := make(map[types.NodeID][]string)

	for id, node := range nm.nodes {
		chain := make([]string, 0, nm.config.Consensus.NumHeights)
		for h := uint64(1); h <= uint64(nm.config.Consensus.NumHeights); h++ {
			if b, ok := node.store.GetFinalizedAtHeight(h); ok {
				chain = append(chain, b.ID)
			} else {
				chain = append(chain, "<none>")
			}
		}
		chains[id] = chain
	}

	allEqual := true
	var refChain []string
	for _, chain := range chains {
		if refChain == nil {
			refChain = chain
		} else {
			for i := range chain {
				if chain[i] != refChain[i] {
					allEqual = false
					break
				}
			}
		}
		if !allEqual {
			break
		}
	}

	fmt.Println("\n--- Global Agreement Check ---")
	if allEqual {
		Logf("All nodes have identical finalized chains: âœ… YES\n")
		fmt.Println("Consensus chain:")
		fmt.Println(strings.Join(refChain, " -> "))
	} else {
		Logf("All nodes have identical finalized chains: âŒ NO\n")
		for id, chain := range chains {
			nodeType := "Honest"
			if nm.nodes[id].IsByzantine {
				nodeType = "Byzantine"
			}
			Logf("Node %3d (%s): %s\n", id, nodeType, strings.Join(chain, " -> "))
		}
	}

	nm.PrintQueryStatistics()
}

func (nm *NetworkManager) PrintQueryStatistics() {
	fmt.Println("\n--- Query & Sync Statistics ---")

	totalQueriesSent := uint32(0)
	totalQueriesReceived := uint32(0)
	totalChitsResponded := uint32(0)
	totalGossipsReceived := uint32(0)
	totalBlocksProposed := uint32(0)
	totalSnapshotsUsed := uint32(0)   // æ–°å¢
	totalSnapshotsServed := uint32(0) // æ–°å¢

	queriesByHeight := make(map[uint64]uint32)

	honestNodeCount := 0
	for _, node := range nm.nodes {
		if node.IsByzantine {
			continue
		}
		honestNodeCount++

		node.stats.Mu.Lock()
		totalQueriesSent += node.stats.QueriesSent
		totalQueriesReceived += node.stats.QueriesReceived
		totalChitsResponded += node.stats.ChitsResponded
		totalGossipsReceived += node.stats.GossipsReceived
		totalBlocksProposed += node.stats.BlocksProposed
		totalSnapshotsUsed += node.stats.SnapshotsUsed
		totalSnapshotsServed += node.stats.SnapshotsServed

		for height, count := range node.stats.QueriesPerHeight {
			queriesByHeight[height] += count
		}
		node.stats.Mu.Unlock()
	}

	if honestNodeCount > 0 {
		avgQueriesSent := float64(totalQueriesSent) / float64(honestNodeCount)
		avgQueriesReceived := float64(totalQueriesReceived) / float64(honestNodeCount)
		avgChitsResponded := float64(totalChitsResponded) / float64(honestNodeCount)

		Logf("Average queries sent per honest node: %.2f\n", avgQueriesSent)
		Logf("Average queries received per honest node: %.2f\n", avgQueriesReceived)
		Logf("Average chits responded per honest node: %.2f\n", avgChitsResponded)
		Logf("Total blocks proposed: %d\n", totalBlocksProposed)
		Logf("Total gossips received: %d\n", totalGossipsReceived)

		// æ–°å¢å¿«ç…§ç»Ÿè®¡
		if nm.config.Snapshot.Enabled {
			Logf("\n--- Snapshot Statistics ---\n")
			Logf("Total snapshots used: %d\n", totalSnapshotsUsed)
			Logf("Total snapshots served: %d\n", totalSnapshotsServed)
		}

		fmt.Println("\nQueries per height (total across all honest nodes):")
		for h := uint64(1); h <= uint64(nm.config.Consensus.NumHeights); h++ {
			if count, exists := queriesByHeight[h]; exists {
				avgPerNode := float64(count) / float64(honestNodeCount)
				Logf("  Height %d: %d total queries (%.2f avg per node)\n", h, count, avgPerNode)
			}
		}

		totalHeightQueries := uint32(0)
		for _, count := range queriesByHeight {
			totalHeightQueries += count
		}
		if nm.config.Consensus.NumHeights > 0 {
			avgQueriesPerHeight := float64(totalHeightQueries) / float64(nm.config.Consensus.NumHeights)
			Logf("\nAverage queries per height (all nodes): %.2f\n", avgQueriesPerHeight)
			avgQueriesPerHeightPerNode := avgQueriesPerHeight / float64(honestNodeCount)
			Logf("Average queries per height per node: %.2f\n", avgQueriesPerHeightPerNode)
		}
	}
}


æ–‡ä»¶è·¯å¾„: consensus/simulatedProposer.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// DefaultBlockProposer é»˜è®¤çš„åŒºå—ææ¡ˆè€…å®ç°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
type DefaultBlockProposer struct {
	maxBlocksPerHeight int
	proposalDenom      int
}

func NewDefaultBlockProposer() interfaces.BlockProposer {
	return &DefaultBlockProposer{
		maxBlocksPerHeight: 3,
		proposalDenom:      33,
	}
}

func (p *DefaultBlockProposer) ProposeBlock(parentID string, height uint64, proposer types.NodeID, round int) (*types.Block, error) {
	blockID := fmt.Sprintf("block-%d-%d-r%d", height, proposer, round)
	block := &types.Block{
		ID:       blockID,
		Height:   height,
		ParentID: parentID,
		Data:     fmt.Sprintf("Height %d, Proposer %d, Round %d", height, proposer, round),
		Proposer: string(proposer),
		Round:    round,
	}
	return block, nil
}

func (p *DefaultBlockProposer) ShouldPropose(nodeID types.NodeID, round int, currentBlocks int, currentHeight int, proposeHeight int) bool {
	// æ–°å¢çš„é«˜åº¦æ£€æŸ¥é€»è¾‘ï¼šå½“å‰é«˜åº¦å¿…é¡»æ˜¯è¦æè®®é«˜åº¦å‡1
	if currentHeight != proposeHeight-1 {
		// å½“å‰é«˜åº¦ä¸æ˜¯ proposeHeight-1ï¼Œä¸å…è®¸æè®®
		return false
	}

	// å¦‚æœå½“å‰é«˜åº¦å·²æœ‰è¶³å¤Ÿå¤šçš„åŒºå—ï¼Œä¸å†ææ¡ˆ
	if currentBlocks >= p.maxBlocksPerHeight {
		return false
	}

	// ä½¿ç”¨åŸæœ‰çš„éšæœºé€‰æ‹©é€»è¾‘
	denom := p.proposalDenom
	if denom <= 0 {
		denom = 1
	}

	return int(nodeID.Last2Mod100()+round)%denom == 0
}


æ–‡ä»¶è·¯å¾„: consensus/simulatedTransport.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

type SimulatedTransport struct {
	nodeID         types.NodeID
	inbox          chan types.Message
	network        *NetworkManager
	ctx            context.Context
	networkLatency time.Duration
	packetLossRate float64 // ä¸¢åŒ…ç‡
}

func NewSimulatedTransport(nodeID types.NodeID, network *NetworkManager, ctx context.Context, latency time.Duration) interfaces.Transport {
	return &SimulatedTransport{
		nodeID:         nodeID,
		inbox:          make(chan types.Message, 10000),
		network:        network,
		ctx:            ctx,
		networkLatency: latency,
		packetLossRate: network.config.Network.PacketLossRate, // è®¾ç½®ä¸¢åŒ…ç‡
	}
}

func (t *SimulatedTransport) Send(to types.NodeID, msg types.Message) error {
	// æ¨¡æ‹Ÿç½‘ç»œä¸¢åŒ…
	if rand.Float64() < t.packetLossRate {
		// ä¸¢åŒ…äº†ï¼Œç›´æ¥è¿”å›ï¼Œä¸å‘é€æ¶ˆæ¯
		// å¯ä»¥é€‰æ‹©è®°å½•æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
		// Logf("[Network] Packet dropped: %s -> %s, MsgType=%v\n", t.nodeID, to, msg.Type)
		return nil // è¿”å›nilè¡¨ç¤º"å‘é€æˆåŠŸ"ï¼ˆå‘é€æ–¹ä¸çŸ¥é“ä¸¢åŒ…ï¼‰
	}
	go func() {
		// å¿«ç…§ä¼ è¾“å»¶è¿Ÿæ›´é•¿
		delay := t.networkLatency
		if msg.Type == types.MsgSnapshotResponse && msg.Snapshot != nil {
			delay = delay * 3 // å¿«ç…§æ•°æ®æ›´å¤§ï¼Œä¼ è¾“æ—¶é—´æ›´é•¿
		}
		delay += time.Duration(rand.Intn(int(delay / 2)))
		time.Sleep(delay)

		select {
		case t.network.GetTransport(to).(*SimulatedTransport).inbox <- msg:
		case <-time.After(100 * time.Millisecond):
		case <-t.ctx.Done():
		}
	}()
	return nil
}

func (t *SimulatedTransport) Receive() <-chan types.Message {
	return t.inbox
}

func (t *SimulatedTransport) Broadcast(msg types.Message, peers []types.NodeID) {
	for _, peer := range peers {
		t.Send(peer, msg)
	}
}

func (t *SimulatedTransport) SamplePeers(exclude types.NodeID, count int) []types.NodeID {
	return t.network.SamplePeers(exclude, count)
}


æ–‡ä»¶è·¯å¾„: consensus/snapshotManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// å¿«ç…§ç®¡ç†å™¨
// ============================================

type SnapshotManager struct {
	nodeID types.NodeID
	store  interfaces.BlockStore
	config *SnapshotConfig
	events interfaces.EventBus
	mu     sync.Mutex
}

func NewSnapshotManager(nodeID types.NodeID, store interfaces.BlockStore, config *SnapshotConfig, events interfaces.EventBus) *SnapshotManager {
	return &SnapshotManager{
		nodeID: nodeID,
		store:  store,
		config: config,
		events: events,
	}
}

func (sm *SnapshotManager) Start(ctx context.Context) {
	if !sm.config.Enabled {
		return
	}

	// ç›‘å¬åŒºå—æœ€ç»ˆåŒ–äº‹ä»¶ï¼Œå®šæœŸåˆ›å»ºå¿«ç…§
	sm.events.Subscribe(types.EventBlockFinalized, func(e interfaces.Event) {
		if block, ok := e.Data().(*types.Block); ok {
			sm.checkAndCreateSnapshot(block.Height)
		}
	})
}

func (sm *SnapshotManager) checkAndCreateSnapshot(height uint64) {
	sm.mu.Lock()
	defer sm.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦åˆ°äº†åˆ›å»ºå¿«ç…§çš„é«˜åº¦
	if height > 0 && height%sm.config.Interval == 0 {
		snapshot, err := sm.store.CreateSnapshot(height)
		if err != nil {
			Logf("[Node %d] Failed to create snapshot at height %d: %v\n",
				sm.nodeID, height, err)
			return
		}

		Logf("[Node %d] ğŸ“¸ Created snapshot at height %d\n", sm.nodeID, height)

		sm.events.PublishAsync(types.BaseEvent{
			EventType: types.EventSnapshotCreated,
			EventData: snapshot,
		})
	}
}


æ–‡ä»¶è·¯å¾„: consensus/snowball.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// Snowball å…±è¯†ç®—æ³•æ ¸å¿ƒ
// ============================================

type Snowball struct {
	mu         sync.RWMutex
	preference string
	confidence int
	finalized  bool
	events     interfaces.EventBus
	lastVotes  map[string]int // å¯¹åº”åŒºå—è¿™ä¸€è½®æœ‰å¤šå°‘èµæˆ
}

func NewSnowball(events interfaces.EventBus) *Snowball {
	return &Snowball{
		events:    events,
		lastVotes: make(map[string]int),
	}
}

type PreferenceChangedData struct {
	BlockId    string // "success" | "timeout"
	Confidence int    // ç»“æŸçš„æŸ¥è¯¢é”®ï¼ˆå¯é€‰ï¼‰
}

func (sb *Snowball) RecordVote(candidates []string, votes map[string]int, alpha int) {
	sb.mu.Lock()
	defer sb.mu.Unlock()

	sb.lastVotes = votes

	var winner string
	maxVotes := 0
	for cid, v := range votes {
		if v > maxVotes {
			maxVotes = v
			winner = cid
		}
	}

	if maxVotes >= alpha {
		if winner != sb.preference {
			sb.events.PublishAsync(types.BaseEvent{
				EventType: types.EventPreferenceChanged,
				EventData: PreferenceSwitch{BlockID: sb.preference, Confidence: sb.confidence, Winner: winner, Alpha: alpha},
			})
			sb.preference = winner
			sb.confidence = 1
		} else {
			sb.confidence++
		}
	} else {
		if len(candidates) > 0 {
			sort.Strings(candidates)
			largestBlock := candidates[len(candidates)-1]
			if largestBlock != sb.preference {
				sb.events.PublishAsync(types.BaseEvent{
					EventType: types.EventPreferenceChanged,
					EventData: PreferenceSwitch{BlockID: sb.preference, Confidence: sb.confidence, Winner: winner, Alpha: alpha},
				})
				sb.preference = largestBlock
				sb.confidence = 0
			}
		}
	}
}

func (sb *Snowball) GetPreference() string {
	sb.mu.RLock()
	defer sb.mu.RUnlock()
	return sb.preference
}

func (sb *Snowball) GetConfidence() int {
	sb.mu.RLock()
	defer sb.mu.RUnlock()
	return sb.confidence
}

func (sb *Snowball) CanFinalize(beta int) bool {
	sb.mu.RLock()
	defer sb.mu.RUnlock()
	return sb.confidence >= beta && !sb.finalized
}

func (sb *Snowball) Finalize() {
	sb.mu.Lock()
	defer sb.mu.Unlock()
	sb.finalized = true
}

func (sb *Snowball) IsFinalized() bool {
	sb.mu.RLock()
	defer sb.mu.RUnlock()
	return sb.finalized
}


æ–‡ä»¶è·¯å¾„: consensus/syncManager.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// åŒæ­¥ç®¡ç†å™¨ - å¢å¼ºç‰ˆï¼ˆæ”¯æŒå¿«ç…§ï¼‰
// ============================================

type SyncManager struct {
	nodeID         types.NodeID
	node           *Node // æ–°å¢
	transport      interfaces.Transport
	store          interfaces.BlockStore
	config         *SyncConfig
	snapshotConfig *SnapshotConfig // æ–°å¢
	events         interfaces.EventBus
	SyncRequests   map[uint32]time.Time
	nextSyncID     uint32
	Syncing        bool
	Mu             sync.RWMutex
	PeerHeights    map[types.NodeID]uint64
	lastPoll       time.Time
	usingSnapshot  bool // æ–°å¢ï¼šæ ‡è®°æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¿«ç…§åŒæ­¥
}

func NewSyncManager(nodeID types.NodeID, transport interfaces.Transport, store interfaces.BlockStore, config *SyncConfig, snapshotConfig *SnapshotConfig, events interfaces.EventBus) *SyncManager {
	return &SyncManager{
		nodeID:         nodeID,
		transport:      transport,
		store:          store,
		config:         config,
		snapshotConfig: snapshotConfig,
		events:         events,
		SyncRequests:   make(map[uint32]time.Time),
		PeerHeights:    make(map[types.NodeID]uint64),
		lastPoll:       time.Now(),
	}
}

func (sm *SyncManager) Start(ctx context.Context) {
	go func() {
		ticker := time.NewTicker(sm.config.CheckInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				sm.checkAndSync()
			case <-ctx.Done():
				return
			}
		}
	}()

	go func() {
		ticker := time.NewTicker(1 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				sm.pollPeerHeights()
			case <-ctx.Done():
				return
			}
		}
	}()
}

// å®šæ—¶æŸ¥è¯¢å…¶ä»–èŠ‚ç‚¹é«˜åº¦
func (sm *SyncManager) pollPeerHeights() {
	peers := sm.transport.SamplePeers(sm.nodeID, 10)
	for _, peer := range peers {
		sm.transport.Send(peer, types.Message{
			Type: types.MsgHeightQuery,
			From: sm.nodeID,
		})
	}
}

func (sm *SyncManager) HandleHeightQuery(msg types.Message) {
	_, height := sm.store.GetLastAccepted()
	currentHeight := sm.store.GetCurrentHeight()

	err := sm.transport.Send(types.NodeID(msg.From), types.Message{
		Type:          types.MsgHeightResponse,
		From:          sm.nodeID,
		Height:        height,
		CurrentHeight: currentHeight,
	})
	if err != nil {
		return
	}
}

func (sm *SyncManager) HandleHeightResponse(msg types.Message) {
	sm.Mu.Lock()
	defer sm.Mu.Unlock()
	sm.PeerHeights[types.NodeID(msg.From)] = msg.CurrentHeight
}

// æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦å¯åŠ¨åŒæ­¥ç¨‹åº
func (sm *SyncManager) checkAndSync() {
	sm.Mu.Lock()
	if sm.Syncing {
		sm.Mu.Unlock()
		return
	}

	maxPeerHeight := uint64(0)
	for _, height := range sm.PeerHeights {
		if height > maxPeerHeight {
			maxPeerHeight = height
		}
	}
	sm.Mu.Unlock()

	localCurrentHeight := sm.store.GetCurrentHeight()
	heightDiff := uint64(0)
	if maxPeerHeight > localCurrentHeight {
		heightDiff = maxPeerHeight - localCurrentHeight
	}

	// åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å¿«ç…§åŒæ­¥
	if sm.snapshotConfig.Enabled && heightDiff > sm.config.SnapshotThreshold {
		// ä½¿ç”¨å¿«ç…§åŒæ­¥
		sm.requestSnapshotSync(maxPeerHeight)
	} else if heightDiff > sm.config.BehindThreshold {
		// ä½¿ç”¨æ™®é€šåŒæ­¥
		sm.requestSync(localCurrentHeight+1, minUint64(localCurrentHeight+sm.config.BatchSize, maxPeerHeight))
	}
}

// è¯·æ±‚å¿«ç…§åŒæ­¥
func (sm *SyncManager) requestSnapshotSync(targetHeight uint64) {
	sm.Mu.Lock()
	if sm.Syncing {
		sm.Mu.Unlock()
		return
	}
	sm.Syncing = true
	sm.usingSnapshot = true
	syncID := atomic.AddUint32(&sm.nextSyncID, 1)
	sm.SyncRequests[syncID] = time.Now()
	sm.Mu.Unlock()

	// æ‰¾ä¸€ä¸ªé«˜åº¦è¶³å¤Ÿçš„èŠ‚ç‚¹
	sm.Mu.RLock()
	var targetPeer types.NodeID = "-1"
	for peer, height := range sm.PeerHeights {
		if height >= targetHeight {
			targetPeer = peer
			break
		}
	}
	sm.Mu.RUnlock()

	if targetPeer == "-1" {
		peers := sm.transport.SamplePeers(sm.nodeID, 5)
		if len(peers) > 0 {
			targetPeer = peers[0]
		}
	}

	if targetPeer != "-1" {
		Logf("[Node %d] ğŸ“¸ Requesting SNAPSHOT sync from Node %d (behind by %d blocks)\n",
			sm.nodeID, targetPeer, targetHeight-sm.store.GetCurrentHeight())

		msg := types.Message{
			Type:            types.MsgSnapshotRequest,
			From:            sm.nodeID,
			SyncID:          syncID,
			RequestSnapshot: true,
			Height:          targetHeight,
		}
		sm.transport.Send(targetPeer, msg)
	} else {
		sm.Mu.Lock()
		sm.Syncing = false
		sm.usingSnapshot = false
		delete(sm.SyncRequests, syncID)
		sm.Mu.Unlock()
	}
}

func (sm *SyncManager) requestSync(fromHeight, toHeight uint64) {
	sm.Mu.Lock()
	if sm.Syncing {
		sm.Mu.Unlock()
		return
	}
	sm.Syncing = true
	syncID := atomic.AddUint32(&sm.nextSyncID, 1)
	sm.SyncRequests[syncID] = time.Now()
	sm.Mu.Unlock()

	sm.Mu.RLock()
	var targetPeer types.NodeID = "-1"
	for peer, height := range sm.PeerHeights {
		if height >= toHeight {
			targetPeer = peer
			break
		}
	}
	sm.Mu.RUnlock()

	if targetPeer == "-1" {
		peers := sm.transport.SamplePeers(sm.nodeID, 5)
		if len(peers) > 0 {
			targetPeer = peers[0]
		}
	}

	if targetPeer != "-1" {
		Logf("[Node %d] Requesting sync from Node %d for heights %d-%d\n",
			sm.nodeID, targetPeer, fromHeight, toHeight)

		msg := types.Message{
			Type:       types.MsgSyncRequest,
			From:       sm.nodeID,
			SyncID:     syncID,
			FromHeight: fromHeight,
			ToHeight:   toHeight,
		}
		sm.transport.Send(targetPeer, msg)
	} else {
		sm.Mu.Lock()
		sm.Syncing = false
		delete(sm.SyncRequests, syncID)
		sm.Mu.Unlock()
	}
}

// å¤„ç†å¿«ç…§è¯·æ±‚ï¼ˆæ–°å¢ï¼‰
func (sm *SyncManager) HandleSnapshotRequest(msg types.Message) {
	// è·å–æœ€è¿‘çš„å¿«ç…§
	snapshot, exists := sm.store.GetLatestSnapshot()
	if !exists {
		// å¦‚æœæ²¡æœ‰å¿«ç…§ï¼Œé™çº§åˆ°æ™®é€šåŒæ­¥
		sm.HandleSyncRequest(types.Message{
			Type:       types.MsgSyncRequest,
			From:       msg.From,
			SyncID:     msg.SyncID,
			FromHeight: 1,
			ToHeight:   minUint64(100, sm.store.GetCurrentHeight()),
		})
		return
	}

	Logf("[Node %d] ğŸ“¸ Sending snapshot (height %d) to Node %d\n",
		sm.nodeID, snapshot.Height, msg.From)

	// æ›´æ–°ç»Ÿè®¡
	if sm.node != nil {
		sm.node.stats.Mu.Lock()
		sm.node.stats.SnapshotsServed++
		sm.node.stats.Mu.Unlock()
	}

	response := types.Message{
		Type:           types.MsgSnapshotResponse,
		From:           sm.nodeID,
		SyncID:         msg.SyncID,
		Snapshot:       snapshot,
		SnapshotHeight: snapshot.Height,
	}

	sm.transport.Send(types.NodeID(msg.From), response)
}

// å¤„ç†å¿«ç…§å“åº”ï¼ˆæ–°å¢ï¼‰
func (sm *SyncManager) HandleSnapshotResponse(msg types.Message) {
	sm.Mu.Lock()
	defer sm.Mu.Unlock()

	if _, ok := sm.SyncRequests[msg.SyncID]; !ok {
		return
	}

	delete(sm.SyncRequests, msg.SyncID)

	if msg.Snapshot == nil {
		sm.Syncing = false
		sm.usingSnapshot = false
		return
	}

	// åŠ è½½å¿«ç…§
	err := sm.store.LoadSnapshot(msg.Snapshot)
	if err != nil {
		Logf("[Node %d] Failed to load snapshot: %v\n", sm.nodeID, err)
		sm.Syncing = false
		sm.usingSnapshot = false
		return
	}

	// æ›´æ–°ç»Ÿè®¡
	if sm.node != nil {
		sm.node.stats.Mu.Lock()
		sm.node.stats.SnapshotsUsed++
		sm.node.stats.Mu.Unlock()
	}

	Logf("[Node %d] ğŸ“¸ Successfully loaded snapshot at height %d\n",
		sm.nodeID, msg.SnapshotHeight)

	// å‘å¸ƒå¿«ç…§åŠ è½½äº‹ä»¶
	sm.events.PublishAsync(types.BaseEvent{
		EventType: types.EventSnapshotLoaded,
		EventData: msg.Snapshot,
	})

	// ç»§ç»­åŒæ­¥å¿«ç…§ä¹‹åçš„åŒºå—
	currentHeight := sm.store.GetCurrentHeight()
	maxPeerHeight := uint64(0)
	for _, height := range sm.PeerHeights {
		if height > maxPeerHeight {
			maxPeerHeight = height
		}
	}

	sm.Syncing = false
	sm.usingSnapshot = false

	// å¦‚æœè¿˜éœ€è¦æ›´å¤šåŒºå—ï¼Œç»§ç»­æ™®é€šåŒæ­¥
	if maxPeerHeight > currentHeight+1 {
		go func() {
			time.Sleep(100 * time.Millisecond)
			sm.requestSync(currentHeight+1, minUint64(currentHeight+sm.config.BatchSize, maxPeerHeight))
		}()
	}
}

func (sm *SyncManager) HandleSyncRequest(msg types.Message) {
	blocks := sm.store.GetBlocksFromHeight(msg.FromHeight, msg.ToHeight)

	if len(blocks) == 0 {
		return
	}

	Logf("[Node %d] Sending %d blocks to Node %d for sync\n",
		sm.nodeID, len(blocks), msg.From)

	response := types.Message{
		Type:       types.MsgSyncResponse,
		From:       sm.nodeID,
		SyncID:     msg.SyncID,
		Blocks:     blocks,
		FromHeight: msg.FromHeight,
		ToHeight:   msg.ToHeight,
	}

	sm.transport.Send(types.NodeID(msg.From), response)
}

func (sm *SyncManager) HandleSyncResponse(msg types.Message) {
	sm.Mu.Lock()
	defer sm.Mu.Unlock()

	if _, ok := sm.SyncRequests[msg.SyncID]; !ok {
		return
	}

	delete(sm.SyncRequests, msg.SyncID)
	sm.Syncing = false

	added := 0
	for _, block := range msg.Blocks {
		isNew, err := sm.store.Add(block)
		if err != nil {
			continue
		}
		if isNew {
			added++
		}
	}

	if added > 0 {
		Logf("[Node %d] ğŸ“¦ Successfully synced %d new blocks (heights %d-%d)\n",
			sm.nodeID, added, msg.FromHeight, msg.ToHeight)
	}

	sm.events.PublishAsync(types.BaseEvent{
		EventType: types.EventSyncComplete,
		EventData: added,
	})
}


æ–‡ä»¶è·¯å¾„: consensus/utils.go
æ–‡ä»¶å†…å®¹:
package consensus

import (...)

// ============================================
// å·¥å…·å‡½æ•°
// ============================================

func Logf(format string, args ...interface{}) {
	now := time.Now()
	timestamp := now.Format("15:04:05.999")
	fmt.Printf("[%s] %s", timestamp, fmt.Sprintf(format, args...))
}

func minUint64(a, b uint64) uint64 {
	if a < b {
		return a
	}
	return b
}


æ–‡ä»¶è·¯å¾„: crt/cert.go
æ–‡ä»¶å†…å®¹:
package crt

import (...)

// convertBits ç”¨äºå°†æ•°æ®ä» fromBits ä½ç»„è½¬æ¢ä¸º toBits ä½ç»„
func convertBits(data []byte, fromBits, toBits uint, pad bool) ([]byte, error) {
	acc := 0
	bits := uint(0)
	maxv := (1 << toBits) - 1
	output := []byte{}

	for _, value := range data {
		acc = (acc << fromBits) | int(value)
		bits += fromBits
		for bits >= toBits {
			bits -= toBits
			output = append(output, byte((acc>>bits)&maxv))
		}
	}

	if pad && bits > 0 {
		output = append(output, byte((acc<<(toBits-bits))&maxv))
	} else if !pad && bits >= fromBits {
		return nil, fmt.Errorf("excess padding")
	} else if !pad && ((acc<<(toBits-bits))&maxv) != 0 {
		return nil, fmt.Errorf("non-zero padding")
	}

	return output, nil
}

// GenerateBitcoinAddress æ ¹æ®å…¬é’¥ç”Ÿæˆä¸€ä¸ª P2WPKH SegWit ä¸»ç½‘åœ°å€ (bc1 å¼€å¤´)
func GenerateBitcoinAddress(pubKey *ecdsa.PublicKey) (string, error) {
	// å…¬é’¥åºåˆ—åŒ–ï¼ˆéå‹ç¼©ï¼‰
	pubKeyBytes := elliptic.Marshal(pubKey.Curve, pubKey.X, pubKey.Y)

	// SHA-256 å“ˆå¸Œ
	sha256Hash := sha256.Sum256(pubKeyBytes)

	// RIPEMD-160 å“ˆå¸Œ
	ripemdHasher := ripemd160.New()
	_, err := ripemdHasher.Write(sha256Hash[:])
	if err != nil {
		return "", err
	}
	ripemdHash := ripemdHasher.Sum(nil)

	if len(ripemdHash) != 20 {
		return "", fmt.Errorf("invalid RIPEMD-160 hash length: %d", len(ripemdHash))
	}

	// æ¯”ç‰¹å¸ P2WPKH åœ°å€ï¼šversion=0ï¼Œdata=hash160(pubkey)
	// version ç”¨ä¸€ä¸ª 5 ä½ç»„è¡¨ç¤ºï¼ˆ0x00ï¼‰
	version := byte(0x00) // 0 è¡¨ç¤º witness version 0

	// å°† 20 å­—èŠ‚ hash è½¬æ¢ä¸º 5 ä½ä¸€ç»„çš„æ•°æ®
	converted, err := convertBits(ripemdHash, 8, 5, false)
	if err != nil {
		return "", err
	}

	// å°† versionï¼ˆ0ï¼‰ å’Œ è½¬æ¢åçš„å“ˆå¸Œæ•°æ®æ‹¼æ¥
	// data çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ 5-bit çš„ç‰ˆæœ¬å·0ï¼Œå…¶ä½™çš„æ˜¯è½¬æ¢åçš„å“ˆå¸Œ
	data := append([]byte{version}, converted...)

	// ä½¿ç”¨ Bech32 ç¼–ç ç”Ÿæˆ bc1 å¼€å¤´çš„åœ°å€
	address, err := bech32.Encode("bc", data)
	if err != nil {
		return "", err
	}

	return address, nil
}

func generateSelfSignedCert(certPath, keyPath string) error {
	// ç”Ÿæˆ ECDSA ç§é’¥
	privateKey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)
	if err != nil {
		return err
	}

	// æ ¹æ®å…¬é’¥ç”Ÿæˆæ¯”ç‰¹å¸åœ°å€
	bitcoinAddress, err := GenerateBitcoinAddress(&privateKey.PublicKey)
	if err != nil {
		return err
	}

	// åˆ›å»ºè¯ä¹¦æ¨¡æ¿
	template := x509.Certificate{
		SerialNumber: big.NewInt(time.Now().UnixNano()),
		Subject: pkix.Name{
			Organization: []string{bitcoinAddress}, // å°† bc1 åœ°å€å†™å…¥ç»„ç»‡å­—æ®µ
		},
		NotBefore: time.Now(),
		NotAfter:  time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:  x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
		ExtKeyUsage: []x509.ExtKeyUsage{
			x509.ExtKeyUsageServerAuth,
		},
		BasicConstraintsValid: true,
		DNSNames:              []string{"localhost"},
	}

	// è‡ªç­¾åè¯ä¹¦
	certBytes, err := x509.CreateCertificate(rand.Reader, &template, &template, &privateKey.PublicKey, privateKey)
	if err != nil {
		return err
	}

	// ä¿å­˜è¯ä¹¦
	certFile, err := os.Create(certPath)
	if err != nil {
		return err
	}
	defer certFile.Close()
	if err := pem.Encode(certFile, &pem.Block{Type: "CERTIFICATE", Bytes: certBytes}); err != nil {
		return err
	}

	// ä¿å­˜ç§é’¥
	keyFile, err := os.Create(keyPath)
	if err != nil {
		return err
	}
	defer keyFile.Close()
	privBytes, err := x509.MarshalECPrivateKey(privateKey)
	if err != nil {
		return err
	}
	if err := pem.Encode(keyFile, &pem.Block{Type: "EC PRIVATE KEY", Bytes: privBytes}); err != nil {
		return err
	}

	logs.Debug("Certificate and key generated:\nCertificate: %s\nPrivate Key: %s\n", certPath, keyPath)
	logs.Debug("Bitcoin address used in certificate: %s\n", bitcoinAddress)
	return nil
}

func Test() {
	certPath := "server.crt"
	keyPath := "server.key"

	if err := generateSelfSignedCert(certPath, keyPath); err != nil {
		logs.Error("Failed to generate certificate: %v", err)
	}

	log.Println("Certificate generation completed!")
}


æ–‡ä»¶è·¯å¾„: db/base.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

func NewZeroTokenBalance() *pb.TokenBalance {
	return &pb.TokenBalance{
		Balance:                "0",
		CandidateLockedBalance: "0",
		MinerLockedBalance:     "0",
		LiquidLockedBalance:    "0",
		WitnessLockedBalance:   "0",
		LeverageLockedBalance:  "0",
	}
}

// SaveAnyTx æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) SaveAnyTx(anyTx *pb.AnyTx) error {
	txID := anyTx.GetTxId()
	if txID == "" {
		return fmt.Errorf("SaveAnyTx: empty txID not allowed")
	}
	// 1. åºåˆ—åŒ–
	data, err := ProtoMarshal(anyTx)
	if err != nil {
		return err
	}
	// 2. ä¸»å­˜å‚¨
	mainKey := KeyAnyTx(txID)
	mgr.EnqueueSet(mainKey, string(data))

	// 3. å¦‚æœ BaseMessage æ˜¯ PENDINGï¼Œåˆ™å†™ "pending_anytx_<txID>"
	base := anyTx.GetBase()
	if base != nil && base.Status == pb.Status_PENDING {
		mgr.EnqueueSet(KeyPendingAnyTx(txID), "")
	} else {
		mgr.EnqueueDelete(KeyPendingAnyTx(txID))
	}

	// 4. è°ƒåº¦åˆ°ä¸åŒçš„è½åº“/ç´¢å¼•å‡½æ•°
	switch content := anyTx.GetContent().(type) {
	case *pb.AnyTx_OrderTx:
		err = mgr.SaveOrderTx(content.OrderTx)
	case *pb.AnyTx_MinerTx:
		err = mgr.SaveMinerTx(content.MinerTx)
	case *pb.AnyTx_Transaction:
		err = mgr.SaveTransaction(content.Transaction)

	default:
		// å¯¹æ²¡æœ‰é¢å¤–ç´¢å¼•éœ€æ±‚çš„Txï¼Œå¯ä¸åšä»»ä½•é¢å¤–æ“ä½œ
	}
	return err
}


æ–‡ä»¶è·¯å¾„: db/db.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// Manager å°è£… BadgerDB çš„ç®¡ç†å™¨
type Manager struct {
	Db *badger.DB
	mu sync.RWMutex

	// é˜Ÿåˆ—é€šé“ï¼Œæ‰¹é‡å†™çš„ goroutine ç”¨å®ƒæ¥å–å†™è¯·æ±‚
	writeQueueChan chan WriteTask
	// å¼ºåˆ¶åˆ·ç›˜é€šé“
	forceFlushChan chan struct{}
	// ç”¨äºé€šçŸ¥å†™é˜Ÿåˆ— goroutine åœæ­¢
	stopChan chan struct{}

	// è¿˜å¯ä»¥å¢åŠ ä¸¤ä¸ªå‚æ•°ï¼Œç”¨æ¥æ§åˆ¶"å†™å¤šå°‘/å¤šé•¿æ—¶é—´"å°±è½åº“
	maxBatchSize  int                // ç´¯è®¡å¤šå°‘æ¡å°±å†™ä¸€æ¬¡
	flushInterval time.Duration      // é—´éš”å¤šä¹…å¼ºåˆ¶å†™ä¸€æ¬¡
	IndexMgr      *MinerIndexManager // æ–°å¢
	seq           *badger.Sequence   //è‡ªå¢å‘å·å™¨
	// ä½ å¯ä»¥åœ¨è¿™é‡Œåšä¸€ä¸ª wait groupï¼Œä¿è¯ close çš„æ—¶å€™èƒ½ç­‰ goroutine é€€å‡º
	wg sync.WaitGroup
	// ç¼“å­˜çš„åŒºå—åˆ‡ç‰‡ï¼Œæœ€å¤šå­˜ 10 ä¸ª
	cachedBlocks   []*pb.Block
	cachedBlocksMu sync.RWMutex
}

// NewManager åˆ›å»ºä¸€ä¸ªæ–°çš„ DBManager å®ä¾‹
func NewManager(path string) (*Manager, error) {
	cfg := config.DefaultConfig()
	opts := badger.DefaultOptions(path).WithLoggingLevel(badger.INFO).
		// å°†å•ä¸ª vlog æ–‡ä»¶é™åˆ¶åˆ° 64 MBï¼Œæ¯”å¦‚ 64 << 20
		WithValueLogFileSize(cfg.Database.ValueLogFileSize)
	// å¦‚æœä¾ç„¶æƒ³ç”¨ mmapï¼Œå¯ä»¥ä¿æŒé»˜è®¤ (MemoryMap) æˆ–è‡ªå·±è®¾ WithValueLogLoadingMode(options.MemoryMap)
	// .WithValueLogLoadingMode(options.MemoryMap)
	//
	// å¯é€‰ï¼šè®©Badgerå¯åŠ¨æ—¶è‡ªåŠ¨æˆªæ–­ä¸å®Œæ•´çš„æ—¥å¿—ï¼Œèƒ½é¿å…æŸäº›ä¸ä¸€è‡´é—®é¢˜
	db, err := badger.Open(opts)
	if err != nil {
		return nil, fmt.Errorf("failed to open badger db: %w", err)
	}

	indexMgr, err := NewMinerIndexManager(db)
	if err != nil {
		db.Close() // æ¸…ç†å·²æ‰“å¼€çš„æ•°æ®åº“
		return nil, fmt.Errorf("failed to create index manager: %w", err)
	}

	// â‘  åˆ›å»º Sequenceï¼ˆä¸€æ¬¡é¢„å– 1 000 ä¸ªå·æ®µï¼Œå¯æŒ‰ä¸šåŠ¡é‡è°ƒå¤§/è°ƒå°ï¼‰
	seq, err := db.GetSequence([]byte("meta:max_index"), cfg.Database.SequenceBandwidth)
	if err != nil {
		db.Close() // æ¸…ç†å·²æ‰“å¼€çš„æ•°æ®åº“
		return nil, fmt.Errorf("failed to create sequence: %w", err)
	}

	manager := &Manager{
		Db:       db,
		IndexMgr: indexMgr,
		seq:      seq,
	}

	return manager, nil
}

func (manager *Manager) InitWriteQueue(maxBatchSize int, flushInterval time.Duration) {
	cfg := config.DefaultConfig()
	manager.maxBatchSize = maxBatchSize
	manager.flushInterval = flushInterval
	manager.writeQueueChan = make(chan WriteTask, cfg.Database.WriteQueueSize) // ç¼“å†²åŒºå¤§å°å¯é…Œæƒ…è°ƒå¤§

	// æ–°å»º forceFlushChan
	manager.forceFlushChan = make(chan struct{}, 1)

	manager.stopChan = make(chan struct{})

	manager.wg.Add(1)
	go manager.runWriteQueue()
}

// å†™é˜Ÿåˆ—çš„æ ¸å¿ƒ goroutine é€»è¾‘
func (manager *Manager) runWriteQueue() {
	defer manager.wg.Done()

	// ç”¨äºä¸´æ—¶æ”¶é›†å†™è¯·æ±‚
	var batch []WriteTask
	batch = make([]WriteTask, 0, manager.maxBatchSize)

	// å®šæ—¶å™¨ï¼šåˆ°äº† flushInterval å°±è¦æäº¤
	ticker := time.NewTicker(manager.flushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-manager.stopChan:
			// æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå…ˆæŠŠæ‰‹å¤´çš„ batch flush ä¸€ä¸‹å†é€€å‡º
			manager.flushBatch(batch)
			return

		case task := <-manager.writeQueueChan:
			// æ”¶åˆ°ä¸€æ¡å†™è¯·æ±‚ï¼ŒåŠ å…¥ batch
			batch = append(batch, task)
			if len(batch) >= manager.maxBatchSize {
				// è¶…è¿‡é˜ˆå€¼ï¼Œç«‹å³ flush
				manager.flushBatch(batch)
				// flush å®Œè¦é‡ç½® batch
				batch = batch[:0]
			}

		case <-ticker.C:
			// åˆ°äº†æ—¶é—´é—´éš”ï¼Œä¹Ÿè¦ flush
			if len(batch) > 0 {
				manager.flushBatch(batch)
				batch = batch[:0]
			}

		case <-manager.forceFlushChan:
			// æ”¶åˆ°"å¼ºåˆ¶åˆ·ç›˜"è¯·æ±‚
			if len(batch) > 0 {
				manager.flushBatch(batch)
				batch = batch[:0]
			}
		}
	}
}

// æä¾›ä¸€ä¸ªæ— å‚å‡½æ•°ï¼Œè§¦å‘æ‰¹é‡é˜Ÿåˆ— flush
func (manager *Manager) ForceFlush() {
	select {
	case manager.forceFlushChan <- struct{}{}:
	default:
		// å¦‚æœé€šé“å·²æ»¡ï¼Œä¸é˜»å¡
	}
}

// è¿™é‡Œ flushBatch å°±æ˜¯æŠŠ batch é‡Œæ‰€æœ‰è¯·æ±‚ä¸€æ¬¡æ€§åœ°åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­æäº¤åˆ° BadgerDBã€‚
func (manager *Manager) flushBatch(batch []WriteTask) {
	if len(batch) == 0 {
		return
	}
	cfg := config.DefaultConfig()
	// ä¿å®ˆè½¯ä¸Šé™ï¼Œç•™å‡º Badger å…ƒæ•°æ®å¼€é”€ä½™é‡
	softLimitBytes := cfg.Database.WriteBatchSoftLimit // 8 MiB
	maxCountPerTxn := cfg.Database.MaxCountPerTxn      // ä¹Ÿä¿ç•™æ¡æ•°ä¸Šé™ï¼ŒåŒé‡ä¿é™©
	perEntryOverhead := cfg.Database.PerEntryOverhead  // ä¼°ç®—æ¯æ¡é™„åŠ å¼€é”€

	// 1) å…ˆæŒ‰â€œå­—èŠ‚+æ¡æ•°â€æŠŠbatchåˆ‡æˆè‹¥å¹² sub-batch
	type sliceRange struct{ i, j int }
	subRanges := make([]sliceRange, 0, (len(batch)+maxCountPerTxn-1)/maxCountPerTxn)

	curStart, curBytes, curCount := 0, 0, 0
	for idx, t := range batch {
		entryBytes := len(t.Key) + len(t.Value) + perEntryOverhead
		// å¦‚æœåŠ ä¸Šå½“å‰æ¡ä¼šè¶…è¿‡é™åˆ¶ï¼Œå°±å…ˆå°å£å¼€æ–°æ®µ
		if curCount > 0 && (int64(curBytes+entryBytes) > softLimitBytes || curCount >= maxCountPerTxn) {
			subRanges = append(subRanges, sliceRange{curStart, idx})
			curStart, curBytes, curCount = idx, 0, 0
		}
		curBytes += entryBytes
		curCount++
	}
	// æ”¶å°¾
	if curStart < len(batch) {
		subRanges = append(subRanges, sliceRange{curStart, len(batch)})
	}

	// 2) æäº¤æ¯ä¸ª sub-batchï¼›è‹¥ä»æŠ¥è¿‡å¤§ï¼ŒäºŒåˆ†é€€è®©
	for _, r := range subRanges {
		i, j := r.i, r.j
		for i < j {
			ok := manager.tryFlushRange(batch, i, j)
			if ok {
				break // è¿™ä¸ªèŒƒå›´æäº¤æˆåŠŸ
			}
			// å¤±è´¥ï¼šæŠŠèŒƒå›´äºŒåˆ†
			mid := i + (j-i)/2
			// å…ˆå°è¯•å·¦åŠ
			if !manager.tryFlushRange(batch, i, mid) {
				// å·¦åŠéƒ½å¤ªå¤§ï¼šç»§ç»­ç¼©å·¦åŠ
				j = mid
				continue
			}
			// å·¦åŠæˆåŠŸï¼Œå†æäº¤å³åŠï¼ˆå¾ªç¯ä¸‹ä¸€è½®å¤„ç†å³åŠï¼‰
			i = mid
		}
	}
}

// è¿”å›æ˜¯å¦æäº¤æˆåŠŸï¼›å¦‚æœæ•´ä¸ªèŒƒå›´æ˜¯ä¸€æ¡ä½†ä»ç„¶è¿‡å¤§ï¼Œä¼šæ‰“å°æ˜ç¡®é”™è¯¯å¹¶è¿”å›false
func (manager *Manager) tryFlushRange(batch []WriteTask, start, end int) bool {
	if start >= end {
		return true
	}
	sub := batch[start:end]

	err := manager.Db.Update(func(txn *badger.Txn) error {
		for _, task := range sub {
			switch task.Op {
			case OpSet:
				if e := txn.Set(task.Key, task.Value); e != nil {
					return e
				}
			case OpDelete:
				if e := txn.Delete(task.Key); e != nil {
					return e
				}
			}
		}
		return nil
	})
	if err == nil {
		return true
	}

	// Badger çš„å…¸å‹æŠ¥é”™æ–‡æ¡ˆé‡ŒåŒ…å« "Txn is too big"
	if strings.Contains(err.Error(), "Txn is too big") {
		if end-start == 1 {
			// å•æ¡ä»è¿‡å¤§ï¼šç»™å‡ºæ¸…æ™°æç¤º
			key := string(sub[0].Key)
			valSz := len(sub[0].Value)
			logs.Error("[flushBatch] single entry still too big: key=%q size=%d bytes; "+
				"consider compressing, chunking, or storing out-of-DB", key, valSz)
			return false
		}
		// äº¤ç»™ä¸Šå±‚ç»§ç»­äºŒåˆ†
		return false
	}

	// å…¶ä»–é”™è¯¯ï¼šè®°å½•å¹¶ç»§ç»­
	logs.Error("[flushBatch] subBatch [%d:%d] error: %v", start, end, err)
	return true // é¿å…å¡æ­»ï¼šæŠŠå®ƒå½“â€œå·²å¤„ç†â€ï¼Œä¸ä¸­æ–­åç»­
}

func (manager *Manager) View(fn func(txn *TransactionView) error) error {
	manager.mu.RLock()
	defer manager.mu.RUnlock()
	return manager.Db.View(func(badgerTxn *badger.Txn) error {
		return fn(&TransactionView{badgerTxn})
	})
}

// TransactionView åŒ…è£… badger.Txn
type TransactionView struct {
	Txn *badger.Txn
}

func (tv *TransactionView) NewIterator() *badger.Iterator {
	return tv.Txn.NewIterator(badger.DefaultIteratorOptions)
}

// æä¾›"æŠ•é€’å†™è¯·æ±‚"çš„æ–¹æ³•ï¼ˆæ›¿æ¢åŸå…ˆçš„ Write/WriteBatchï¼‰

func (manager *Manager) EnqueueSet(key, value string) {
	manager.writeQueueChan <- WriteTask{
		Key:   []byte(key),
		Value: []byte(value),
		Op:    OpSet,
	}
}

func (manager *Manager) EnqueueDelete(key string) {
	manager.writeQueueChan <- WriteTask{
		Key: []byte(key),
		Op:  OpDelete,
	}
}

func (manager *Manager) Close() {
	// 1. é€šçŸ¥å†™é˜Ÿåˆ— goroutine åœæ­¢
	if manager.stopChan != nil {
		close(manager.stopChan)
	}

	// 2. ç­‰å¾… goroutine é€€å‡º
	manager.wg.Wait()

	// 3. è¿™æ—¶æ‰€æœ‰é˜Ÿåˆ—é‡Œçš„æ•°æ®éƒ½å·²ç»flushå®Œäº†ï¼Œå¯ä»¥å®‰å…¨å…³é—­DB
	manager.mu.Lock()
	defer manager.mu.Unlock()

	if manager.seq != nil {
		_ = manager.seq.Release() // æ— é¡»å¤„ç†è¿”å›å€¼ï¼›Close() æ—¶ Badger ä»ä¼šå®‰å…¨è½ç›˜
		manager.seq = nil
	}

	if manager.Db != nil {
		_ = manager.Db.Close()
		manager.Db = nil
	}
}

// Read è¯»å–é”®å¯¹åº”çš„å€¼
func (manager *Manager) Read(key string) (string, error) {
	manager.mu.RLock()
	db := manager.Db
	manager.mu.RUnlock()

	if db == nil {
		return "", fmt.Errorf("database is not initialized or closed")
	}

	var value string
	err := db.View(func(txn *badger.Txn) error {
		item, err := txn.Get([]byte(key))
		if err != nil {
			return err
		}
		val, err := item.ValueCopy(nil)
		if err != nil {
			return err
		}
		value = string(val)
		return nil
	})
	if err != nil {
		return "", err
	}
	return value, nil
}

// å°† db.Transaction åºåˆ—åŒ–ä¸º [][]byte
func SerializeAllTransactions(txCopy []*pb.AnyTx) [][]byte {

	// 1) æŒ‰ TxId æ’åº
	sort.Slice(txCopy, func(i, j int) bool {
		return txCopy[i].GetTxId() < txCopy[j].GetTxId()
	})

	// 2) é€ç¬”åºåˆ—åŒ–
	var result [][]byte
	for _, tx := range txCopy {
		result = append(result, serializeTransaction(tx))
	}
	return result
}

// æ ¹æ® db.Transaction çš„å­—æ®µè¿›è¡Œåºåˆ—åŒ–
// å®é™…ä¸­åº”æ ¹æ®ä¸šåŠ¡éœ€æ±‚å°†äº¤æ˜“å˜æˆå­—èŠ‚åˆ‡ç‰‡ï¼Œè¿™é‡Œåªä½œç®€å•ç¤ºä¾‹
func serializeTransaction(tx *pb.AnyTx) []byte {
	data := []byte(tx.GetTxId() + "|" + tx.GetBase().FromAddress)
	// å¯ä»¥å¢åŠ æ›´å¤šå­—æ®µåºåˆ—åŒ–é€»è¾‘
	return data
}

// NextIndex è·å–ä¸‹ä¸€ä¸ªè‡ªå¢ç´¢å¼•
func (m *Manager) NextIndex() (uint64, error) {
	id, err := m.seq.Next() // Badger è‡ªåŠ¨å¹¶å‘å®‰å…¨
	if err != nil {
		return 0, err
	}
	return id + 1, nil // è®©ç´¢å¼•ä¾æ—§ä» 1 å¼€å§‹
}


æ–‡ä»¶è·¯å¾„: db/keys.go
æ–‡ä»¶å†…å®¹:
// db/keys.go
package db

import (...)

// ===================== ç‰ˆæœ¬æ§åˆ¶ =====================
// è®¾ç½®å…¨å±€ Key ç‰ˆæœ¬å‰ç¼€ï¼ˆä¾‹å¦‚ "v1" â†’ äº§å‡º "v1_<key>"ï¼‰ã€‚
// å¦‚éœ€ç«‹åˆ»å…¼å®¹æ—§æ•°æ®ï¼Œæš‚æ—¶å°† KeyVersion è®¾ä¸º "" å³å¯ä¸åŠ ç‰ˆæœ¬å‰ç¼€ã€‚
const KeyVersion = "v1"

// æŠŠç‰ˆæœ¬å·æ‹¼åˆ°æœ€å‰é¢ï¼ˆä¿æŒä½ ä¸‹åˆ’çº¿é£æ ¼ï¼šv1_<...>ï¼‰
func withVer(s string) string {
	if KeyVersion == "" {
		return s
	}
	return KeyVersion + "_" + s
}

// è¯»å–å›é€€è¾…åŠ©ï¼šæŠŠå¸¦ç‰ˆæœ¬çš„é”®å»æ‰ç‰ˆæœ¬å‰ç¼€ï¼Œä¾¿äºåŒè¯»å›é€€ã€‚
// ä¾‹ï¼šnewKey := KeyTx(id); oldKey := StripVersion(newKey)
func StripVersion(prefixed string) string {
	if KeyVersion == "" {
		return prefixed
	}
	p := KeyVersion + "_"
	return strings.TrimPrefix(prefixed, p)
}

// â€”â€” åŒºå— â€”â€”
// ä¾‹ï¼šblockdata_<blockHash>
func KeyBlockData(blockHash string) string {
	return withVer(fmt.Sprintf("blockdata_%s", blockHash))
}

// ä¾‹ï¼šheight_<height>_blocks
func KeyHeightBlocks(height uint64) string {
	return withVer(fmt.Sprintf("height_%d_blocks", height))
}

// ä¾‹ï¼šblockid_<blockHash>
func KeyBlockIDToHeight(blockHash string) string {
	return withVer(fmt.Sprintf("blockid_%s", blockHash))
}

// ä¾‹ï¼šlatest_block_height
func KeyLatestHeight() string { return withVer("latest_block_height") }

// â€”â€” äº¤æ˜“é€šç”¨æ˜ å°„ â€”â€”
// ä¾‹ï¼šanyTx_<txID>ï¼ˆæ˜ å°„åˆ° tx_<txID> æˆ– order_<txID> ç­‰ï¼‰
func KeyAnyTx(txID string) string { return withVer("anyTx_" + txID) }

// â€”â€” Pending AnyTx â€”â€”
// ä¾‹ï¼špending_anytx_<txID>
func KeyPendingAnyTx(txID string) string { return withVer("pending_anytx_" + txID) }

// â€”â€” å…·ä½“äº¤æ˜“ â€”â€”
// ä¾‹ï¼štx_<txID>
func KeyTx(txID string) string { return withVer("tx_" + txID) }

// ä¾‹ï¼šorder_<txID>
func KeyOrderTx(txID string) string { return withVer("order_" + txID) }

// ä¾‹ï¼šminerTx_<txID>
func KeyMinerTx(txID string) string { return withVer("minerTx_" + txID) }

// â€”â€” è®¢å•ä»·æ ¼ç´¢å¼•ï¼ˆä¿æŒä½ åŸæ¥çš„ç®¡é“ä¸å†’å·ç»“æ„ä¸å˜ï¼‰â€”â€”
// ä¾‹ï¼špair:<pair>|is_filled:<true|false>|price:<67ä½åè¿›åˆ¶>|order_id:<txID>
func KeyOrderPriceIndex(pair string, isFilled bool, priceKey67 string, orderID string) string {
	return withVer(fmt.Sprintf("pair:%s|is_filled:%t|price:%s|order_id:%s", pair, isFilled, priceKey67, orderID))
}

// â€”â€” è´¦æˆ·ä¸ç´¢å¼• â€”â€”
// ä¾‹ï¼šaccount_<address>
func KeyAccount(addr string) string { return withVer("account_" + addr) }

// ä¾‹ï¼šindexToAccount_<idx>
func KeyIndexToAccount(idx uint64) string { return withVer(fmt.Sprintf("indexToAccount_%d", idx)) }
func NameOfKeyIndexToAccount() string     { return withVer("indexToAccount_") }

// ä¾‹ï¼šfree_idx_%020d
// ä½ åŸæ¥è¿™ä¸ªå‡½æ•°è¿”å›çš„æ˜¯â€œå‰ç¼€â€ï¼Œæˆ‘ä¿æŒä¸å˜ï¼š
func KeyFreeIdx() string { return withVer("free_idx_") }

// æŠ•ç¥¨/å€™é€‰äººç­‰ä½ å·²æœ‰çš„æ¨¡å¼ï¼ˆå¦‚ stakeIndex_ å‰ç¼€é‡Œå¸¦ address:ï¼‰ä¿æŒåŸçŠ¶ï¼š
// ä¾‹ï¼šstakeIndex_<invertedPadded32>__address:<addr>
func KeyStakeIndex(invertedPadded32, addr string) string {
	return withVer(fmt.Sprintf("stakeIndex_%s_address:%s", invertedPadded32, addr))
}

// â€”â€” èŠ‚ç‚¹/å®¢æˆ·ç«¯ä¿¡æ¯ â€”â€”
// ä¾‹ï¼šnode_<pubKey>
// ä½ åŸå‡½æ•°åæ²¡æœ‰å‚æ•°ä¸”è¿”å›å‰ç¼€ï¼Œæˆ‘ä¿æŒä¸å˜ï¼š
func KeyNode() string { return withVer("node_") }

// ä¾‹ï¼šclientinfo_<ip>
func KeyClientInfo(ip string) string { return withVer("clientinfo_" + ip) }


æ–‡ä»¶è·¯å¾„: db/manage_account.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// SaveAccount stores an Account in the database
func (mgr *Manager) SaveAccount(account *pb.Account) error {
	key := KeyAccount(account.Address)
	data, err := ProtoMarshal(account)
	if err != nil {
		return err
	}
	//logs.Trace("SaveAccount key:%s", key)
	mgr.EnqueueSet(key, string(data))
	return nil
}

// GetAccount retrieves an Account from the database
func (mgr *Manager) GetAccount(address string) (*pb.Account, error) {
	key := KeyAccount(address)
	//logs.Trace("GetAccount key:%s", key)
	val, err := mgr.Read(key)
	if err != nil {
		return nil, err
	}
	account := &pb.Account{}
	if err := ProtoUnmarshal([]byte(val), account); err != nil {
		return nil, err
	}
	return account, nil
}

// CalcStake = receive_votes + FB.miner_locked_balance
func CalcStake(acc *pb.Account) (decimal.Decimal, error) {
	rv, err := decimal.NewFromString(acc.ReceiveVotes)
	if err != nil {
		rv = decimal.Zero // å¦‚æœacc.ReceiveVotesç©ºæˆ–è§£æå¤±è´¥ï¼Œå¯è®¾ä¸º0
	}

	fbBal, ok := acc.Balances["FB"]
	if !ok {
		// è¯´æ˜æ²¡æœ‰ä»»ä½•FBä½™é¢ï¼Œé”å®šä½™é¢ä¹Ÿä¸º0
		return rv, nil
	}
	ml, err2 := decimal.NewFromString(fbBal.MinerLockedBalance)
	if err2 != nil {
		ml = decimal.Zero
	}
	return rv.Add(ml), nil
}

// ç”¨æ¥åˆ æ‰æ—§stakeIndexå†æ’å…¥æ–°çš„
func (mgr *Manager) UpdateStakeIndex(oldStake, newStake decimal.Decimal, address string) error {
	oldKey := buildStakeIndexKey(oldStake, address)
	newKey := buildStakeIndexKey(newStake, address)

	if oldKey != newKey {
		// åˆ é™¤æ—§
		_ = mgr.DeleteKey(oldKey)
		// å†™æ–°
		mgr.EnqueueSet(newKey, "")
	}
	return nil
}

// å‡è®¾ maxStake = 1e30 (çœ‹ä½ éœ€è¦å¤šå°‘é‡çº§)
var maxStake, _ = decimal.NewFromString("1e30")

// å°† stake è½¬ä¸ºå€’æ’å­—ç¬¦ä¸²
func buildStakeIndexKey(stake decimal.Decimal, address string) string {
	// 0) è‹¥stake<0å¯èƒ½è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œç®€å•max(0, stake)
	if stake.Cmp(decimal.Zero) < 0 {
		stake = decimal.Zero
	}
	// 1) inverted = maxStake - stake
	inv := maxStake.Sub(stake)
	if inv.Cmp(decimal.Zero) < 0 {
		inv = decimal.Zero
	}
	invStr := inv.String()

	// 2) å·¦é›¶å¡«å……(é•¿åº¦çœ‹ä½ éœ€è¦å¤šå¤§ï¼Œç¤ºä¾‹è®¾ 32)
	padNeeded := 32 - len(invStr)
	if padNeeded < 0 {
		padNeeded = 0
	}
	zeros := strings.Repeat("0", padNeeded)
	finalStr := zeros + invStr

	return KeyStakeIndex(finalStr, address)
}

func (mgr *Manager) getAccountByIndex(idx uint64) (*pb.Account, error) {
	//----------------------------------------
	// â‘  å–å‡ºåœ°å€å­—ç¬¦ä¸²
	//----------------------------------------
	var addr string
	indexKey := []byte(KeyIndexToAccount(idx))

	err := mgr.Db.View(func(txn *badger.Txn) error {
		item, err := txn.Get(indexKey)
		if err != nil {
			return err // badger.ErrKeyNotFound ç­‰
		}
		val, err := item.ValueCopy(nil)
		if err != nil {
			return err
		}
		addr = string(val) // value å°±æ˜¯ä¸€æ®µåœ°å€å­—ç¬¦ä¸²
		return nil
	})
	if err != nil {
		return nil, err
	}

	//----------------------------------------
	// â‘¡ å–å‡º Account å¯¹è±¡
	//----------------------------------------
	var accBytes []byte
	accountKey := []byte(addr)

	err = mgr.Db.View(func(txn *badger.Txn) error {
		item, err := txn.Get(accountKey)
		if err != nil {
			return err
		}
		accBytes, err = item.ValueCopy(nil)
		return err
	})
	if err != nil {
		return nil, err
	}

	//----------------------------------------
	// â‘¢ ååºåˆ—åŒ–å¹¶è¿”å›
	//----------------------------------------
	acc := &pb.Account{}
	if err := proto.Unmarshal(accBytes, acc); err != nil {
		return nil, err
	}
	return acc, nil
}


æ–‡ä»¶è·¯å¾„: db/manage_miner.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// ä»ç´¢å¼•ç©ºé—´é‡Œç›´æ¥éšæœºé‡‡æ ·
func (mgr *Manager) GetRandomMinersFast(k int) ([]*pb.Account, error) {
	// ä½¿ç”¨ä¼ å…¥çš„managerå‚æ•°è€Œä¸æ˜¯åˆ›å»ºæ–°çš„
	if mgr == nil {
		return nil, fmt.Errorf("GetRandomMiners: db manager is nil")
	}

	idxs, err := mgr.IndexMgr.SampleK(k)
	if err != nil {
		return nil, err
	}
	if len(idxs) < k {
		logs.Trace("[GetRandomMinersFast] sampled %d indices k=%d", len(idxs), k)
		return nil, fmt.Errorf("GetRandomMiners: k out of range")
	}

	accounts := make([]*pb.Account, 0, len(idxs))
	for _, idx := range idxs {
		acc, err := mgr.getAccountByIndex(idx)
		if errors.Is(badger.ErrKeyNotFound, err) {
			logs.Error("[GetRandomMinersFast] index %s not exist", idx)
			continue // ç†è®ºä¸ä¼šå‘ç”Ÿï¼›é˜²å¾¡
		}
		if err != nil {
			return nil, err
		}
		accounts = append(accounts, acc)
	}
	return accounts, nil
}


æ–‡ä»¶è·¯å¾„: db/manage_tx_storage.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// ------------- åŸºç¡€äº¤æ˜“ -------------
func (mgr *Manager) SaveTransaction(tx *pb.Transaction) error {
	//logs.Trace("SaveTransaction %s\n", tx)
	key := KeyTx(tx.Base.TxId)
	data, err := ProtoMarshal(tx)
	if err != nil {
		return err
	}
	mgr.EnqueueSet(key, string(data))
	// å¦‚æœæ˜¯PENDING
	if tx.Base.Status == pb.Status_PENDING {
		pendingKey := KeyPendingAnyTx(tx.Base.TxId)
		mgr.EnqueueSet(pendingKey, string(data))
	}
	// 2. åŒæ—¶æŠŠå®ƒå°è£…è¿› AnyTx å¹¶å­˜ "anyTx_<txid>"
	mgr.EnqueueSet(KeyAnyTx(tx.Base.TxId), key)
	return nil
}

func (mgr *Manager) GetTransaction(txID string) (*pb.Transaction, error) {
	key := KeyTx(txID)
	val, err := mgr.Read(key)
	if err != nil {
		return nil, err
	}
	tx := &pb.Transaction{}
	if err := ProtoUnmarshal([]byte(val), tx); err != nil {
		return nil, err
	}
	return tx, nil
}

// ------------- OrderTx -------------

func (mgr *Manager) SaveOrderTx(order *pb.OrderTx) error {
	// 1. å…ˆæ‹¿åˆ° pairKey
	pairKey := utils.GeneratePairKey(order.BaseToken, order.QuoteToken)

	// 2. æŠŠ price è½¬æˆ stringKey
	priceKey, err := PriceToKey128(order.Price)
	if err != nil {
		return err
	}

	// 3. æ„é€ ç´¢å¼•key
	//    ä¾‹å¦‚: "pair:BTC_USDT|price:000000000123123|order_id:..."
	indexKey := KeyOrderPriceIndex(pairKey, order.IsFilled, priceKey, order.Base.TxId)

	// 4. å­˜å‚¨ (è·Ÿä½ ç°åœ¨çš„é€»è¾‘ä¸€æ ·ï¼Œåªæ˜¯æŠŠ "base_token_base_quote" æ›¿æ¢æˆ pairKey)
	data, err := ProtoMarshal(order)
	if err != nil {
		return err
	}
	mgr.EnqueueSet(indexKey, string(data))

	// å­˜å‚¨åŸå§‹è®¢å•
	orderKey := KeyOrderTx(order.Base.TxId)
	mgr.EnqueueSet(orderKey, string(data))
	// 5. åŒæ—¶æŠŠå®ƒå°è£…è¿› AnyTx å¹¶å­˜ "anyTx_<txid>"
	mgr.EnqueueSet(KeyAnyTx(order.Base.TxId), orderKey)
	return nil
}
func GetOrderTx(mgr *Manager, txID string) (*pb.OrderTx, error) {
	key := "order_" + txID
	val, err := mgr.Read(key)
	if err != nil {
		return nil, err
	}
	order := &pb.OrderTx{}
	if err := ProtoUnmarshal([]byte(val), order); err != nil {
		return nil, err
	}
	return order, nil
}

// å»è®¢å•IDå¯¹åº”çš„ OrderTx è¯»å–ï¼Œ
// å¢åŠ  filled_base / filled_quoteï¼Œç„¶ååˆ¤æ–­æ˜¯å¦ is_filledã€‚
func (mgr *Manager) UpdateOrderTxInDB(orderID string, tradeAmt, price decimal.Decimal) error {

	orderTx, err := GetOrderTx(mgr, orderID)
	if err != nil {
		return err
	}
	if orderTx == nil {
		return fmt.Errorf("orderTx not found: %s", orderID)
	}
	oldFilledBase, _ := decimal.NewFromString(orderTx.FilledBase)
	oldFilledQuote, _ := decimal.NewFromString(orderTx.FilledQuote)

	// å‡è®¾ base=tradeAmt, quote= tradeAmt*price
	newBase := oldFilledBase.Add(tradeAmt)
	newQuote := oldFilledQuote.Add(tradeAmt.Mul(price))

	orderTx.FilledBase = newBase.String()
	orderTx.FilledQuote = newQuote.String()

	totalBase, _ := decimal.NewFromString(orderTx.Amount)
	if newBase.Cmp(totalBase) >= 0 {
		orderTx.IsFilled = true
	}

	return mgr.SaveOrderTx(orderTx)
}
func (mgr *Manager) GetOrderTx(txID string) (*pb.OrderTx, error) {
	key := KeyOrderTx(txID)
	val, err := mgr.Read(key)
	if err != nil {
		return nil, err
	}
	order := &pb.OrderTx{}
	if err := ProtoUnmarshal([]byte(val), order); err != nil {
		return nil, err
	}
	return order, nil
}

func (mgr *Manager) SaveMinerTx(tx *pb.MinerTx) error {
	// 0) å…ˆæŠŠ MinerTx æœ¬èº«æ’å…¥å†™é˜Ÿåˆ—ï¼ˆä¿æŒä½ åŸæ¥çš„é€»è¾‘ï¼‰
	mainKey := KeyMinerTx(tx.Base.TxId)
	data, err := ProtoMarshal(tx)
	if err != nil {
		return err
	}
	mgr.EnqueueSet(mainKey, string(data))
	mgr.EnqueueSet(KeyAnyTx(tx.Base.TxId), mainKey)

	// 1) è¯»å– / åˆå§‹åŒ–è´¦æˆ·
	addr := tx.Base.FromAddress
	acc, err := mgr.GetAccount(addr)
	if err != nil {
		return err
	}
	//logs.Trace("acc.FB=%s", acc.Balances["FB"])
	// ç¡®ä¿ FB ä½™é¢å­˜åœ¨
	fb, ok := acc.Balances["FB"]
	if !ok {
		fb = NewZeroTokenBalance()
		acc.Balances["FB"] = fb
	}

	// 2) é‡‘é¢è§£æï¼ˆtx.Amount å¯èƒ½ä¸ºç©ºï¼ŒREMOVE æ—¶å¯å¿½ç•¥ï¼‰
	amt := decimal.Zero
	if tx.Amount != "" {
		amt, err = decimal.NewFromString(tx.Amount)
		if err != nil {
			return fmt.Errorf("invalid MinerTx amount=%q: %v", tx.Amount, err)
		}
	}

	switch tx.Op {
	case pb.OrderOp_ADD:
		// (ADD) 2-a åˆ¤æ–­æ˜¯å¦å·²æ˜¯çŸ¿å·¥
		if acc.IsMiner {
			// å·²æ˜¯çŸ¿å·¥ â†’ åªå¢åŠ è´¨æŠ¼
			prevLocked, _ := decimal.NewFromString(fb.MinerLockedBalance)
			fb.MinerLockedBalance = prevLocked.Add(amt).String()
		} else {
			// ä¸æ˜¯çŸ¿å·¥ â†’ åˆ†é… index & ç½® is_miner=true
			idx, tasks, err := getNewIndex(mgr)
			if err != nil {
				return err
			}
			// æŠŠ getNewIndex ç”Ÿæˆçš„å…ƒæ•°æ®å†™ä»»åŠ¡æ’è¿›é˜Ÿåˆ—
			for _, w := range tasks {
				mgr.writeQueueChan <- w
			}
			acc.Index = idx
			acc.IsMiner = true

			prevLocked, _ := decimal.NewFromString(fb.MinerLockedBalance)
			fb.MinerLockedBalance = prevLocked.Add(amt).String()
			// å­˜å…¥indexToAccount
			indexToAccount := KeyAccount(acc.Address)
			mgr.EnqueueSet(KeyIndexToAccount(idx), indexToAccount)
			mgr.IndexMgr.Add(idx) //å†…å­˜ç»´æŠ¤åœ¨çº¿çŸ¿å·¥ç´¢å¼•
		}

		// ä»å¯ç”¨ä½™é¢æ‰£é™¤
		prevBal, _ := decimal.NewFromString(fb.Balance)
		fb.Balance = prevBal.Sub(amt).String()
		//logs.Trace("fb.Balance =%s amt=%s idx=%s", fb.Balance, amt, acc.Index)

	case pb.OrderOp_REMOVE:
		// (REMOVE) å›é€€é”ä»“ + å–æ¶ˆçŸ¿å·¥æ ‡è®° + é‡Šæ”¾ index
		// 1) å›é€€ä½™é¢
		prevLocked, _ := decimal.NewFromString(fb.MinerLockedBalance)
		prevBal, _ := decimal.NewFromString(fb.Balance)
		fb.Balance = prevBal.Add(prevLocked).String()
		fb.MinerLockedBalance = "0"

		// 2) å–æ¶ˆçŸ¿å·¥èº«ä»½
		acc.IsMiner = false

		// 3) å›æ”¶ index (tx.Index å¿…é¡»åœ¨ä¸Šå±‚å¡«å¥½)
		mgr.writeQueueChan <- removeIndex(acc.Index)
		// 4) å›æ”¶indexToAccount_
		mgr.EnqueueDelete(KeyIndexToAccount(acc.Index))
		mgr.IndexMgr.Remove(acc.Index)

	default:
		return fmt.Errorf("unknown MinerTx op=%v", tx.Op)
	}

	// 3) æŠŠæ›´æ–°åçš„è´¦æˆ·å†™å›
	if err := mgr.SaveAccount(acc); err != nil {
		return err
	}

	return nil
}

// GetAnyTxById æ ¹æ®ç»™å®šçš„ tx_id ä»æ•°æ®åº“ä¸­è¯»å–å¯¹åº”çš„äº¤æ˜“ï¼ˆAnyTxï¼‰
// è¿™é‡Œå‡è®¾åœ¨ä¿å­˜æ—¶ï¼Œé™¤äº†ä¸“ç”¨å‰ç¼€å¤–ï¼Œè¿˜é¢å¤–ä¿å­˜äº†ä¸€ä¸ªé€šç”¨ key "anyTx_<txID>"
// å…¶å€¼ä¸ºå®é™…å­˜å‚¨è¯¥äº¤æ˜“çš„ keyï¼ˆå¦‚ "tx_<txID>" æˆ– "order_<txID>" ç­‰ï¼‰ã€‚
func (mgr *Manager) GetAnyTxById(txID string) (*pb.AnyTx, error) {
	// 1. å…ˆè¯»å–é€šç”¨ key "anyTx_<txID>"
	anyKey := KeyAnyTx(txID)
	specificKey, err := mgr.Read(anyKey)
	if err != nil {
		return nil, fmt.Errorf("failed to read anyTx key %s: %v", anyKey, err)
	}
	if specificKey == "" {
		return nil, fmt.Errorf("no anyTx record for txID %s", txID)
	}

	// 2. æ ¹æ®ä¸“ç”¨ keyè¯»å–å®é™…äº¤æ˜“æ•°æ®
	txData, err := mgr.Read(specificKey)
	if err != nil {
		return nil, fmt.Errorf("failed to read transaction data for key %s: %v", specificKey, err)
	}
	if txData == "" {
		return nil, fmt.Errorf("empty transaction data for key %s", specificKey)
	}

	// 3. ååºåˆ—åŒ–ä¸º AnyTx å¯¹è±¡
	var anyTx pb.AnyTx
	if err := ProtoUnmarshal([]byte(txData), &anyTx); err != nil {
		return nil, fmt.Errorf("failed to unmarshal AnyTx data: %v", err)
	}
	return &anyTx, nil
}


æ–‡ä»¶è·¯å¾„: db/mange_block.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// å°†åŒºå—å­˜å…¥DBï¼ŒåŒæ—¶å°†åŒºå—å­˜å…¥å†…å­˜åˆ‡ç‰‡ï¼ˆç¼“å­˜ï¼‰
func (mgr *Manager) SaveBlock(block *pb.Block) error {
	logs.Debug("Saving new block_%d with ID %s", block.Height, block.BlockHash)

	// 1. ä½¿ç”¨ BlockID ä½œä¸ºä¸»é”®å­˜å‚¨å®Œæ•´åŒºå—
	blockKey := KeyBlockData(block.BlockHash)
	data, err := ProtoMarshal(block)
	if err != nil {
		return err
	}
	mgr.EnqueueSet(blockKey, string(data))

	// 2. ç»´æŠ¤é«˜åº¦åˆ°åŒºå—IDåˆ—è¡¨çš„æ˜ å°„
	heightKey := KeyHeightBlocks(block.Height)
	existingIDs, _ := mgr.Read(heightKey)

	var blockIDs []string
	if existingIDs != "" {
		// è§£æç°æœ‰çš„IDåˆ—è¡¨
		json.Unmarshal([]byte(existingIDs), &blockIDs)
	}

	// æ·»åŠ æ–°çš„blockIDï¼ˆå»é‡ï¼‰
	found := false
	for _, id := range blockIDs {
		if id == block.BlockHash {
			found = true
			break
		}
	}
	if !found {
		blockIDs = append(blockIDs, block.BlockHash)
	}

	idsData, _ := json.Marshal(blockIDs)
	mgr.EnqueueSet(heightKey, string(idsData))

	// 3. IDåˆ°é«˜åº¦æ˜ å°„
	idKey := KeyBlockIDToHeight(block.BlockHash)
	mgr.EnqueueSet(idKey, strconv.FormatUint(block.Height, 10))

	// 4. æ›´æ–°æœ€æ–°åŒºå—é«˜åº¦
	mgr.EnqueueSet(KeyLatestHeight(), strconv.FormatUint(block.Height, 10))

	// 5. æ›´æ–°å†…å­˜ç¼“å­˜
	cfg := config.DefaultConfig()
	mgr.cachedBlocksMu.Lock()
	if len(mgr.cachedBlocks) >= cfg.Database.BlockCacheSize {
		mgr.cachedBlocks = mgr.cachedBlocks[1:]
	}
	mgr.cachedBlocks = append(mgr.cachedBlocks, block)
	mgr.cachedBlocksMu.Unlock()

	return nil
}

// GetBlock æ ¹æ®é«˜åº¦è·å–å¯¹åº”åŒºå—ï¼Œå…ˆçœ‹å†…å­˜ç¼“å­˜ï¼Œå†çœ‹ DB
func (mgr *Manager) GetBlock(height uint64) (*pb.Block, error) {
	// è·å–è¯¥é«˜åº¦çš„ç¬¬ä¸€ä¸ªåŒºå—ï¼ˆç”¨äºå…¼å®¹æ—§ä»£ç ï¼‰
	blocks, err := mgr.GetBlocksByHeight(height)
	if err != nil || len(blocks) == 0 {
		return nil, fmt.Errorf("no blocks at height %d", height)
	}
	return blocks[0], nil
}

func (mgr *Manager) GetBlocksByHeight(height uint64) ([]*pb.Block, error) {
	// 1. ä»é«˜åº¦æ˜ å°„è·å–æ‰€æœ‰åŒºå—ID
	heightKey := KeyHeightBlocks(height)
	idsStr, err := mgr.Read(heightKey)
	if err != nil {
		return nil, err
	}

	var blockIDs []string
	if err := json.Unmarshal([]byte(idsStr), &blockIDs); err != nil {
		return nil, err
	}

	// 2. è·å–æ¯ä¸ªåŒºå—
	var blocks []*pb.Block
	for _, id := range blockIDs {
		block, err := mgr.GetBlockByID(id)
		if err == nil && block != nil {
			blocks = append(blocks, block)
		}
	}

	return blocks, nil
}

// GetBlockByID æ ¹æ®åŒºå—IDï¼ˆBlockHashï¼‰è·å–åŒºå—
func (mgr *Manager) GetBlockByID(blockID string) (*pb.Block, error) {
	// 1. å…ˆæ£€æŸ¥ç¼“å­˜
	mgr.cachedBlocksMu.RLock()
	for _, b := range mgr.cachedBlocks {
		if b != nil && b.BlockHash == blockID {
			mgr.cachedBlocksMu.RUnlock()
			return b, nil
		}
	}
	mgr.cachedBlocksMu.RUnlock()

	// 2. ç›´æ¥ä» blockdata_<blockID> è¯»å–
	blockKey := KeyBlockData(blockID)
	val, err := mgr.Read(blockKey)
	if err != nil {
		return nil, fmt.Errorf("block %s not found", blockID)
	}

	block := &pb.Block{}

	if err := ProtoUnmarshal([]byte(val), block); err != nil {
		return nil, err
	}

	return block, nil
}

// å½“æ²¡æœ‰IDæ˜ å°„æ—¶çš„é™çº§æ–¹æ¡ˆï¼ˆéå†æŸ¥æ‰¾ï¼‰
func (mgr *Manager) getBlockByIDFallback(blockID string) (*pb.Block, error) {
	// è·å–æœ€æ–°é«˜åº¦
	latestHeight, err := mgr.GetLatestBlockHeight()
	if err != nil {
		return nil, fmt.Errorf("failed to get latest height: %v", err)
	}

	// ä»æœ€æ–°é«˜åº¦å‘å‰éå†æŸ¥æ‰¾ï¼ˆé€šå¸¸æœ€è¿‘çš„åŒºå—è¢«æŸ¥è¯¢çš„æ¦‚ç‡æ›´é«˜ï¼‰
	for h := latestHeight; h > 0; h-- {
		block, err := mgr.GetBlock(h)
		if err != nil {
			continue // è·³è¿‡ä¸å­˜åœ¨çš„é«˜åº¦
		}
		if block.BlockHash == blockID {
			// æ‰¾åˆ°äº†ï¼Œé¡ºä¾¿å»ºç«‹æ˜ å°„å…³ç³»ä»¥åŠ é€Ÿåç»­æŸ¥è¯¢
			idKey := KeyBlockIDToHeight(blockID)
			mgr.EnqueueSet(idKey, strconv.FormatUint(h, 10))
			return block, nil
		}
	}

	// æ£€æŸ¥åˆ›ä¸–åŒºå—
	genesis, err := mgr.GetBlock(0)
	if err == nil && genesis.BlockHash == blockID {
		return genesis, nil
	}

	return nil, fmt.Errorf("block with ID %s not found", blockID)
}

// GetLatestBlockHeight ç›´æ¥ä» "latest_block_height" é”®ä¸­è¯»å–æœ€æ–°çš„åŒºå—é«˜åº¦
func (mgr *Manager) GetLatestBlockHeight() (uint64, error) {
	latestKey := KeyLatestHeight()
	val, err := mgr.Read(latestKey)
	if err != nil {
		return 0, err
	}
	height, err := strconv.ParseUint(val, 10, 64)
	if err != nil {
		return 0, err
	}
	return height, nil
}

// è·å–æŒ‡å®šé«˜åº¦èŒƒå›´å†…çš„æ‰€æœ‰åŒºå—
func (mgr *Manager) GetBlocksByRange(fromHeight, toHeight uint64) ([]*pb.Block, error) {
	if fromHeight > toHeight {
		return nil, fmt.Errorf("invalid range: from %d to %d", fromHeight, toHeight)
	}

	blocks := make([]*pb.Block, 0, toHeight-fromHeight+1)
	for h := fromHeight; h <= toHeight; h++ {
		block, err := mgr.GetBlock(h)
		if err != nil {
			// è·³è¿‡ä¸å­˜åœ¨çš„é«˜åº¦
			logs.Debug("[GetBlocksByRange] Skip height %d: %v", h, err)
			continue
		}
		blocks = append(blocks, block)
	}

	return blocks, nil
}

// BlockExists æ£€æŸ¥æŒ‡å®šIDçš„åŒºå—æ˜¯å¦å­˜åœ¨
func (mgr *Manager) BlockExists(blockID string) bool {
	// 1. å…ˆæ£€æŸ¥ç¼“å­˜
	mgr.cachedBlocksMu.RLock()
	for _, b := range mgr.cachedBlocks {
		if b != nil && b.BlockHash == blockID {
			mgr.cachedBlocksMu.RUnlock()
			return true
		}
	}
	mgr.cachedBlocksMu.RUnlock()

	// 2. æ£€æŸ¥æ•°æ®åº“ä¸­çš„IDæ˜ å°„
	idKey := KeyBlockIDToHeight(blockID)
	_, err := mgr.Read(idKey)
	return err == nil
}


æ–‡ä»¶è·¯å¾„: db/mange_client.go
æ–‡ä»¶å†…å®¹:
package db

import (...)
// SaveClientInfo æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) SaveClientInfo(info *pb.ClientInfo) error {
	key := KeyClientInfo(info.Ip)
	data, err := ProtoMarshal(info)
	if err != nil {
		return err
	}
	mgr.EnqueueSet(key, string(data))
	return nil
}

// GetClientInfo æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) GetClientInfo(ip string) (*pb.ClientInfo, error) {
	key := KeyClientInfo(ip)
	val, err := mgr.Read(key)
	if err != nil {
		return nil, err
	}
	info := &pb.ClientInfo{}
	if err := ProtoUnmarshal([]byte(val), info); err != nil {
		return nil, err
	}
	return info, nil
}


æ–‡ä»¶è·¯å¾„: db/mange_node.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// GetAllNodeInfos æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) GetAllNodeInfos() ([]*pb.NodeInfo, error) {
	var nodes []*pb.NodeInfo
	err := mgr.Db.View(func(txn *badger.Txn) error {
		it := txn.NewIterator(badger.DefaultIteratorOptions)
		defer it.Close()

		prefix := []byte(KeyNode())
		for it.Seek(prefix); it.ValidForPrefix(prefix); it.Next() {
			item := it.Item()
			val, err := item.ValueCopy(nil)
			if err != nil {
				return err
			}
			var node pb.NodeInfo
			if err := proto.Unmarshal(val, &node); err != nil {
				return err
			}
			nodes = append(nodes, &node)
		}
		return nil
	})
	if err != nil {
		return nil, err
	}
	return nodes, nil
}

// SaveNodeInfo æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) SaveNodeInfo(node *pb.NodeInfo) error {
	data, err := ProtoMarshal(node)
	if err != nil {
		return err
	}
	key := KeyNode() + node.PublicKey
	mgr.EnqueueSet(key, string(data))
	return nil
}


æ–‡ä»¶è·¯å¾„: db/mange_pending_anytx.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// SavePendingAnyTx æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) SavePendingAnyTx(tx *pb.AnyTx) error {
	txID := tx.GetTxId()
	if txID == "" {
		return fmt.Errorf("SavePendingAnyTx: empty txID")
	}
	data, err := ProtoMarshal(tx)
	if err != nil {
		return err
	}
	key := KeyPendingAnyTx(txID)
	mgr.EnqueueSet(key, string(data))
	return nil
}

// DeletePendingAnyTx æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) DeletePendingAnyTx(txID string) error {
	if txID == "" {
		return fmt.Errorf("DeletePendingAnyTx: empty txID")
	}
	key := KeyPendingAnyTx(txID)
	mgr.EnqueueDelete(key)
	return nil
}

// LoadPendingAnyTx æ”¹ä¸ºæˆå‘˜å‡½æ•°
func (mgr *Manager) LoadPendingAnyTx() ([]*pb.AnyTx, error) {
	mgr.mu.RLock()
	db := mgr.Db
	mgr.mu.RUnlock()
	if db == nil {
		return nil, fmt.Errorf("database is not initialized or closed")
	}
	var result []*pb.AnyTx

	err := db.View(func(txn *badger.Txn) error {
		it := txn.NewIterator(badger.DefaultIteratorOptions)
		defer it.Close()

		prefix := []byte(KeyPendingAnyTx(""))
		for it.Seek(prefix); it.ValidForPrefix(prefix); it.Next() {
			item := it.Item()
			val, e := item.ValueCopy(nil)
			if e != nil {
				return e
			}
			var anyTx pb.AnyTx
			if uerr := proto.Unmarshal(val, &anyTx); uerr != nil {
				continue
			}
			result = append(result, &anyTx)
		}
		return nil
	})
	if err != nil {
		return nil, err
	}
	return result, nil
}


æ–‡ä»¶è·¯å¾„: db/mange_price.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

var (
	minPrice = decimal.NewFromFloat(1e-33)
	maxPrice = decimal.NewFromFloat(1e33)
)

// PriceToKey128 å°† priceStr è½¬æ¢ä¸ºé•¿åº¦ 67 çš„åè¿›åˆ¶å­—ç¬¦ä¸²ï¼Œç”¨äºæœ‰åºæ¯”è¾ƒ
func PriceToKey128(priceStr string) (string, error) {
	price, err := decimal.NewFromString(priceStr)
	if err != nil {
		return "", fmt.Errorf("invalid price string %q: %v", priceStr, err)
	}
	if price.Cmp(minPrice) < 0 || price.Cmp(maxPrice) > 0 {
		return "", fmt.Errorf("price out of range [1e-33, 1e33], got=%s", priceStr)
	}
	shift := decimal.NewFromFloat(1e33)
	shifted := price.Mul(shift)
	shiftedInt := shifted.BigInt()
	decStr := shiftedInt.String()

	const totalLen = 67
	padNeeded := totalLen - len(decStr)
	if padNeeded < 0 {
		return "", fmt.Errorf("price exponent overflow > 1e66, got=%s", priceStr)
	}
	zeroPad := strings.Repeat("0", padNeeded)
	return zeroPad + decStr, nil
}

// KeyToPriceDecimal è§£æ 67 ä½å­—ç¬¦ä¸²ï¼Œå† /1e33
func KeyToPriceDecimal(priceKey string) (decimal.Decimal, error) {
	if len(priceKey) != 67 {
		return decimal.Zero, fmt.Errorf("priceKey length != 67: got %d", len(priceKey))
	}
	i := new(big.Int)
	if _, ok := i.SetString(priceKey, 10); !ok {
		return decimal.Zero, fmt.Errorf("invalid decimal digits in key: %s", priceKey)
	}
	decVal := decimal.NewFromBigInt(i, 0)
	oneE33 := decimal.New(1, 33)
	return decVal.Div(oneE33), nil
}


æ–‡ä»¶è·¯å¾„: db/miner_index_manager.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

// MinerIndexManager è´Ÿè´£ï¼š
//  1. å¯åŠ¨æ—¶æ‰«æ Badgerï¼Œæ¢å¤æ´»è·ƒçŸ¿å·¥ç´¢å¼•åˆ° RoaringBitmapï¼›
//  2. è¿è¡Œä¸­å®æ—¶ Add / Removeï¼›
//  3. æä¾›é«˜æ€§èƒ½é‡‡æ · SampleKã€‚
type MinerIndexManager struct {
	mu     sync.RWMutex
	bitmap *roaring.Bitmap
	db     *badger.DB
}

// ----------  åˆå§‹åŒ– / æ¢å¤  ----------

func NewMinerIndexManager(db *badger.DB) (*MinerIndexManager, error) {
	m := &MinerIndexManager{
		db:     db,
		bitmap: roaring.New(),
	}
	if err := m.RebuildBitmapFromDB(); err != nil {
		return nil, err
	}
	return m, nil
}

// åœ¨ä¸€æ¬¡åªè¯»äº‹åŠ¡é‡Œè¿­ä»£æ‰€æœ‰ "indexToAccount_*" é”®ï¼Œå¡«å…… bitmapã€‚
func (m *MinerIndexManager) RebuildBitmapFromDB() error {
	prefix := []byte(NameOfKeyIndexToAccount())

	return m.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close()

		count := 0
		for it.Seek(prefix); it.ValidForPrefix(prefix); it.Next() {
			key := it.Item().Key()
			idxBytes := key[len(prefix):]
			idx, err := strconv.ParseUint(string(idxBytes), 10, 64)
			if err != nil {
				continue
			}
			m.bitmap.Add(uint32(idx))
			count++
		}
		logs.Info("[MinerIndexManager] rebuilt bitmap with %d miners", count)
		return nil
	})
}

// ----------  è¿è¡Œæ—¶ç»´æŠ¤  ----------

func (m *MinerIndexManager) Add(idx uint64) {
	m.mu.Lock()
	m.bitmap.Add(uint32(idx))
	m.mu.Unlock()
}

func (m *MinerIndexManager) Remove(idx uint64) {
	m.mu.Lock()
	m.bitmap.Remove(uint32(idx))
	m.mu.Unlock()
}

// ----------  é«˜æ€§èƒ½é‡‡æ ·  ----------

func (m *MinerIndexManager) SampleK(k int) ([]uint64, error) {
	m.mu.RLock()
	defer m.mu.RUnlock()

	card := int(m.bitmap.GetCardinality())
	if card == 0 {
		return nil, nil // æ²¡æœ‰çŸ¿å·¥
	}
	if k > card {
		k = card
	}

	res := make([]uint64, 0, k)
	rng := rand.New(rand.NewSource(time.Now().UnixNano()))
	seen := make(map[uint32]struct{}, k)

	for len(res) < k {
		r := uint32(rng.Intn(card)) // [0, card)
		v, _ := m.bitmap.Select(r)  // O(log64 N)
		if _, dup := seen[v]; dup {
			continue
		}
		seen[v] = struct{}{}
		res = append(res, uint64(v))
	}
	return res, nil
}


æ–‡ä»¶è·¯å¾„: db/queue.go
æ–‡ä»¶å†…å®¹:
package db

type WriteTask struct {
	Key   []byte
	Value []byte
	Op    WriteOp // å¯ä»¥æ˜¯ â€œSetâ€ or â€œDeleteâ€
}

type WriteOp int

const (
	OpSet WriteOp = iota
	OpDelete
)


æ–‡ä»¶è·¯å¾„: db/utils.go
æ–‡ä»¶å†…å®¹:
package db

import (...)

func ProtoMarshal(m proto.Message) ([]byte, error) {
	return proto.Marshal(m)
}

func ProtoUnmarshal(data []byte, m proto.Message) error {
	return proto.Unmarshal(data, m)
}

// DeleteKey ä¸€ä¸ªDeleteKeyå·¥å…·
func (manager *Manager) DeleteKey(key string) error {
	manager.mu.RLock()
	db := manager.Db
	manager.mu.RUnlock()

	if db == nil {
		return fmt.Errorf("database is not initialized or closed")
	}

	return db.Update(func(txn *badger.Txn) error {
		return txn.Delete([]byte(key))
	})
}

// getNewIndex åªåšåªè¯»æ“ä½œï¼Œè®¡ç®—â€œåº”è¯¥ç”¨å“ªä¸ªä¸‹æ ‡â€
// å¹¶è¿”å›ï¼š
//
//	idx      -> æ–°åˆ†é…çš„ä¸‹æ ‡
//	tasks    -> ä¸ºä¿æŒä¸€è‡´æ€§å¿…é¡»è¿½åŠ åˆ°å†™é˜Ÿåˆ—é‡Œçš„ WriteTask åˆ‡ç‰‡
func getNewIndex(mgr *Manager) (uint64, []WriteTask, error) {
	var (
		idx        uint64
		tasks      []WriteTask
		freeIdxKey []byte
	)

	// â‘  åªè¯»äº‹åŠ¡ï¼šå°è¯•å¯»æ‰¾å¯å¤ç”¨çš„ free_idx_*
	err := mgr.Db.View(func(txn *badger.Txn) error {
		itOpts := badger.DefaultIteratorOptions
		itOpts.Prefix = []byte(KeyFreeIdx())
		it := txn.NewIterator(itOpts)
		defer it.Close()

		it.Rewind()
		if it.Valid() {
			// æ‰¾åˆ°äº†å¯å¤ç”¨çš„ index
			freeIdxKey = it.Item().KeyCopy(nil)
			idxStr := bytes.TrimPrefix(freeIdxKey, []byte(KeyFreeIdx()))
			i, _ := strconv.ParseUint(string(idxStr), 10, 64)
			idx = i
			return nil
		}

		// æ²¡æœ‰ç©ºé—² -> å°è¯•è¯»å– meta:max_index
		idx = 0

		return nil

	})
	if err != nil {
		return 0, nil, err
	}
	if idx == 0 {
		idx, _ = mgr.NextIndex()
	}
	// â‘¡ ç”Ÿæˆå†™å…¥ä»»åŠ¡
	if freeIdxKey != nil {
		// å¤ç”¨ indexï¼Œéœ€è¦åˆ é™¤ free_idx_<idx>
		tasks = append(tasks, WriteTask{
			Key: freeIdxKey,
			Op:  OpDelete,
		})
	}

	return idx, tasks, nil
}

func removeIndex(idx uint64) WriteTask {
	k := []byte(fmt.Sprintf(KeyFreeIdx()+"%020d", idx))
	return WriteTask{Key: k, Op: OpSet} // å€¼ä¸ºç©ºå³å¯ï¼Œä¹Ÿå¯ä»¥å­˜æ—¶é—´æˆ³
}

// HashTx æ¥å—ä»»æ„äº¤æ˜“æ¶ˆæ¯ï¼ˆproto.Messageï¼‰ï¼Œå¹¶è¿”å›å…¶å“ˆå¸Œå€¼ï¼ˆæ’é™¤ BaseMessage.TxId å­—æ®µï¼‰ã€‚

// HashTx æ¥å—ä»»æ„äº¤æ˜“æ¶ˆæ¯ï¼ˆproto.Messageï¼‰ï¼Œå¹¶è¿”å›å…¶å“ˆå¸Œå€¼ã€‚
// åœ¨è®¡ç®— hash æ—¶ï¼Œæ’é™¤äº† BaseMessage ä¸­çš„ tx_id å’Œ signature å­—æ®µã€‚
func HashTx(tx proto.Message) (string, error) {
	// å…‹éš†ä¸€ä»½æ¶ˆæ¯ï¼Œé¿å…ä¿®æ”¹åŸå§‹å¯¹è±¡
	txCopy := proto.Clone(tx)

	// æ ¹æ®ä¸åŒçš„ tx ç±»å‹ï¼Œæ¸…ç©ºå…¶ä¸­ BaseMessage çš„ tx_id å’Œ signature å­—æ®µ
	switch t := txCopy.(type) {
	case *pb.IssueTokenTx:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}
	case *pb.FreezeTx:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}
	case *pb.Transaction:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}
	case *pb.OrderTx:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}
	case *pb.CandidateTx:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}
	case *pb.MinerTx:
		if t.Base != nil {
			t.Base.TxId = ""
			t.Base.Signature = ""
		}

	case *pb.AnyTx:
		// å¯¹äº AnyTxï¼Œéœ€è¦åˆ¤æ–­å½“å‰å­˜æ”¾çš„æ˜¯å“ªç§ txï¼Œå¹¶æ¸…ç©ºå…¶ä¸­çš„ BaseMessage ä¸­ç›¸å…³å­—æ®µ
		switch content := t.Content.(type) {
		case *pb.AnyTx_IssueTokenTx:
			if content.IssueTokenTx.Base != nil {
				content.IssueTokenTx.Base.TxId = ""
				content.IssueTokenTx.Base.Signature = ""
			}
		case *pb.AnyTx_FreezeTx:
			if content.FreezeTx.Base != nil {
				content.FreezeTx.Base.TxId = ""
				content.FreezeTx.Base.Signature = ""
			}
		case *pb.AnyTx_Transaction:
			if content.Transaction.Base != nil {
				content.Transaction.Base.TxId = ""
				content.Transaction.Base.Signature = ""
			}
		case *pb.AnyTx_OrderTx:
			if content.OrderTx.Base != nil {
				content.OrderTx.Base.TxId = ""
				content.OrderTx.Base.Signature = ""
			}
		case *pb.AnyTx_AddressTx:
			if content.AddressTx.Base != nil {
				content.AddressTx.Base.TxId = ""
				content.AddressTx.Base.Signature = ""
			}
		case *pb.AnyTx_CandidateTx:
			if content.CandidateTx.Base != nil {
				content.CandidateTx.Base.TxId = ""
				content.CandidateTx.Base.Signature = ""
			}

		default:
			return "", fmt.Errorf("ä¸æ”¯æŒçš„ AnyTx å†…éƒ¨ç±»å‹")
		}
	default:
		return "", fmt.Errorf("ä¸æ”¯æŒçš„äº¤æ˜“ç±»å‹")
	}

	// ä½¿ç”¨ proto.Marshal åºåˆ—åŒ–ä¸ºå­—èŠ‚æ•°ç»„
	data, err := proto.Marshal(txCopy)
	if err != nil {
		return "", err
	}

	// è®¡ç®— SHA256 å“ˆå¸Œå€¼ï¼Œå¹¶ä»¥åå…­è¿›åˆ¶å­—ç¬¦ä¸²è¿”å›
	hashBytes := sha256.Sum256(data)
	return hex.EncodeToString(hashBytes[:]), nil
}


æ–‡ä»¶è·¯å¾„: handlers/handleBatchGetTx.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†æ‰¹é‡è·å–äº¤æ˜“è¯·æ±‚
func (hm *HandlerManager) HandleBatchGetTx(w http.ResponseWriter, r *http.Request) {

	hm.Stats.RecordAPICall("HandleBatchGetTx")
	if !hm.checkAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}

	var req pb.BatchGetShortTxRequest
	if err := proto.Unmarshal(bodyBytes, &req); err != nil {
		http.Error(w, "Invalid BatchGetDataRequest proto", http.StatusBadRequest)
		return
	}

	matchedTxs := hm.txPool.GetTxsByShortHashes(req.ShortHashes, true)
	resp := &pb.BatchGetShortTxResponse{
		Transactions: matchedTxs,
	}

	respBytes, _ := proto.Marshal(resp)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)
	w.Write(respBytes)
}


æ–‡ä»¶è·¯å¾„: handlers/handleBlockGossip.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å‘é€ç«¯ gossip å‘çš„æ˜¯ JSON çš„ types.GossipPayloadï¼ˆé‡Œå¤´åµŒ db.Blockï¼‰
// è¿™é‡Œåªè§£æè¿™ä¸€ç§ï¼›ä¸åšå…¶ä»–æ ¼å¼å…œåº•ã€‚
func (hm *HandlerManager) HandleBlockGossip(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleBlockGossip0")

	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}
	defer r.Body.Close()

	var payload types.GossipPayload
	if err := json.Unmarshal(bodyBytes, &payload); err != nil {
		http.Error(w, "Failed to parse JSON GossipPayload", http.StatusBadRequest)
		return
	}
	if payload.Block == nil {
		http.Error(w, "GossipPayload missing block", http.StatusBadRequest)
		return
	}

	// è½¬ä¸ºå…±è¯†å±‚ block
	if hm.adapter == nil {
		http.Error(w, "adapter unavailable", http.StatusServiceUnavailable)
		return
	}
	consBlock, err := hm.adapter.DBBlockToConsensus(payload.Block)
	if err != nil {
		http.Error(w, "Failed to convert block", http.StatusBadRequest)
		return
	}

	// å·²è§è¿‡çš„åŒºå—ç›´æ¥è¿”å› OKï¼ˆå¯é€‰ï¼ŒæŒ‰ä½ ç°æœ‰å­—æ®µï¼‰
	if hm.seenBlocksCache != nil && consBlock.ID != "" && hm.seenBlocksCache.Contains(consBlock.ID) {
		logs.Debug("[HandleBlockGossip] Block %s already seen, OK", consBlock.ID)
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("OK"))
		return
	}
	if hm.seenBlocksCache != nil && consBlock.ID != "" {
		hm.seenBlocksCache.Add(consBlock.ID, true)
	}

	// ç»Ÿè®¡ç‚¹ä½
	hm.Stats.RecordAPICall("HandleBlockGossip1")

	// äº¤ç»™å…±è¯†/ç½‘ç»œå±‚
	msg := types.Message{
		RequestID: payload.RequestID,
		Type:      types.MsgGossip,
		From:      types.NodeID(consBlock.Proposer),
		Block:     consBlock,
		BlockID:   consBlock.ID,
		Height:    consBlock.Height,
	}

	// å°† dbBlock åŠ åˆ°å…±è¯†å­˜å‚¨ï¼ˆç›´æ¥ç”¨ payload é‡Œçš„ db.Block å³å¯ï¼‰
	if hm.consensusManager != nil {
		if err := hm.consensusManager.AddBlock(payload.Block); err != nil {
			logs.Debug("[HandleBlockGossip] AddBlock warn: %v", err) // å·²å­˜åœ¨ç­‰éè‡´å‘½é”™è¯¯
		}
		if rt, ok := hm.consensusManager.Transport.(*consensus.RealTransport); ok {
			if err := rt.EnqueueReceivedMessage(msg); err != nil {
				logs.Warn("[HandleBlockGossip] Enqueue gossip message failed: %v", err)
			}
		}
	}

	// å°†äº¤æ˜“æ”¾å…¥äº¤æ˜“æ± 
	if len(payload.Block.Body) > 0 {
		for _, tx := range payload.Block.Body {
			if tx != nil {
				if err := hm.txPool.StoreAnyTx(tx); err != nil {
					logs.Debug("[HandleBlockGossip] Failed to store tx %s: %v", tx.GetTxId(), err)
				}
			}
		}
	}

	logs.Debug("[HandleBlockGossip] Block %s at height %d proposer=%s",
		consBlock.ID, consBlock.Height, consBlock.Proposer)

	w.WriteHeader(http.StatusOK)
	w.Write([]byte("OK"))
}


æ–‡ä»¶è·¯å¾„: handlers/handleChits.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

func (hm *HandlerManager) HandleChits(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleChits")
	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}

	var chits pb.Chits
	if err := proto.Unmarshal(bodyBytes, &chits); err != nil {
		http.Error(w, "Invalid Chits proto", http.StatusBadRequest)
		return
	}

	// è½¬æ¢ä¸ºå…±è¯†æ¶ˆæ¯å¹¶å¤„ç†
	if hm.adapter != nil {
		// ä½¿ç”¨ chits.Address è€Œä¸æ˜¯ä» RemoteAddr æ¨æ–­
		senderAddress := chits.Address

		// éªŒè¯å‘é€æ–¹
		if !hm.verifyNodeIdentity(senderAddress, &chits) {
			http.Error(w, "Invalid sender", http.StatusUnauthorized)
			return
		}

		from := types.NodeID(senderAddress)
		msg := hm.adapter.ChitsToConsensusMessage(&chits, from)

		// å¦‚æœæ˜¯RealTransportï¼Œä½¿ç”¨é˜Ÿåˆ—æ–¹å¼å¤„ç†
		if rt, ok := hm.consensusManager.Transport.(*consensus.RealTransport); ok {
			if err := rt.EnqueueReceivedMessage(msg); err != nil {
				logs.Warn("[Handler] Failed to enqueue chits message: %v", err)
				// æ§åˆ¶é¢æ¶ˆæ¯å…¥é˜Ÿå¤±è´¥ï¼Œè¿”å› 503
				http.Error(w, "Service temporarily unavailable", http.StatusServiceUnavailable)
				return
			}
		}
	}

	w.WriteHeader(http.StatusOK)
}


æ–‡ä»¶è·¯å¾„: handlers/handleGetBlock.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†è·å–åŒºå—è¯·æ±‚
func (hm *HandlerManager) HandleGetBlock(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleGetBlock")
	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}

	var req pb.GetBlockRequest
	if err := proto.Unmarshal(bodyBytes, &req); err != nil {
		http.Error(w, "Invalid GetBlockRequest proto", http.StatusBadRequest)
		return
	}

	// ä½¿ç”¨æ³¨å…¥çš„dbManagerè€Œä¸æ˜¯åˆ›å»ºæ–°å®ä¾‹
	block, err := hm.dbManager.GetBlock(req.Height)
	if err != nil || block == nil {
		resp := &pb.GetBlockResponse{
			Error: fmt.Sprintf("Block not found at height %d", req.Height),
		}
		respBytes, _ := proto.Marshal(resp)
		w.Header().Set("Content-Type", "application/x-protobuf")
		w.WriteHeader(http.StatusNotFound)
		w.Write(respBytes)
		return
	}

	resp := &pb.GetBlockResponse{
		Block: block,
	}
	respBytes, err := proto.Marshal(resp)
	if err != nil {
		http.Error(w, "Failed to marshal GetBlockResponse", http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Encoding", "gzip")
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)

	gz := gzip.NewWriter(w)
	defer gz.Close()
	gz.Write(respBytes)
}


æ–‡ä»¶è·¯å¾„: handlers/handleGetData.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// HandleGetData å¤„ç†æ¥è‡ªå¯¹ç­‰èŠ‚ç‚¹çš„ /getdata è¯·æ±‚ã€‚
// å®¢æˆ·ç«¯ä¼šå‘é€ GetData æ¶ˆæ¯ï¼ˆåŒ…å« tx_idï¼‰ï¼ŒæœåŠ¡å™¨æŸ¥æ‰¾è¯¥ txï¼ˆä¾‹å¦‚ AnyTx æˆ– Transactionï¼‰ï¼Œ
// å¹¶å°†å®Œæ•´äº¤æ˜“æ•°æ®è¿”å›ç»™è¯·æ±‚è€…ã€‚

// å¤„ç†è·å–äº¤æ˜“æ•°æ®è¯·æ±‚
func (hm *HandlerManager) HandleGetData(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleGetData")
	if !hm.checkAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read getdata request body", http.StatusBadRequest)
		return
	}

	var getDataMsg pb.GetData
	if err := proto.Unmarshal(bodyBytes, &getDataMsg); err != nil {
		http.Error(w, "Invalid GetData proto", http.StatusBadRequest)
		return
	}

	// å…ˆä»TxPoolæŸ¥æ‰¾
	txFromPool := hm.txPool.GetTransactionById(getDataMsg.TxId)
	if txFromPool != nil {
		respData, _ := proto.Marshal(txFromPool)
		w.Header().Set("Content-Type", "application/x-protobuf")
		w.WriteHeader(http.StatusOK)
		w.Write(respData)
		return
	}

	// ä»æ•°æ®åº“æŸ¥æ‰¾
	anyTx, err := hm.dbManager.GetAnyTxById(getDataMsg.TxId)
	if err != nil || anyTx == nil {
		http.Error(w, fmt.Sprintf("Transaction %s not found", getDataMsg.TxId), http.StatusNotFound)
		return
	}

	respData, _ := proto.Marshal(anyTx)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)
	w.Write(respData)
}

func (hm *HandlerManager) HandleGet(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleGet")
	if !hm.checkAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}
	body, _ := io.ReadAll(r.Body)
	var req pb.GetBlockByIDRequest
	if err := proto.Unmarshal(body, &req); err != nil {
		http.Error(w, "Invalid GetBlockByID proto", http.StatusBadRequest)
		return
	}
	blk, err := hm.dbManager.GetBlockByID(req.BlockId)
	if err != nil || blk == nil {
		http.Error(w, fmt.Sprintf("Block %s not found", req.BlockId), http.StatusNotFound)
		return
	}
	resp := &pb.GetBlockResponse{Block: blk}
	bytes, _ := proto.Marshal(resp)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)
	w.Write(bytes)
}


æ–‡ä»¶è·¯å¾„: handlers/handleHeightQuery.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

func (hm *HandlerManager) HandleHeightQuery(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleHeightQuery")
	// è¿”å›å½“å‰èŠ‚ç‚¹çš„é«˜åº¦ä¿¡æ¯
	_, height := hm.consensusManager.GetLastAccepted()
	currentHeight := hm.consensusManager.GetCurrentHeight()

	resp := &pb.HeightResponse{ // éœ€è¦åœ¨protoä¸­å®šä¹‰
		LastAcceptedHeight: height,
		CurrentHeight:      currentHeight,
	}

	data, _ := proto.Marshal(resp)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.Write(data)
}


æ–‡ä»¶è·¯å¾„: handlers/handleNodes.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†èŠ‚ç‚¹åˆ—è¡¨è¯·æ±‚
func (hm *HandlerManager) HandleNodes(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleNodes")
	if !hm.checkAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	nodes, err := hm.dbManager.GetAllNodeInfos()
	if err != nil {
		http.Error(w, "Failed to get nodes", http.StatusInternalServerError)
		return
	}

	nodeList := &pb.NodeList{
		Nodes: nodes,
	}
	data, _ := proto.Marshal(nodeList)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.Write(data)
}


æ–‡ä»¶è·¯å¾„: handlers/handlePull.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†PullQueryè¯·æ±‚ï¼ˆSnowmanå…±è¯†ï¼‰
func (hm *HandlerManager) HandlePullQuery(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandlePullQuery")
	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}

	var pullQuery pb.PullQuery
	if err := proto.Unmarshal(bodyBytes, &pullQuery); err != nil {
		http.Error(w, "Invalid PullQuery proto", http.StatusBadRequest)
		return
	}

	// æ„é€ æ¶ˆæ¯å¹¶å°è¯•å…¥é˜Ÿ
	msg := types.Message{
		RequestID: pullQuery.RequestId,
		Type:      types.MsgPullQuery,
		From:      types.NodeID(pullQuery.Address),
		BlockID:   pullQuery.BlockId,
		Height:    pullQuery.RequestedHeight,
	}

	if rt, ok := hm.consensusManager.Transport.(*consensus.RealTransport); ok {
		if err := rt.EnqueueReceivedMessage(msg); err != nil {
			logs.Warn("[Handler] Failed to enqueue PullQuery: %v", err)
			http.Error(w, "Service temporarily unavailable", http.StatusServiceUnavailable)
			return
		}
	}

	w.WriteHeader(http.StatusOK)
}


æ–‡ä»¶è·¯å¾„: handlers/handlePush.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†PushQueryè¯·æ±‚ï¼ˆSnowmanå…±è¯†ï¼‰
func (hm *HandlerManager) HandlePushQuery(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandlePushQuery")
	bodyBytes, _ := io.ReadAll(r.Body)

	var pushQuery pb.PushQuery
	proto.Unmarshal(bodyBytes, &pushQuery)
	// ä½¿ç”¨ pushQuery.Address è€Œä¸æ˜¯ä» IP æ¨æ–­
	senderAddress := pushQuery.Address
	// éªŒè¯å‘é€æ–¹èº«ä»½ï¼ˆé€šè¿‡ç­¾åæˆ–å…¶ä»–æœºåˆ¶ï¼‰
	if !hm.verifyNodeIdentity(senderAddress, pushQuery) {
		http.Error(w, "Invalid node identity", http.StatusUnauthorized)
		return
	}
	// 1ã€æ£€æŸ¥å†…å­˜txpoolæ˜¯å¦å­˜åœ¨
	// 2ã€æ ¡éªŒåˆæ³•æ€§
	// 3ã€ä½¿ç”¨ adapter è½¬æ¢
	msg, err := hm.adapter.PushQueryToConsensusMessage(&pushQuery, types.NodeID(senderAddress))
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	// 4ã€ä¸¢è¿›å…±è¯†ï¼Œå¤„ç†æ¶ˆæ¯
	// å¦‚æœtransportæ˜¯RealTransportï¼Œä½¿ç”¨é˜Ÿåˆ—æ–¹å¼
	if rt, ok := hm.consensusManager.Transport.(*consensus.RealTransport); ok {
		if err := rt.EnqueueReceivedMessage(msg); err != nil {
			logs.Warn("[Handler] Failed to enqueue message: %v", err)
			// è¿”å› 503 Service Unavailableï¼Œä¿ƒä½¿å‘é€æ–¹é€€é¿é‡è¯•
			http.Error(w, "Service temporarily unavailable", http.StatusServiceUnavailable)
			return
		}
	}

	// 5ã€ç”Ÿæˆå“åº”ç›´æ¥è¿”å› 200 OKï¼Œä¸è¿”å› chits
	w.WriteHeader(http.StatusOK)
}


æ–‡ä»¶è·¯å¾„: handlers/handlePut.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å‘é€ç«¯ /put å‘çš„æ˜¯ protobuf çš„ db.Blockï¼Œè¿™é‡Œåªè§£æè¿™ä¸€ç§
func (hm *HandlerManager) HandlePut(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandlePut")

	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}
	defer r.Body.Close()

	var block pb.Block
	if err := proto.Unmarshal(bodyBytes, &block); err != nil {
		http.Error(w, "Failed to parse protobuf db.Block", http.StatusBadRequest)
		return
	}

	// åŸºæœ¬æ ¡éªŒï¼ˆæŒ‰ä½ é¡¹ç›®ä¹ æƒ¯æ¥ï¼Œå¯ä¿ç•™ï¼‰
	if block.BlockHash == "" || block.BlockHash == "genesis" {
		http.Error(w, "Invalid block hash", http.StatusBadRequest)
		return
	}

	// ä¿å­˜åŒºå—
	if err := hm.dbManager.SaveBlock(&block); err != nil {
		logs.Error("[HandlePut] Failed to save block %s: %v", block.BlockHash, err)
		http.Error(w, "Failed to save block", http.StatusInternalServerError)
		return
	}

	// å°†äº¤æ˜“æ”¾å…¥äº¤æ˜“æ± ï¼ˆæ ‡è®°ä¸ºå·²åœ¨åŒºå—ä¸­ï¼‰
	if len(block.Body) > 0 {
		for _, tx := range block.Body {
			if tx != nil {
				if err := hm.txPool.StoreAnyTx(tx); err != nil {
					logs.Debug("[HandlePut] Failed to store tx %s: %v", tx.GetTxId(), err)
				}
			}
		}
		logs.Debug("[HandlePut] Added %d transactions from block %s to pool", len(block.Body), block.BlockHash)
	}

	// é€šçŸ¥å…±è¯†ï¼ˆä¿æŒä½ ç°æœ‰é€»è¾‘ï¼‰
	if hm.consensusManager != nil && hm.adapter != nil {
		if consensusBlock, err := hm.adapter.DBBlockToConsensus(&block); err == nil {
			msg := types.Message{
				RequestID: 0, // /put ä¸èµ°è¯·æ±‚-å“åº”ï¼Œè¿™é‡Œå›ºå®š 0
				Type:      types.MsgPut,
				From:      types.NodeID(block.Miner),
				Block:     consensusBlock,
				BlockID:   block.BlockHash,
				Height:    block.Height,
			}
			if rt, ok := hm.consensusManager.Transport.(*consensus.RealTransport); ok {
				if err := rt.EnqueueReceivedMessage(msg); err != nil {
					logs.Warn("[HandlePut] Failed to enqueue block message: %v", err)
				}
			}
		}
	}

	logs.Info("[HandlePut] Stored block %s at height %d (txs=%d)", block.BlockHash, block.Height, len(block.Body))
	w.WriteHeader(http.StatusOK)
}


æ–‡ä»¶è·¯å¾„: handlers/handleStatus.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// å¤„ç†çŠ¶æ€æŸ¥è¯¢
func (hm *HandlerManager) HandleStatus(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleStatus")
	if !hm.checkAuth(r) {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	resProto := &pb.StatusResponse{
		Status: "ok",
		Info:   fmt.Sprintf("Server is running on port %s", hm.port),
	}
	data, err := proto.Marshal(resProto)
	if err != nil {
		http.Error(w, "Failed to marshal status response", http.StatusInternalServerError)
		return
	}
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)
	w.Write(data)
}


æ–‡ä»¶è·¯å¾„: handlers/handleTx.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// HandleTx å¤„ç†äº¤æ˜“æäº¤
func (hm *HandlerManager) HandleTx(w http.ResponseWriter, r *http.Request) {
	hm.Stats.RecordAPICall("HandleTx")
	bodyBytes, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}

	var incomingAny pb.AnyTx
	if err := proto.Unmarshal(bodyBytes, &incomingAny); err != nil {
		http.Error(w, "Invalid AnyTx proto", http.StatusBadRequest)
		return
	}

	host, _, _ := net.SplitHostPort(r.RemoteAddr)

	// ç›´æ¥æäº¤ç»™TxPoolï¼Œä¸å†å…³å¿ƒå†…éƒ¨é˜Ÿåˆ—
	err = hm.txPool.SubmitTx(&incomingAny, host, func(txID string) {
		// å¹¿æ’­å›è°ƒ
		hm.senderManager.BroadcastTx(&incomingAny)
	})

	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to submit tx: %v", err), http.StatusInternalServerError)
		return
	}

	resProto := &pb.StatusResponse{
		Status: "ok",
		Info:   "Tx received",
	}
	resBytes, _ := proto.Marshal(resProto)
	w.Header().Set("Content-Type", "application/x-protobuf")
	w.WriteHeader(http.StatusOK)
	w.Write(resBytes)
}


æ–‡ä»¶è·¯å¾„: handlers/manager.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// HandlerManager ç®¡ç†æ‰€æœ‰HTTPå¤„ç†å™¨åŠå…¶ä¾èµ–
type HandlerManager struct {
	dbManager        *db.Manager
	consensusManager *consensus.ConsensusNodeManager
	senderManager    *sender.SenderManager
	txPool           *txpool.TxPool
	port             string // å½“å‰èŠ‚ç‚¹ç«¯å£
	address          string // å½“å‰èŠ‚ç‚¹åœ°å€
	adapter          *consensus.ConsensusAdapter

	// æ·»åŠ å·²çŸ¥å—ç¼“å­˜
	seenBlocksCache *lru.Cache // ç”¨äºè®°å½•å·²å¤„ç†çš„åŒºå—ID
	// ç»Ÿè®¡ç›¸å…³å­—æ®µ
	Stats *stats.Stats
}

// NewHandlerManager åˆ›å»ºæ–°çš„å¤„ç†å™¨ç®¡ç†å™¨
func NewHandlerManager(
	dbMgr *db.Manager,
	consensusMgr *consensus.ConsensusNodeManager,
	port, address string,
	senderMgr *sender.SenderManager,
	txPool *txpool.TxPool, // åªæ³¨å…¥TxPool
) *HandlerManager {
	// åˆ›å»º LRU ç¼“å­˜ï¼Œå®¹é‡è®¾ä¸º 10000
	seenBlocksCache, _ := lru.New(100)
	return &HandlerManager{
		dbManager:        dbMgr,
		consensusManager: consensusMgr,
		txPool:           txPool,
		senderManager:    senderMgr,
		port:             port,
		address:          address,
		adapter:          consensus.NewConsensusAdapter(dbMgr),
		Stats:            stats.NewStats(),
		seenBlocksCache:  seenBlocksCache,
	}
}

type ChallengeInfo struct {
	Challenge   string
	CreatedTime time.Time
}

// RegisterRoutes æ³¨å†Œæ‰€æœ‰è·¯ç”±
func (hm *HandlerManager) RegisterRoutes(mux *http.ServeMux) {
	// Snowmanå…±è¯†ç›¸å…³
	mux.HandleFunc("/pushquery", hm.HandlePushQuery)
	mux.HandleFunc("/pullquery", hm.HandlePullQuery)
	mux.HandleFunc("/gossipAnyMsg", hm.HandleBlockGossip)
	mux.HandleFunc("/chits", hm.HandleChits)
	mux.HandleFunc("/heightquery", hm.HandleHeightQuery)
	// åŸºæœ¬åŠŸèƒ½
	mux.HandleFunc("/status", hm.HandleStatus)
	mux.HandleFunc("/tx", hm.HandleTx)
	mux.HandleFunc("/getblock", hm.HandleGetBlock)
	mux.HandleFunc("/getdata", hm.HandleGetData)
	mux.HandleFunc("/batchgetdata", hm.HandleBatchGetTx)
	mux.HandleFunc("/nodes", hm.HandleNodes)
	mux.HandleFunc("/getblockbyid", hm.HandleGet)
	mux.HandleFunc("/put", hm.HandlePut)

}

// æ·»åŠ èº«ä»½éªŒè¯æ–¹æ³•
func (hm *HandlerManager) verifyNodeIdentity(address string, message interface{}) bool {
	// ä»æ•°æ®åº“è·å–è¯¥åœ°å€çš„å…¬é’¥
	//account, err := db.GetAccount(hm.dbManager, address)
	//if err != nil || account == nil {
	//	return false
	//}

	// TODO: éªŒè¯æ¶ˆæ¯ç­¾å
	// è¿™é‡Œéœ€è¦æ¯ä¸ªæ¶ˆæ¯éƒ½åŒ…å«ç­¾åå­—æ®µ
	return true
}

// è¾…åŠ©æ–¹æ³•

func (hm *HandlerManager) checkAuth(r *http.Request) bool {
	if !AUTH_ENABLED {
		return true
	}

	clientIP := strings.Split(r.RemoteAddr, ":")[0]
	info, err := hm.dbManager.GetClientInfo(clientIP)
	if err != nil {
		return false
	}
	return info.GetAuthed()
}

func (hm *HandlerManager) hasBlock(blockId string) bool {
	if hm.consensusManager != nil {
		return hm.consensusManager.HasBlock(blockId)
	}
	return hm.dbManager.BlockExists(blockId)
}

func (hm *HandlerManager) Stop() {
	if hm.senderManager != nil {
		hm.senderManager.Stop()
	}
	// å…¶ä»–æ¸…ç†å·¥ä½œ
}


æ–‡ä»¶è·¯å¾„: handlers/tx_utils.go
æ–‡ä»¶å†…å®¹:
package handlers

import (...)

// ExtractTxId ä» AnyTx ä¸­æå–å…¶ BaseMessage.TxId
func ExtractTxId(a *pb.AnyTx) (string, error) {
	switch tx := a.GetContent().(type) {
	case *pb.AnyTx_IssueTokenTx:
		if tx.IssueTokenTx.Base == nil {
			return "", fmt.Errorf("IssueTokenTx base is nil")
		}
		return tx.IssueTokenTx.Base.TxId, nil

	case *pb.AnyTx_FreezeTx:
		if tx.FreezeTx.Base == nil {
			return "", fmt.Errorf("FreezeTx base is nil")
		}
		return tx.FreezeTx.Base.TxId, nil

	case *pb.AnyTx_Transaction:
		if tx.Transaction.Base == nil {
			return "", fmt.Errorf("Transaction base is nil")
		}
		return tx.Transaction.Base.TxId, nil

	case *pb.AnyTx_OrderTx:
		if tx.OrderTx.Base == nil {
			return "", fmt.Errorf("OrderTx base is nil")
		}
		return tx.OrderTx.Base.TxId, nil

	case *pb.AnyTx_AddressTx:
		if tx.AddressTx.Base == nil {
			return "", fmt.Errorf("AddressTx base is nil")
		}
		return tx.AddressTx.Base.TxId, nil

	case *pb.AnyTx_CandidateTx:
		if tx.CandidateTx.Base == nil {
			return "", fmt.Errorf("CandidateTx base is nil")
		}
		return tx.CandidateTx.Base.TxId, nil

	default:
		return "", fmt.Errorf("unrecognized tx type")
	}
}

var AUTH_ENABLED = false

func CheckAuth(r *http.Request) bool {
	if !AUTH_ENABLED {
		return true
	}
	clientIP := strings.Split(r.RemoteAddr, ":")[0]
	dbMgr, err := db.NewManager("")
	if err != nil {
		logs.Error("CheckAuth GetInstance err : %v", err)
		return false
	}
	info, err := dbMgr.GetClientInfo(clientIP)
	if err != nil {
		logs.Debug("CheckAuth GetClientInfo err : %v key: %s \n", err, clientIP)
		return false
	}
	logs.Debug("CheckAuth info: %s", info.Ip)
	if err != nil {
		// æ•°æ®åº“ä¸­æ— è®°å½•ï¼Œè¯´æ˜æœªè®¤è¯
		return false
	}
	return info.GetAuthed()
}


æ–‡ä»¶è·¯å¾„: handlers/types.go
æ–‡ä»¶å†…å®¹:
package handlers

type RequestPayload struct {
	String1 string `json:"string1"`
	String2 string `json:"string2"`
}

// HandshakePayload ç”¨äºæ¡æ‰‹è¯·æ±‚çš„ JSON æ ¼å¼
type HandshakePayload struct {
	ClientID  string `json:"client_id"`
	PublicKey string `json:"public_key"` // å®¢æˆ·ç«¯å‘é€çš„å…¬é’¥ PEM
	Signature string `json:"signature"`  // å¯¹ (client_id + server_challenge) çš„ç­¾å
}

var ServerChallenge = "server_challenge_123456"


æ–‡ä»¶è·¯å¾„: interfaces/iface.go
æ–‡ä»¶å†…å®¹:
package interfaces

import (...)

type BlockStore interface {
	Add(block *types.Block) (bool, error)
	Get(id string) (*types.Block, bool)
	GetByHeight(height uint64) []*types.Block
	GetLastAccepted() (string, uint64)
	GetFinalizedAtHeight(height uint64) (*types.Block, bool)
	GetBlocksFromHeight(from, to uint64) []*types.Block
	GetCurrentHeight() uint64

	// å¿«ç…§ç›¸å…³
	CreateSnapshot(height uint64) (*types.Snapshot, error)
	LoadSnapshot(snapshot *types.Snapshot) error
	GetLatestSnapshot() (*types.Snapshot, bool)
	GetSnapshotAtHeight(height uint64) (*types.Snapshot, bool)

	SetFinalized(height uint64, blockID string)
}

type ConsensusEngine interface {
	Start(ctx context.Context) error
	RegisterQuery(nodeID types.NodeID, requestID uint32, blockID string, height uint64) string
	SubmitChit(nodeID types.NodeID, queryKey string, preferredID string)
	GetActiveQueryCount() int
	GetPreference(height uint64) string
}

type Event interface {
	Type() types.EventType
	Data() interface{}
}

// ============================================
// åŒºå—ææ¡ˆæ¥å£å®šä¹‰
// ============================================

// å®šä¹‰äº†åŒºå—ææ¡ˆçš„æ¥å£
type BlockProposer interface {
	// ProposeBlock ç”Ÿæˆä¸€ä¸ªæ–°çš„åŒºå—ææ¡ˆ
	// parentID: çˆ¶åŒºå—ID
	// height: åŒºå—é«˜åº¦
	// proposer: ææ¡ˆè€…ID
	// round: ææ¡ˆè½®æ¬¡
	ProposeBlock(parentID string, height uint64, proposer types.NodeID, round int) (*types.Block, error)

	// ShouldPropose å†³å®šæ˜¯å¦åº”è¯¥åœ¨å½“å‰è½®æ¬¡æå‡ºåŒºå—
	// nodeID: èŠ‚ç‚¹ID
	// round: å½“å‰è½®æ¬¡
	// currentBlocks: å½“å‰é«˜åº¦å·²å­˜åœ¨çš„åŒºå—æ•°é‡
	ShouldPropose(nodeID types.NodeID, round int, currentBlocks int, currentHeight int, proposeHeight int) bool
}

// ============================================
// ç½‘ç»œä¼ è¾“å±‚æ¥å£
// ============================================

type Transport interface {
	Send(to types.NodeID, msg types.Message) error
	Receive() <-chan types.Message
	Broadcast(msg types.Message, peers []types.NodeID)
	SamplePeers(exclude types.NodeID, count int) []types.NodeID
}

type EventBus interface {
	Subscribe(topic types.EventType, handler EventHandler)
	Publish(event Event)
	PublishAsync(event Event)
}

type EventHandler func(Event)


æ–‡ä»¶è·¯å¾„: logs/log.go
æ–‡ä»¶å†…å®¹:
package logs

import (...)

// å®šä¹‰æ—¥å¿—çº§åˆ«å¸¸é‡ï¼ˆæ•°å€¼è¶Šå¤§ï¼Œçº§åˆ«è¶Šé«˜ï¼‰
const (
	LevelTrace   = iota // 0ï¼ˆæœ€ä½ï¼Œæœ€è¯¦ç»†ï¼‰
	LevelDebug          // 1
	LevelVerbose        // 2ï¼ˆæ–°å¢çº§åˆ«ï¼‰
	LevelInfo           // 3
	LevelWarning        // 4
	LevelError          // 5ï¼ˆæœ€é«˜ï¼Œæœ€ä¸¥é‡ï¼‰
)

var logLevel = LevelVerbose // å…¨å±€æ—¥å¿—çº§åˆ«ï¼ˆç¤ºä¾‹è®¾ç½®ä¸º LevelVerboseï¼‰

// å…¨å±€ Logger å®ä¾‹
var logger *Logger
var MyAddress = "0x0000000"
var IsCurrentLeader = ""

// Logger ç»“æ„ä½“
type Logger struct {
	traceLogger   *log.Logger
	debugLogger   *log.Logger
	verboseLogger *log.Logger
	infoLogger    *log.Logger
	warnLogger    *log.Logger
	errorLogger   *log.Logger
}

// åˆå§‹åŒ–å…¨å±€ Logger å®ä¾‹
func init() {
	logger = &Logger{
		traceLogger:   log.New(os.Stdout, "[TRACE]   ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
		debugLogger:   log.New(os.Stdout, "[DEBUG]   ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
		verboseLogger: log.New(os.Stdout, "[VERBOSE] ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
		infoLogger:    log.New(os.Stdout, "[INFO]    ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
		warnLogger:    log.New(os.Stdout, "[WARN]    ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
		errorLogger:   log.New(os.Stderr, "[ERROR]   ", log.Ldate|log.Ltime|log.Lmicroseconds|log.Lshortfile),
	}
}

// åŒ…çº§åˆ«çš„æ—¥å¿—æ–¹æ³•
func Trace(format string, v ...interface{}) {
	if logLevel <= LevelTrace {
		logger.traceLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+format, v...)
	}
}

func Debug(format string, v ...interface{}) {
	if logLevel <= LevelDebug {
		logger.debugLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+" "+format, v...)
	}
}

func Verbose(format string, v ...interface{}) {
	if logLevel <= LevelVerbose {
		logger.verboseLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+" "+format, v...)
	}
}

func Info(format string, v ...interface{}) {
	if logLevel <= LevelInfo {
		logger.infoLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+" "+format, v...)
	}
}

func Warn(format string, v ...interface{}) {
	if logLevel <= LevelWarning {
		logger.warnLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+" "+format, v...)
	}
}

func Error(format string, v ...interface{}) {
	if logLevel <= LevelError {
		logger.errorLogger.Printf(IsCurrentLeader+" "+MyAddress[:7]+" "+format, v...)
	}
}


æ–‡ä»¶è·¯å¾„: matching/match.go
æ–‡ä»¶å†…å®¹:
package matching

import (...)

// PruneByMarkPrice æ ¹æ®æ ‡è®°ä»·æ ¼è¿‡æ»¤è®¢å•å¹¶é‡å»ºè®¢å•ç°¿
// åªä¿ç•™ [0.5*markPrice, 2.0*markPrice] åŒºé—´å†…çš„æ‰€æœ‰è®¢å•
// OrderBook çš„ PruneByMarkPrice ç°åœ¨åªè´Ÿè´£å†…å­˜ä¸­çš„æ¸…ç†å·¥ä½œ
func (ob *OrderBook) PruneByMarkPrice(markPrice decimal.Decimal) {
	lowerBound := markPrice.Mul(decimal.NewFromFloat(0.5)) // 0.5 * markPrice
	upperBound := markPrice.Mul(decimal.NewFromFloat(2.0)) // 2.0 * markPrice

	// æ¸…ç† buyMap
	for price, pl := range ob.buyMap {
		if price.Cmp(lowerBound) < 0 || price.Cmp(upperBound) > 0 {
			for _, order := range pl.Orders {
				ob.removeOrderIndex(order.ID)
			}
			delete(ob.buyMap, price)
		}
	}

	// æ¸…ç† sellMap
	for price, pl := range ob.sellMap {
		if price.Cmp(lowerBound) < 0 || price.Cmp(upperBound) > 0 {
			for _, order := range pl.Orders {
				ob.removeOrderIndex(order.ID)
			}
			delete(ob.sellMap, price)
		}
	}

	// é‡å»ºå †
	ob.buyHeap = &MaxPriceHeap{}
	for _, pl := range ob.buyMap {
		heap.Push(ob.buyHeap, pl)
	}

	ob.sellHeap = &MinPriceHeap{}
	for _, pl := range ob.sellMap {
		heap.Push(ob.sellHeap, pl)
	}
}

// AddOrder æ–°å¢è®¢å•å¹¶ï¼ˆå¯é€‰ï¼‰å°è¯•å±€éƒ¨æ’®åˆ
func (ob *OrderBook) AddOrder(o *Order) error {
	// è¿™é‡Œç”¨ decimal.Zero æ¯”è¾ƒ
	if o.Amount.Cmp(decimal.Zero) <= 0 {
		return errors.New("order amount must be positive")
	}
	lowerBound := decimal.NewFromFloat(1e-33)
	upperBound := decimal.NewFromFloat(1e33)
	if o.Price.Cmp(lowerBound) < 0 || o.Price.Cmp(upperBound) > 0 {
		return fmt.Errorf("price out of range in OrderBook: %s", o.Price.String())
	}
	// 1. åŠ å…¥/æ›´æ–°å¯¹åº” priceMap
	var lvl *PriceLevel
	if o.Side == BUY {
		lvl = ob.buyMap[o.Price]
		if lvl == nil {
			lvl = &PriceLevel{Price: o.Price}
			ob.buyMap[o.Price] = lvl
			heap.Push(ob.buyHeap, lvl)
		}
	} else { // SELL
		lvl = ob.sellMap[o.Price]
		if lvl == nil {
			lvl = &PriceLevel{Price: o.Price}
			ob.sellMap[o.Price] = lvl
			heap.Push(ob.sellHeap, lvl)
		}
	}
	lvl.Orders = append(lvl.Orders, o)

	// 2. åŠ å…¥è®¢å•IDç´¢å¼•
	ob.orderIndex[o.ID] = &OrderRef{Order: o, PriceLevel: lvl}

	// 3. å¯é€‰: æ˜¯å¦ç«‹å³æ’®åˆ => çœ‹ä»·æ ¼æ˜¯å¦æœ‰äº¤å‰
	if o.Side == BUY {
		// å¦‚æœä¹°å•ä»·æ ¼ >= å½“å‰æœ€ä¼˜å–ä»·ï¼Œåˆ™å°è¯•æ’®åˆ
		bestSellPrice := ob.getBestSellPrice()
		// bestSellPrice > 0 => bestSellPrice.Cmp(decimal.Zero) > 0
		if bestSellPrice.Cmp(decimal.Zero) > 0 && o.Price.Cmp(bestSellPrice) >= 0 {
			ob.match(BUY)
		}
	} else { // SELL
		// å¦‚æœå–å•ä»·æ ¼ <= å½“å‰æœ€ä¼˜ä¹°ä»·ï¼Œåˆ™å°è¯•æ’®åˆ
		bestBuyPrice := ob.getBestBuyPrice()
		if bestBuyPrice.Cmp(decimal.Zero) > 0 && o.Price.Cmp(bestBuyPrice) <= 0 {
			ob.match(SELL)
		}
	}

	return nil
}

// getBestBuyOrder è·å–ä¹°æ–¹å †é¡¶çš„ç¬¬ä¸€ä¸ªè®¢å•(ä¸ä¸€å®šæ˜¯é˜Ÿåˆ—ç¬¬ä¸€ä¸ªï¼Œä½†ä¸‹æ ‡0ä¸ä¼šè¶Šç•Œ)
func (ob *OrderBook) getBestBuyOrder() *Order {
	if ob.buyHeap.Len() == 0 {
		return nil
	}
	pl := (*ob.buyHeap)[0]
	if len(pl.Orders) == 0 {
		return nil
	}
	return pl.Orders[0]
}

// getBestSellOrder è·å–å–æ–¹å †é¡¶çš„ç¬¬ä¸€ä¸ªè®¢å•
func (ob *OrderBook) getBestSellOrder() *Order {
	if ob.sellHeap.Len() == 0 {
		return nil
	}
	pl := (*ob.sellHeap)[0]
	if len(pl.Orders) == 0 {
		return nil
	}
	return pl.Orders[0]
}

// match ä¸å¯¹æ‰‹æ–¹æœ€ä¼˜ä»·æ ¼è¿›è¡Œæ’®åˆï¼›
// side è¡¨ç¤ºå½“å‰æ–°æ¥çš„è®¢å•æ–¹å‘ (BUY => è¿™æ‰¹æ–°ä¹°å•ï¼›SELL => è¿™æ‰¹æ–°å–å•)ã€‚
func (ob *OrderBook) match(side OrderSide) {
	for {
		var changed bool

		if side == BUY {
			// 1) è‹¥ä¹°å †ç©º => æ— å¯æ’®åˆ
			if ob.buyHeap.Len() == 0 {
				break
			}
			bestBuy := (*ob.buyHeap)[0]
			if len(bestBuy.Orders) == 0 {
				// è¯¥ä»·ä½ä¸Šè®¢å•éƒ½è¢«æ’®åˆå…‰äº†ï¼Œå¼¹å‡ºå¹¶ç»§ç»­
				heap.Pop(ob.buyHeap)
				delete(ob.buyMap, bestBuy.Price)
				continue
			}
			// 2) æ£€æŸ¥æ˜¯å¦è·Ÿæœ€ä¼˜å–ä»·äº¤å‰
			bestSellPrice := ob.getBestSellPrice()
			if bestSellPrice.IsZero() {
				// å–å †æ²¡æœ‰è®¢å•ï¼Œæ— æ³•æˆäº¤
				break
			}
			// å¦‚æœä¹°ä»· < å–ä»· => ä¸äº¤å‰ => ç»ˆæ­¢
			if bestBuy.Price.Cmp(bestSellPrice) < 0 {
				break
			}
			// 3) äº¤å‰ => æ‰§è¡Œæ’®åˆ
			changed = ob.executeTrade(bestBuy, BUY)

		} else {
			// side == SELL
			if ob.sellHeap.Len() == 0 {
				break
			}
			bestSell := (*ob.sellHeap)[0]
			if len(bestSell.Orders) == 0 {
				heap.Pop(ob.sellHeap)
				delete(ob.sellMap, bestSell.Price)
				continue
			}
			bestBuyPrice := ob.getBestBuyPrice()
			if bestBuyPrice.IsZero() {
				break
			}
			// å¦‚æœå–ä»· > ä¹°ä»· => ä¸äº¤å‰
			if bestSell.Price.Cmp(bestBuyPrice) > 0 {
				break
			}
			changed = ob.executeTrade(bestSell, SELL)
		}

		// å¦‚æœæœ¬è½®æ’®åˆæ²¡æœ‰å®é™…æˆäº¤ï¼Œç›´æ¥é€€å‡ºé¿å…æ­»å¾ªç¯
		if !changed {
			break
		}
	}
}

// è¿™é‡Œæ˜¯æ’®åˆæ ¸å¿ƒ executeTrade
func (ob *OrderBook) executeTrade(pl *PriceLevel, side OrderSide) bool {
	changed := false
	for i := 0; i < len(pl.Orders); {
		o := pl.Orders[i]
		if o.Amount.Cmp(decimal.Zero) <= 0 {
			// å·²è€—å°½åˆ™ä»åˆ‡ç‰‡ç§»é™¤
			pl.Orders = append(pl.Orders[:i], pl.Orders[i+1:]...)
			ob.removeOrderIndex(o.ID)
			continue
		}

		// æ‰¾åˆ°å¯¹æ‰‹å•(è‹¥ side==BUYï¼Œå°±æ‰¾æœ€ä¼˜å–ï¼›è‹¥ side==SELLï¼Œå°±æ‰¾æœ€ä¼˜ä¹°)
		var opp *Order
		if side == BUY {
			opp = ob.getBestSellOrder()
		} else {
			opp = ob.getBestBuyOrder()
		}
		if opp == nil {
			// æ²¡æœ‰å¯¹æ‰‹å•ï¼Œæ’®åˆç»“æŸ
			break
		}

		// åˆ¤æ–­æ˜¯å¦æœ‰äº¤å‰ä»·æ ¼ï¼Œè‹¥ä¸äº¤å‰ä¹Ÿbreak ...
		// ...

		tradeAmt := minDecimal(o.Amount, opp.Amount)
		if tradeAmt.Cmp(decimal.Zero) <= 0 {
			break
		}
		changed = true

		// å‡è®¾æ’®åˆä»·å–å¯¹æ‰‹å•ä»·æ ¼
		actualPrice := opp.Price

		// å‡å°‘å„è‡ªå‰©ä½™é‡
		o.Amount = o.Amount.Sub(tradeAmt)
		opp.Amount = opp.Amount.Sub(tradeAmt)

		// â˜… åœ¨è¿™é‡Œå‘é€æ’®åˆäº‹ä»¶ => Manager åå°å»DBæ›´æ–°
		ob.tradeCh <- TradeUpdate{
			OrderID:    o.ID,
			TradeAmt:   tradeAmt,
			TradePrice: actualPrice,
			RemainAmt:  o.Amount,
			IsFilled:   o.Amount.Cmp(decimal.Zero) == 0,
		}
		ob.tradeCh <- TradeUpdate{
			OrderID:    opp.ID,
			TradeAmt:   tradeAmt,
			TradePrice: actualPrice,
			RemainAmt:  opp.Amount,
			IsFilled:   opp.Amount.Cmp(decimal.Zero) == 0,
		}

		// å¦‚æœå¯¹æ‰‹å•è€—å°½ => remove
		if opp.Amount.Cmp(decimal.Zero) <= 0 {
			ob.removeFromPriceLevel(opp)
		}

		// å¦‚æœå½“å‰è®¢å•è€—å°½ => remove
		if o.Amount.Cmp(decimal.Zero) <= 0 {
			pl.Orders = append(pl.Orders[:i], pl.Orders[i+1:]...)
			ob.removeOrderIndex(o.ID)
			continue
		}
		i++ // åªæœ‰å½“ o è¿˜å‰©ä½™æ—¶æ‰ i++ å‰è¿›
	}
	return changed
}

// removeFromPriceLevel å½“å¯¹æ‰‹è®¢å•æ’®åˆå®Œåï¼Œéœ€ä»å¯¹åº”priceLevelåˆ é™¤
func (ob *OrderBook) removeFromPriceLevel(o *Order) {
	ref, ok := ob.orderIndex[o.ID]
	if !ok {
		return
	}
	pl := ref.PriceLevel

	// ä» pl.Orders ä¸­åˆ é™¤
	newOrders := pl.Orders[:0]
	for _, od := range pl.Orders {
		if od.ID != o.ID {
			newOrders = append(newOrders, od)
		}
	}
	pl.Orders = newOrders

	ob.removeOrderIndex(o.ID)
}

// removeOrderIndex ä»orderIndexç§»é™¤
func (ob *OrderBook) removeOrderIndex(orderID string) {
	delete(ob.orderIndex, orderID)
}

// CancelOrder é€šè¿‡è®¢å•IDåˆ é™¤è®¢å•
func (ob *OrderBook) CancelOrder(orderID string) error {
	ref, ok := ob.orderIndex[orderID]
	if !ok {
		return errors.New("order not found")
	}
	pl := ref.PriceLevel

	// ä»pl.Ordersä¸­åˆ é™¤
	newOrders := pl.Orders[:0]
	for _, od := range pl.Orders {
		if od.ID != orderID {
			newOrders = append(newOrders, od)
		}
	}
	pl.Orders = newOrders
	ob.removeOrderIndex(orderID)
	return nil
}

// getBestBuyPrice è·å–å½“å‰æœ€é«˜ä¹°ä»·
func (ob *OrderBook) getBestBuyPrice() decimal.Decimal {
	if ob.buyHeap.Len() == 0 {
		return decimal.Zero
	}
	return (*ob.buyHeap)[0].Price
}

// getBestSellPrice è·å–å½“å‰æœ€ä½å–ä»·
func (ob *OrderBook) getBestSellPrice() decimal.Decimal {
	if ob.sellHeap.Len() == 0 {
		// è¡¨ç¤ºæ— å–å•æ—¶
		// è¿™é‡Œå¯ä»¥è¿”å›ä¸€ä¸ªæå¤§çš„å€¼ï¼Œæˆ–è€…å°±è¿”å›0ä»¥åšç‰¹æ®Šåˆ¤æ–­
		// é€‰æ‹©è¿”å›0ï¼ˆå¤–éƒ¨åˆ¤æ–­ if Cmp(decimal.Zero)>0 è¡¨ç¤ºæœ‰å–å•ï¼‰
		return decimal.Zero
	}
	return (*ob.sellHeap)[0].Price
}

// minDecimal æ›¿ä»£åŸæœ‰çš„minå‡½æ•°ï¼Œç”¨äº decimal
func minDecimal(a, b decimal.Decimal) decimal.Decimal {
	if a.Cmp(b) < 0 {
		return a
	}
	return b
}

// BuyMap è¿”å›ä¹°å• price->PriceLevel çš„æ˜ å°„
func (ob *OrderBook) BuyMap() map[decimal.Decimal]*PriceLevel {
	return ob.buyMap
}
func (ob *OrderBook) SellMap() map[decimal.Decimal]*PriceLevel {
	return ob.sellMap
}

// æ¯è½®æŒ‰å¦‚ä¸‹æ­¥éª¤è°ƒç”¨ï¼Œå³å¯ä¿è¯å†…å­˜å¯æ§
// 1ã€è°ƒç”¨é‡å»ºä»·æ ¼å †ï¼Œå¸‚åœºä»·çš„0.5~2.0
// 2ã€DBè¯»å–0.5~2.0åˆ°å †
// 3ã€å†…å­˜è¯»å–0.5~2.0åˆ°æ¨


æ–‡ä»¶è·¯å¾„: matching/order_book_manager.go
æ–‡ä»¶å†…å®¹:
package matching

import (...)

// TradingPair ç»“æ„ä½“ç”¨äºåŒºåˆ†ä¸åŒäº¤æ˜“å¯¹
type TradingPair struct {
	BaseToken  string
	QuoteToken string
}

// OrderBookManager ç®¡ç†å¤šä¸ªäº¤æ˜“å¯¹çš„è®¢å•ç°¿
type OrderBookManager struct {
	dbMgr      *db.Manager
	orderBooks map[TradingPair]*OrderBook
	tradeCh    chan TradeUpdate // ç”¨äºæ¥æ”¶æ’®åˆåçš„äº‹ä»¶(éƒ¨åˆ†/å…¨éƒ¨æˆäº¤)
	stopCh     chan struct{}
	mu         sync.RWMutex
	wg         sync.WaitGroup
}

// NewOrderBookManager åˆ›å»ºè®¢å•ç°¿ç®¡ç†å™¨ï¼Œå¹¶å¯åŠ¨åå°åç¨‹ç›‘å¬æ’®åˆäº‹ä»¶
func NewOrderBookManager(dbMgr *db.Manager) *OrderBookManager {
	obm := &OrderBookManager{
		dbMgr:      dbMgr,
		orderBooks: make(map[TradingPair]*OrderBook),
		tradeCh:    make(chan TradeUpdate, 65000), // è§†éœ€æ±‚å¯è®¾ç½®æ›´å¤§æˆ–æ›´å°ç¼“å†²
		stopCh:     make(chan struct{}),
	}
	obm.wg.Add(1)
	// å¯åŠ¨åå° goroutine å¤„ç†æ’®åˆäº‹ä»¶ï¼ˆæ— è®ºéƒ¨åˆ†è¿˜æ˜¯å…¨éƒ¨ï¼‰
	go obm.handleTradeUpdates()

	return obm
}

// Stop åœæ­¢åå°äº‹ä»¶å¾ªç¯ï¼ˆå¯åœ¨è¿›ç¨‹é€€å‡ºæ—¶è°ƒç”¨ï¼‰
func (obm *OrderBookManager) Stop() {
	close(obm.stopCh)
	// 2. ç­‰åå°goroutineå…¨éƒ¨é€€å‡º
	obm.wg.Wait()
}

// GetOrderBook è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„è®¢å•ç°¿ï¼›è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»º
func (obm *OrderBookManager) GetOrderBook(baseToken, quoteToken string) *OrderBook {
	obm.mu.Lock()
	defer obm.mu.Unlock()

	pair := TradingPair{BaseToken: baseToken, QuoteToken: quoteToken}
	ob, exists := obm.orderBooks[pair]
	if !exists {
		// æ–°å»º OrderBookï¼Œæ³¨æ„è¦æŠŠ tradeCh ä¼ è¿›å»
		ob = NewOrderBook(obm.tradeCh)
		obm.orderBooks[pair] = ob
	}
	return ob
}

// handleTradeUpdates å¾ªç¯ä» tradeCh è¯»äº‹ä»¶å¹¶æ›´æ–°æ•°æ®åº“(æˆ–åšå…¶ä»–æ“ä½œ)
func (obm *OrderBookManager) handleTradeUpdates() {
	defer obm.wg.Done()
	for {
		select {
		case <-obm.stopCh:
			// æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯
			return
		case ev := <-obm.tradeCh:
			// è¿™é‡Œä½ å¯ä»¥æ›´æ–°æ•°æ®åº“
			// è°ƒç”¨ä¸€ä¸ª DB å‡½æ•°ï¼Œæ¯”å¦‚ db.UpdateOrderTxInDB æ¥å¢åŠ æ’®åˆé‡
			err := obm.dbMgr.UpdateOrderTxInDB(ev.OrderID, ev.TradeAmt, ev.TradePrice)
			if err != nil {
				logs.Verbose("[OrderBookManager] failed to update DB for order %s: %v", ev.OrderID, err)
			}

			// å¯é€‰ï¼šå¦‚æœ IsFilled == trueï¼Œå¯ä»¥é¢å¤–åšåˆ é™¤è®¢å•ä¹‹ç±»æ“ä½œ
			// ...
			//log.Printf("[handleTradeUpdates] order=%s traded=%s remain=%s price=%s filled=%v",
			//	ev.OrderID, ev.TradeAmt, ev.RemainAmt, ev.TradePrice, ev.IsFilled)
		}
	}
}

// LoadOrdersInRange åœ¨ OrderBookManager å±‚é¢å¤„ç†æ•°æ®åº“æ“ä½œ
func (obm *OrderBookManager) LoadOrdersInRange(
	baseToken, quoteToken string,
	lowerPrice, upperPrice decimal.Decimal,
) error {
	// 1) ç”¨ priceToKey128 å¾—åˆ°ä¸¤ä¸ª 67 ä½å­—ç¬¦ä¸²
	lowerKeyStr, err := db.PriceToKey128(lowerPrice.String())
	if err != nil {
		return fmt.Errorf("invalid lowerPrice: %v", err)
	}
	upperKeyStr, err := db.PriceToKey128(upperPrice.String())
	if err != nil {
		return fmt.Errorf("invalid upperPrice: %v", err)
	}

	// 2) æ‹¼æ¥æˆ â€œpair:base_quote|is_filled:false|price:0000...xxxâ€
	pair := utils.GeneratePairKey(baseToken, quoteToken)
	prefix := fmt.Sprintf("pair:%s|is_filled:false|price:", pair)
	lowestKey := prefix + lowerKeyStr
	highestKey := prefix + upperKeyStr

	ob := obm.GetOrderBook(baseToken, quoteToken)

	// 3) æ‰“å¼€ DB çš„åªè¯»äº‹åŠ¡
	return obm.dbMgr.View(func(txn *db.TransactionView) error {
		it := txn.NewIterator()
		defer it.Close()

		for it.Seek([]byte(lowestKey)); it.Valid(); it.Next() {
			item := it.Item()
			keyBytes := item.Key()
			k := string(keyBytes)

			// å¦‚æœè¶…å‡º highestKeyï¼Œå°±è·³å‡º
			if k > highestKey {
				break
			}

			// 1) å…ˆè§£æ keyï¼Œæ‹¿åˆ° order_id
			//    key æ ¼å¼: "pair:base_quote|price:000...67|order_id:xxxxx"
			//    å¯ä»¥å…ˆæ‰¾ "|order_id:" å†å–åé¢éƒ¨åˆ†
			parts := strings.Split(k, "|order_id:")
			if len(parts) != 2 {
				// æ ¼å¼ä¸åŒ¹é…ï¼Œè·³è¿‡
				continue
			}
			orderID := parts[1]

			// 2) è¯»å–äºŒçº§ç´¢å¼•çš„å€¼ï¼Œè¿™é‡Œå…¶å®åªæ˜¯ä¸ª OrderPriceIndex
			val, err := item.ValueCopy(nil)
			if err != nil {
				continue
			}
			var idx pb.OrderPriceIndex
			if err := proto.Unmarshal(val, &idx); err != nil {
				// ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ OrderPriceIndex ç»“æ„ï¼Œè·³è¿‡
				continue
			}

			// 3) å†å»æ‹¿å®Œæ•´è®¢å•
			orderTx, err := db.GetOrderTx(obm.dbMgr, orderID)
			if err != nil || orderTx == nil {
				continue
			}

			// 4) æŠŠ OrderTx è½¬æˆæ’®åˆå±‚ Order
			order, err := convertOrderTxToOrder(orderTx)
			if err != nil {
				continue
			}

			// 5) åŠ å…¥å†…å­˜
			_ = ob.AddOrder(order)
		}
		return nil
	})
}

func (obm *OrderBookManager) PruneAndRebuild(pair TradingPair, markPrice decimal.Decimal) error {
	ob := obm.GetOrderBook(pair.BaseToken, pair.QuoteToken)

	// å…ˆåœ¨å†…å­˜é‡Œ prune
	ob.PruneByMarkPrice(markPrice)

	// å†ä»æ•°æ®åº“åŠ è½½ [0.5 * markPrice, 2.0 * markPrice] åŒºé—´è®¢å•
	lowerBound := markPrice.Mul(decimal.NewFromFloat(0.5))
	upperBound := markPrice.Mul(decimal.NewFromFloat(2.0))
	return obm.LoadOrdersInRange(pair.BaseToken, pair.QuoteToken, lowerBound, upperBound)
}


æ–‡ä»¶è·¯å¾„: matching/price_heap.go
æ–‡ä»¶å†…å®¹:
package matching

import (...)

// --------------------- æ•°æ®ç»“æ„å®šä¹‰ ---------------------

// OrderSide è¡¨ç¤ºä¹°æˆ–å–
type OrderSide int

const (
	BUY OrderSide = iota
	SELL
)

// Order è¡¨ç¤ºä¸€æ¡è®¢å•
type Order struct {
	ID     string          // è®¢å•ID
	Side   OrderSide       // ä¹° or å–
	Price  decimal.Decimal // ä»·æ ¼
	Amount decimal.Decimal // å‰©ä½™æ•°é‡
}

// PriceLevel ä»£è¡¨æŸä¸€ä»·æ ¼å±‚çš„è®¢å•åˆ—è¡¨
type PriceLevel struct {
	Price  decimal.Decimal
	Orders []*Order // åœ¨ä¸€ä¸ªç®€åŒ–å®ç°é‡Œç”¨åˆ‡ç‰‡å³å¯ï¼›å¯æ”¹ç”¨åŒå‘é“¾è¡¨ç­‰
}

// OrderRef ç”¨æ¥å¿«é€Ÿå®šä½è®¢å•å’Œå¯¹åº”çš„priceLevel
type OrderRef struct {
	Order      *Order
	PriceLevel *PriceLevel
}

// --------------------- å †(ä¹°æ–¹: MaxPriceHeap) ---------------------

type MaxPriceHeap []*PriceLevel

func (h MaxPriceHeap) Len() int { return len(h) }
func (h MaxPriceHeap) Less(i, j int) bool {
	// æƒ³è¦æœ€å¤§å †ï¼Œå°±è®©å¤§çš„åœ¨å‰
	return h[i].Price.Cmp(h[j].Price) > 0
}
func (h MaxPriceHeap) Swap(i, j int) {
	h[i], h[j] = h[j], h[i]
}
func (h *MaxPriceHeap) Push(x interface{}) {
	*h = append(*h, x.(*PriceLevel))
}
func (h *MaxPriceHeap) Pop() interface{} {
	old := *h
	n := len(old)
	item := old[n-1]
	*h = old[0 : n-1]
	return item
}

// --------------------- å †(å–æ–¹: MinPriceHeap) ---------------------

type MinPriceHeap []*PriceLevel

func (h MinPriceHeap) Len() int { return len(h) }
func (h MinPriceHeap) Less(i, j int) bool {
	// æƒ³è¦æœ€å°å †ï¼Œå°±è®©å°çš„åœ¨å‰
	return h[i].Price.Cmp(h[j].Price) < 0
}
func (h MinPriceHeap) Swap(i, j int) {
	h[i], h[j] = h[j], h[i]
}
func (h *MinPriceHeap) Push(x interface{}) {
	*h = append(*h, x.(*PriceLevel))
}
func (h *MinPriceHeap) Pop() interface{} {
	old := *h
	n := len(old)
	item := old[n-1]
	*h = old[0 : n-1]
	return item
}


æ–‡ä»¶è·¯å¾„: matching/types.go
æ–‡ä»¶å†…å®¹:
package matching

import (...)

//OrderBookManager é‡ŒæŒæœ‰ä¸€ä¸ª tradeChï¼Œè´Ÿè´£æ¥æ”¶æ‰€æœ‰æ’®åˆäº‹ä»¶ã€‚
//æ¯ä¸ª OrderBook åœ¨æ„é€ æ—¶æ‹¿åˆ°è¿™ä¸ªé€šé“å¼•ç”¨ï¼Œæ¯æ¬¡ executeTrade() å®Œéƒ½å¾€é‡Œå‘é€ TradeUpdateã€‚
//OrderBookManager è‡ªå·±å¼€ goroutineï¼ˆhandleTradeUpdatesï¼‰æŒç»­ä»é€šé“é‡Œè¯»ï¼Œç„¶åå» db.UpdateOrderTxInDB åšæ•°æ®åº“æ›´æ–°ã€‚
//è¿™æ ·å³å¯å®ç°â€œä¸€æ—¦æœ‰æ’®åˆå°±èƒ½ç«‹åˆ»æ›´æ–°â€ï¼Œä¸ç®¡éƒ¨åˆ†è¿˜æ˜¯å…¨éƒ¨ã€‚

// TradeUpdate è¡¨ç¤ºä¸€æ¬¡æ’®åˆäº‹ä»¶ï¼Œå¯èƒ½æ˜¯éƒ¨åˆ†æˆäº¤æˆ–å…¨éƒ¨æˆäº¤
type TradeUpdate struct {
	OrderID    string          // è®¢å•ID
	TradeAmt   decimal.Decimal // æœ¬æ¬¡æ’®åˆæˆäº¤é‡
	TradePrice decimal.Decimal // æœ¬æ¬¡æ’®åˆä½¿ç”¨çš„ä»·æ ¼
	RemainAmt  decimal.Decimal // è®¢å•å‰©ä½™é‡(æ’®åˆå)
	IsFilled   bool            // æ˜¯å¦å·²å®Œå…¨æˆäº¤
}

// OrderBook åŒ…å«ä¹°ã€å–åŒæ–¹çš„ä»·æ ¼æ˜ å°„ã€å †ï¼Œä»¥åŠè®¢å•IDç´¢å¼•
type OrderBook struct {
	buyMap  map[decimal.Decimal]*PriceLevel
	sellMap map[decimal.Decimal]*PriceLevel

	buyHeap  *MaxPriceHeap // å †é¡¶æ˜¯æœ€é«˜ä¹°ä»·
	sellHeap *MinPriceHeap // å †é¡¶æ˜¯æœ€ä½å–ä»·

	orderIndex map[string]*OrderRef

	// ç”¨äºå‘é€æ’®åˆäº‹ä»¶
	tradeCh chan<- TradeUpdate
}

func NewOrderBook(tradeCh chan<- TradeUpdate) *OrderBook {
	return &OrderBook{
		buyMap:     make(map[decimal.Decimal]*PriceLevel),
		sellMap:    make(map[decimal.Decimal]*PriceLevel),
		buyHeap:    &MaxPriceHeap{},
		sellHeap:   &MinPriceHeap{},
		orderIndex: make(map[string]*OrderRef),
		tradeCh:    tradeCh,
	}
}

// extractOrderTx å°è¯•ä» AnyTx æå– OrderTx
func extractOrderTx(a *pb.AnyTx) *pb.OrderTx {
	content := a.GetContent()
	otx, ok := content.(*pb.AnyTx_OrderTx)
	if !ok {
		return nil
	}
	return otx.OrderTx
}

// convertOrderTxToOrder å°† db.OrderTx è½¬ä¸º match.go é‡Œçš„ Order ç»“æ„
func convertOrderTxToOrder(o *pb.OrderTx) (*Order, error) {
	if o == nil || o.Base == nil {
		return nil, errors.New("orderTx invalid")
	}
	// sideï¼šç¤ºä¾‹ä¸­, OrderOp_ADD = BUY, OrderOp_REMOVE = SELL
	var side OrderSide
	if o.Op == pb.OrderOp_ADD {
		side = BUY
	} else {
		side = SELL
	}

	price, err := decimal.NewFromString(o.Price)
	if err != nil {
		return nil, fmt.Errorf("parse price error: %v", err)
	}
	amount, err := decimal.NewFromString(o.Amount)
	if err != nil {
		return nil, fmt.Errorf("parse amount error: %v", err)
	}
	// äºŒæ¬¡æ ¡éªŒ
	lowerBound := decimal.NewFromFloat(1e-33)
	upperBound := decimal.NewFromFloat(1e33)
	if price.Cmp(lowerBound) < 0 || price.Cmp(upperBound) > 0 {
		return nil, fmt.Errorf("price out of range [1e-33, 1e33]")
	}
	return &Order{
		ID:     o.Base.TxId,
		Side:   side,
		Price:  price,
		Amount: amount,
	}, nil
}


æ–‡ä»¶è·¯å¾„: middleware/middleware.go
æ–‡ä»¶å†…å®¹:
package middleware

import (...)

// å…¨å±€å˜é‡ï¼Œç”¨äºè®°å½•æ¯ä¸ª IP åœ¨å½“å‰æ—¶é—´çª—å£å†…çš„è¯·æ±‚æ¬¡æ•°ä»¥åŠæœ€åä¸€æ¬¡æ›´æ–°æ—¶é—´
var (
	ipRequestCount = make(map[string]int)
	ipLastReset    = make(map[string]time.Time)
	mu             sync.Mutex
)

// é…ç½®å‚æ•°
const (
	requestLimit    = 1000000000000   // æ¯ä¸ª IP æ¯ä¸ªçª—å£å…è®¸çš„æœ€å¤§è¯·æ±‚æ¬¡æ•°
	resetInterval   = time.Second     // è¯·æ±‚è®¡æ•°çš„æ—¶é—´çª—å£ï¼Œ1åˆ†é’Ÿ
	cleanupInterval = 2 * time.Minute // æ¸…ç†é—´éš”ï¼Œæ¯2åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡ä¸æ´»è·ƒè®°å½•
)

// RateLimit æ˜¯ä¸€ä¸ªä¸­é—´ä»¶ï¼Œç”¨äºé™åˆ¶æ¯ä¸ª IP åœ¨ resetInterval å†…çš„è¯·æ±‚æ¬¡æ•°
func RateLimit(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// è·å–å®¢æˆ·ç«¯ IPï¼ˆç®€å•å¤„ç†ï¼Œä¸å¤„ç† IPv6 æ ¼å¼ç­‰æƒ…å†µï¼‰
		clientIP := strings.Split(r.RemoteAddr, ":")[0]

		mu.Lock()
		now := time.Now()
		// å¦‚æœè¯¥ IP ä¸å­˜åœ¨è®°å½•ï¼Œæˆ–è€…ä¸Šæ¬¡è®°å½•çš„æ—¶é—´å·²ç»è¶…è¿‡äº† resetIntervalï¼Œåˆ™é‡ç½®è®¡æ•°
		if last, ok := ipLastReset[clientIP]; !ok || now.Sub(last) > resetInterval {
			ipRequestCount[clientIP] = 0
			ipLastReset[clientIP] = now
		}

		// ç´¯åŠ è¯·æ±‚æ¬¡æ•°
		ipRequestCount[clientIP]++
		// å¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è¿”å› 429 Too Many Requests
		if ipRequestCount[clientIP] > requestLimit {
			mu.Unlock()
			http.Error(w, "Too Many Requests", http.StatusTooManyRequests)
			return
		}
		mu.Unlock()

		// è°ƒç”¨ä¸‹ä¸€ä¸ª Handler
		next.ServeHTTP(w, r)
	})
}

// StartIPCleanup å¯åŠ¨ä¸€ä¸ªåå° goroutineï¼Œå®šæ—¶æ¸…ç†ä¸æ´»è·ƒçš„ IP è®°å½•
func StartIPCleanup() {
	ticker := time.NewTicker(cleanupInterval)
	go func() {
		for range ticker.C {
			mu.Lock()
			now := time.Now()
			// éå†æ‰€æœ‰ IPï¼Œå¦‚æœä¸Šæ¬¡è®°å½•çš„æ—¶é—´è¶…è¿‡ 2 * resetIntervalï¼Œåˆ™åˆ é™¤è¯¥ IP è®°å½•
			for ip, last := range ipLastReset {
				if now.Sub(last) > 2*resetInterval {
					delete(ipLastReset, ip)
					delete(ipRequestCount, ip)
				}
			}
			mu.Unlock()
		}
	}()
}


æ–‡ä»¶è·¯å¾„: network/network.go
æ–‡ä»¶å†…å®¹:
package network

import (...)

// Network è´Ÿè´£ç»´æŠ¤å¯¹ç­‰èŠ‚ç‚¹åˆ—è¡¨ã€ä»DBåŠ è½½æˆ–æ›´æ–°
type Network struct {
	dbManager *db.Manager
	mu        sync.RWMutex
	nodes     map[string]*pb.NodeInfo // key=publicKey
}

// NewNetwork åˆ›å»ºä¸€ä¸ª Network å®ä¾‹å¹¶ä»DBåŠ è½½å·²æœ‰èŠ‚ç‚¹
func NewNetwork(dbMgr *db.Manager) *Network {
	n := &Network{
		dbManager: dbMgr,
		nodes:     make(map[string]*pb.NodeInfo),
	}

	// å¦‚æœéœ€è¦åˆå§‹åŒ–æ—¶åŠ è½½ DB é‡Œçš„ nodeä¿¡æ¯
	nodes, err := dbMgr.GetAllNodeInfos()
	if err != nil {
		logs.Verbose("[Network] Failed to load nodes from DB: %v", err)
	} else {
		for _, node := range nodes {
			n.nodes[node.PublicKey] = node
		}
	}
	return n
}

// AddOrUpdateNode æ›´æ–°æˆ–æ–°å¢èŠ‚ç‚¹ä¿¡æ¯
func (n *Network) AddOrUpdateNode(pubKey, ip string, isOnline bool) {
	n.mu.Lock()
	defer n.mu.Unlock()

	info := &pb.NodeInfo{
		PublicKey: pubKey,
		Ip:        ip,
		IsOnline:  isOnline,
	}
	n.nodes[pubKey] = info

	// åŒæ­¥å†™DB
	if err := n.dbManager.SaveNodeInfo(info); err != nil {
		logs.Verbose("[Network] Failed to save node info: %v", err)
	}
}

// GetNodeByPubKey è·å–æŸä¸ªå…¬é’¥å¯¹åº”çš„NodeInfo
func (n *Network) GetNodeByPubKey(pubKey string) *pb.NodeInfo {
	n.mu.RLock()
	defer n.mu.RUnlock()
	return n.nodes[pubKey]
}

// GetAllNodes è¿”å›æ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯
func (n *Network) GetAllNodes() []*pb.NodeInfo {
	n.mu.RLock()
	defer n.mu.RUnlock()

	var result []*pb.NodeInfo
	for _, node := range n.nodes {
		result = append(result, node)
	}
	return result
}

// IsKnownNode åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦åœ¨æœ¬åœ°è·¯ç”±è¡¨é‡Œ
func (n *Network) IsKnownNode(pubKey string) bool {
	n.mu.RLock()
	defer n.mu.RUnlock()
	_, ok := n.nodes[pubKey]
	return ok
}

// GetTop100CouncilNodes ä»æ•°æ®åº“ä¸­è¯»å–â€œstakeIndex_â€é”®è·å–å‰100ä¸ªè®®å‘˜ï¼ˆçŸ¿å·¥ï¼‰çš„åœ°å€ï¼Œ
// ç„¶åæ ¹æ®è¿™äº›åœ°å€åœ¨ network.nodes æ˜ å°„ä¸­æŸ¥æ‰¾ç›¸åº”çš„èŠ‚ç‚¹ä¿¡æ¯å¹¶è¿”å›ã€‚
// å¦‚æœæœªèƒ½æ‰¾åˆ° 100 ä¸ªè®®å‘˜ï¼Œåˆ™è¿”å›é”™è¯¯ã€‚


æ–‡ä»¶è·¯å¾„: pb/anytx_ext.go
æ–‡ä»¶å†…å®¹:
// pb/anytx_ext.go
package pb

func (m *AnyTx) GetBase() *BaseMessage {
	switch tx := m.GetContent().(type) {
	case *AnyTx_IssueTokenTx:
		return tx.IssueTokenTx.GetBase()
	case *AnyTx_FreezeTx:
		return tx.FreezeTx.GetBase()
	case *AnyTx_Transaction:
		return tx.Transaction.GetBase()
	case *AnyTx_OrderTx:
		return tx.OrderTx.GetBase()
	case *AnyTx_AddressTx:
		return tx.AddressTx.GetBase()
	case *AnyTx_CandidateTx:
		return tx.CandidateTx.GetBase()
	default:
		return nil
	}
}

func (m *AnyTx) GetTxId() string {
	if b := m.GetBase(); b != nil {
		return b.TxId
	}
	return ""
}


æ–‡ä»¶è·¯å¾„: pb/data.proto
æ–‡ä»¶å†…å®¹:
syntax = "proto3";
// protoc --go_out=. --go_opt=paths=source_relative db/data.proto
package pb;

option go_package = "awesomeProject1/db;db";

// --------------------- Token & Registry ---------------------
message Token {
  string address = 1; // tokenåœ°å€ï¼Œæ‰€æœ‰tokenéƒ½æ˜¯å¹³çº§ï¼ŒåŒºåˆ«æ˜¯ç³»ç»Ÿtokenä¼šæœ‰ä»£ç å¯¹å®ƒçš„åœ°å€åšç‰¹æ®Šå¤„ç†ï¼Œæ¯”å¦‚åŸç”Ÿä»£å¸FBä¼šæŠŠåœ°å€ç¡¬ç¼–ç åˆ°ä»£ç é‡Œé¢
  string symbol = 2; // ä¾‹å¦‚ "USDT"ã€"MYT"ç­‰
  string name = 3;   // ä¾‹å¦‚ "Tether USD"
  string owner = 4;  // æ‹¥æœ‰è€…åœ°å€ï¼Œå¯åšå†»ç»“ç­‰ç®¡ç†æƒé™ï¼Œå¦‚æœç­‰äº 0x0 è¡¨ç¤ºæ²¡æœ‰æ‹¥æœ‰è€…
  string totalSupply = 5; // å‘è¡Œæ€»é‡
  bool canMint = 6;       // æ˜¯å¦å¯å¢å‘ï¼Œé”€æ¯çš„è¯ç›´æ¥æ‰“å…¥ 0x0 åœ°å€å³å¯ï¼ŒæŸ¥è¯¢0x0ä¹Ÿå¯æŸ¥åˆ°è¢«é”€æ¯çš„tokenæ•°é‡
}

message TokenRegistry {
  map<string, Token> tokens = 1;
}

// --------------------- å…¬å…±å­—æ®µå®šä¹‰ ---------------------
message BaseMessage {
  string tx_id = 1;         // äº¤æ˜“ ID å³hash
  string from_address = 2;  // å‘èµ·è€…åœ°å€
  uint64 executed_height = 3; // å®é™…æ‰§è¡Œçš„åŒºå—é«˜åº¦
  string public_key = 4;
  string signature = 5;     // ç­¾å
  Status status = 6;
  uint64 nonce = 7;
}

// --------------------- è´¦æˆ· & åŒºå—ä¿¡æ¯ ---------------------
message Account {
  string address = 1; // è´¦æˆ·åœ°å€
  string public_key = 2; // åœ°å€å¯¹åº”çš„å…¬é’¥
  uint64 nonce = 3;   // è´¦æˆ·çš„æ“ä½œåºå·
  repeated string orders = 4; // æœªæ‰§è¡Œå®Œçš„ order çŠ¶æ€çš„ hash åˆ—è¡¨
  map<string, TokenBalance> balances = 5; // keyä¸ºtokenåœ°å€
  string receive_votes = 6; // æ­¤è´¦æˆ·æ”¶åˆ°çš„æŠ•ç¥¨
  string candidate = 7;     // è¢«æ­¤è´¦æˆ·é€‰ä¸¾çš„äººï¼Œä¸€ä¸ªè´¦æˆ·åªèƒ½åŒæ—¶é€‰ä¸¾ä¸€ä¸ªäºº
  string unclaimed_reward = 8;  // ç´¯è®¡ä½†å°šæœªé¢†å–çš„å¥–åŠ±
  string last_acc_reward = 9;   // ä¸Šæ¬¡æ›´æ–°æ—¶çš„ç´¯ç§¯å› å­
  bool   is_miner = 10;     // æ˜¯å¦æ­£åœ¨å‚ä¸å…±è¯†æŒ–çŸ¿
  string ip = 11;
  uint64 index = 12; // æ¯ä¸ªçŸ¿å·¥éƒ½æœ‰å”¯ä¸€çš„indexï¼Œç”¨äºbitmap
  string code = 13;    // ä¸ºåç»­åˆçº¦åŠŸèƒ½ä¿ç•™å­—æ®µ
}

message TokenBalance {
  string balance = 1;       // å¯ç”¨ä½™é¢
  string candidate_locked_balance = 2; // æŠ•ç¥¨é”å®šä½™é¢
  string miner_locked_balance = 3; // å…±è¯†æŒ–çŸ¿é”å®šä½™é¢
  string liquid_locked_balance = 4; // æµåŠ¨æ€§æŒ–çŸ¿é”å®šä½™é¢
  string witness_locked_balance = 5; // è§è¯è€…æŒ–çŸ¿é”å®šä½™é¢
  string leverage_locked_balance = 6; // æ æ†äº¤æ˜“é”å®šä½™é¢
}

message Block {
  uint64 height = 1;
  string txs_hash = 2;
  string block_hash = 3;
  string prev_block_hash = 4;
  string accumulated_reward = 5;// åŒºå—å¥–åŠ±ç´¯è®¡å› å­
  bytes bit_map = 6; // çŸ¿å·¥åœ¨çº¿ä½å›¾
  bytes miner_signature = 7;
  bytes short_txs = 8;
  string miner = 9;
  repeated AnyTx body = 10;// å…¨éƒ¨äº¤æ˜“
}
message RewordInfo {

}
message OrderPriceIndex {// å¿«é€Ÿæ£€ç´¢åˆ°ä»·æ ¼åŒºé—´çš„è®¢å•ï¼Œä¸orderTxä¸€å¹¶å­˜å…¥
  bool ok = 1; //å ä½ç¬¦,ä¸éœ€è¦ï¼Œä¸»è¦æ˜¯éœ€è¦è¿™ä¸ªå­—æ®µçš„key(pair:...|price:...|is_filledï¼š...|order_id:...)æ¥å¿«é€ŸæŸ¥è¯¢åˆ°ä»·æ ¼åŒºé—´å†…ï¼Œè¿˜æœªå®Œå…¨æˆäº¤ï¼ˆis_filled:falseï¼‰çš„tx
}
message CandidateIndex {//å¿«é€Ÿéå†åˆ°è®®å‘˜çš„æ‰€æœ‰å§”æ‰˜äºº
  bool ok = 1;// key(candidate:...|user:...)
}
// --------------------- äº¤æ˜“ç›¸å…³æ¶ˆæ¯ ---------------------
message IssueTokenTx {// å‘å¸tx
  BaseMessage base = 1;
  string token_name = 2;
  string token_symbol = 3;
  string total_supply = 4;
  bool canMint = 5;
}

message FreezeTx {//å†»ç»“ã€è§£å†»Token tx
  BaseMessage base = 1;
  string token_addr = 2;
  string target_addr = 3;
  bool freeze = 4; // true ä¸ºå†»ç»“ï¼Œfalse ä¸ºè§£å†»
}

message Transaction {//è½¬è´¦tx
  BaseMessage base = 1;
  string to = 2;
  string token_address = 3;
  string amount = 4;
}

message OrderTx {//ä¸‹å•tx
  BaseMessage base = 1;
  string base_token = 2;  // ä¾‹å¦‚ "bc1q6156"ä»£è¡¨USDT
  string quote_token = 3; // ä¾‹å¦‚ "bc1q0000"ä»£è¡¨BTC
  OrderOp op = 4; // ADDæ˜¯æ›´æ–°è®¢å•çŠ¶æ€REMOVEæ˜¯æ’¤å•ï¼Œä¹°å•å’Œä¹°å•æ˜¯æŒ‰base_tokenå’Œquote_tokenæ¥å†³å®šçš„ã€‚æ¯”å¦‚ä¹°BTCï¼Œé‚£ä¹ˆbase_token=USDTçš„åœ°å€,quote_token=BTCçš„åœ°å€
  string op_target_id = 5;   // å¦‚æœè¦æ›´æ–°/ç§»é™¤è®¢å•id
  string amount = 6;
  string price = 7;
  string filled_base = 8;  // è¡¨ç¤ºè¯¥è®¢å•å·²ç»æˆäº¤çš„baseæ•°é‡
  string filled_quote = 9; // è¡¨ç¤ºè¯¥è®¢å•å·²ç»æˆäº¤çš„quoteæ•°é‡
  bool is_filled = 10; // æ˜¯å¦å·²ç»å®Œå…¨æˆäº¤æ ‡ç­¾
}

message RechargeTx {//ä¸Šè´¦TX,ç”¨æˆ·è‡ªå·±åœ¨æœ¬åœ°æ ¹æ®å…¬é’¥+tweakç”Ÿæˆå……å€¼åœ°å€ã€‚å……å€¼å®Œæˆåå¹¿æ’­RechargeTx
  BaseMessage base = 1;
  string token_address = 2;//å¯¹åº”æœ¬é“¾çš„å“ªä¸ªèµ„äº§
  //è¿™ä¸ªå­—æ®µåœ¨æ‰“åŒ…åŒºå—çš„æ—¶å€™ç”Ÿæˆï¼Œç”¨æˆ·ç›´æ¥é€šè¿‡åŒºå—é“¾æµè§ˆå™¨æŸ¥è¯¢å³å¯
  string generated_address = 3;//ç”Ÿæˆçš„èšåˆåœ°å€ï¼Œå¦‚æœæ˜¯btcå°±ç›´æ¥ç”¨ï¼Œå¦‚æœæ˜¯å…¶ä»–é“¾å°±å¯¹åº”å…¶åˆçº¦å†…çš„æ‰€æœ‰è€…å­—æ®µ
  string tweak = 4;//åœ¨é’±åŒ…ç«¯ï¼Œç”Ÿæˆåœ°å€çš„æ—¶å€™è®°å½•ä¸‹æ¥ï¼Œ
  //åŒä¸€ä¸ªåœ°å€å¤šæ¬¡ä¸Šè´¦å’‹æï¼Ÿ
  //ä¸è¡Œï¼Œä¸€ä¸ªAddressTxå¯¹åº”ä¸€æ¬¡ä¸Šè´¦è¯·æ±‚
}

message CandidateTx {//å§”æ‰˜äººtx
  BaseMessage base = 1;
  OrderOp op = 2;
  string candidate_address = 3;
  string amount = 4;
}
message MinerTx {//å‘ŠçŸ¥å…¨ç½‘è‡ªå·±æ˜¯å¦å‚ä¸å…±è¯†æŒ–çŸ¿
  BaseMessage base = 1;
  OrderOp op = 2;//å¦‚æœæ˜¯ADDï¼Œåˆ™ä¼šç›´æ¥æŠŠis_minerç½®ä¸ºtrue,miner_locked_balanceä¼šè¢«amountç´¯åŠ ã€‚
  string amount = 3;// å¦‚æœæ˜¯REMOVEä¸éœ€è¦ä¼ è¿™ä¸ªå‚æ•°ï¼Œis_minerç½®ä¸ºfalse,miner_locked_balanceçš„å€¼ç›´æ¥ç´¯åŠ åˆ°TokenBalance.balance,miner_locked_balanceç½®0

}

// ç”¨ oneof å°è£…å„ç§ Tx
message AnyTx {
  oneof content {
    IssueTokenTx issue_token_tx = 1;
    FreezeTx freeze_tx = 2;
    Transaction transaction = 3;
    OrderTx order_tx = 4;
    RechargeTx address_tx = 5;
    CandidateTx candidate_tx = 6;
    MinerTx miner_tx = 8;
  }
}
// --------------------- è®¢å• & çŠ¶æ€ç›¸å…³ ---------------------
enum OrderOp {
  ADD = 0;
  REMOVE = 1;
}

enum Status {
  PENDING = 0;
  FAILED = 1;
  SUCCEED = 2;
}

// --------------------- èŠ‚ç‚¹==å®¢æˆ·ç«¯ä¿¡æ¯ ---------------------
message NodeInfo {
  string public_key = 1;
  string ip = 2;
  bool isOnline = 4;
}

message NodeList {
  repeated NodeInfo nodes = 1;
}

message ClientInfo {
  string ip = 1;
  bool authed = 2;
  string public_key_pem = 3; // å‡è®¾ä»¥ PEM æ ¼å¼å­˜å‚¨å…¬é’¥ï¼Œä¹Ÿå¯ä»¥å­˜å…¶å®ƒå½¢å¼
}

// --------------------- Handshake & çŠ¶æ€è¯·æ±‚ ---------------------
message HandshakeRequest {
  string client_id = 1; // å°±æ˜¯çŸ¿å·¥åœ°å€
  string public_key = 2; // PEM
  string signature = 3;
}

message HandshakeResponse {
  string status = 1; // "handshake_ok" æˆ–å…¶å®ƒ
}

message StatusRequest {
  string address = 1;  // è¯·æ±‚æ–¹åœ°å€
}

message StatusResponse {
  string status = 1; // "ok"
  string info = 2;   // "Server is running"
}

// --------------------- èŠ‚ç‚¹é—´é€šè®¯ä¿¡æ¯ ---------------------

// ç”¨äºè¯·æ±‚å®Œæ•´äº¤æ˜“æ•°æ®
message GetData {
  string tx_id = 1;
  string address = 2;// è¯·æ±‚æ–¹åœ°å€
}

message GetBlockRequest {
  uint64 height = 1;   // æƒ³è¦è·å–å“ªä¸ªé«˜åº¦çš„åŒºå—
}
message GetBlockResponse {
  Block block = 1;     // è‹¥æˆåŠŸï¼Œåˆ™è¿”å›å®Œæ•´åŒºå—
  string error = 2;    // è‹¥å‡ºé”™ï¼ŒæŠŠé”™è¯¯ä¿¡æ¯è¿”å›ç»™è¯·æ±‚æ–¹
}

message BatchGetShortTxRequest {
  repeated bytes short_hashes = 1; // æ¯ä¸ª 8 å­—èŠ‚çš„çŸ­ hash
  string address = 2;  // è¯·æ±‚æ–¹åœ°å€
}

message BatchGetShortTxResponse {
  repeated AnyTx transactions = 1;
}
message CheckPointInfo {
  uint64 height = 1;
  string txs_hash = 2;
  bytes aggregate_signature = 3;
  bytes bit_map = 4;
  bytes txs = 5;// æ‰€æœ‰äº¤æ˜“çš„ç®€çŸ­tx_hash
}
// æ‹‰å–å…±è¯†çŠ¶æ€çš„è¯·æ±‚ï¼ˆç›®å‰ä¸ºç©ºï¼Œå¯æ‰©å±•ï¼‰
message GetConsensusStateRequest {}
// ---------------- Snowman networking ----------------
message PushQuery {
  uint32 request_id = 1;
  string address = 2;
  // Timeout (ns) for this request
  uint64 deadline = 3;
  bool container_is_block = 4;// ä¸ºtrueè¡¨ç¤ºæ˜¯å®Œæ•´æ•°æ®ï¼Œfalseè¡¨ç¤ºåªæœ‰txs
  bytes container = 5;// å½“txæ•°é‡å°äº2500æ—¶å€™ï¼Œè¯¥å­—æ®µä¸ºæ‰€æœ‰äº¤æ˜“çš„å®Œæ•´äºŒè¿›åˆ¶æ•°æ®ï¼Œ>=2500çš„æ—¶å€™ä¸º æ‰€æœ‰äº¤æ˜“çš„ç®€çŸ­tx_hash
  // Requesting peer's last accepted height
  uint64 requested_height = 6;
  string block_id = 7;
  bytes signature = 8;  // TODOï¼šæ¶ˆæ¯ç­¾å
  uint64 nonce = 9;     // TODOï¼šé˜²é‡æ”¾æ”»å‡»
}

// PullQuery requests the preferences of a remote peer given a container id.
//
// Remote peers should respond to a PullQuery with a Chits message
message PullQuery {
  uint32 request_id = 1;
  string address = 2;
  // Timeout (ns) for this request
  uint64 deadline = 3;
  // Container id being gossiped
  string block_id = 4;
  // Requesting peer's last accepted height
  uint64 requested_height = 5;
}

// Chits contains the preferences of a peer in response to a PushQuery or
// PullQuery message.
message Chits {
  uint32 request_id = 1;
  string address = 2;
  // ID of the currently preferred block
  string preferred_block = 3;
  // ID of the last accepted block
  string accepted_block = 4;
  // ID of the currently preferred block at the requested height
  uint64 preferred_block_at_height = 5;
  // Last accepted block's height
  uint64 accepted_height = 6;
  bytes bitmap = 7;//ä¸Šä¸€ä¸ªåŒºå—ä¸è‡ªå·±è”ç³»è¿‡çš„èŠ‚ç‚¹
}

message HeightResponse{ // éœ€è¦åœ¨protoä¸­å®šä¹‰
  uint64 LastAcceptedHeight = 1;
  uint64 CurrentHeight = 2;
  string address = 3;  // å“åº”æ–¹åœ°å€
}

message GetBlockByIDRequest { string block_id = 1; }
è·³è¿‡æ’é™¤çš„ç›®å½•: print

æ–‡ä»¶è·¯å¾„: sender/consensus_types.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// ============= Message Types =============

// chitsMessage ç”¨äºå‘é€Chitså“åº”
type chitsMessage struct {
	requestData []byte
}

// blockMessage ç”¨äºå‘é€å®Œæ•´åŒºå—
type blockMessage struct {
	requestData []byte
}

// heightQueryMessage ç”¨äºå‘é€é«˜åº¦æŸ¥è¯¢
type heightQueryMessage struct {
	requestData []byte
	onSuccess   func(*pb.HeightResponse)
}

// syncRequestMessage ç”¨äºåŒæ­¥è¯·æ±‚
type syncRequestMessage struct {
	requestData []byte
	fromHeight  uint64
	toHeight    uint64
	onSuccess   func([]*pb.Block)
}


æ–‡ä»¶è·¯å¾„: sender/crypto_utils.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

var (
	ClientPrivateKey *ecdsa.PrivateKey
	ClientPublicKey  *ecdsa.PublicKey
)

func InitKeys() {
	var err error
	ClientPrivateKey, err = ecdsa.GenerateKey(elliptic.P256(), rand.Reader)
	if err != nil {
		logs.Error("Failed to generate client key: %v", err)
	}
	ClientPublicKey = &ClientPrivateKey.PublicKey
}

func SignMessage(priv *ecdsa.PrivateKey, message string) (string, error) {
	hash := sha256.Sum256([]byte(message))
	r, s, err := ecdsa.Sign(rand.Reader, priv, hash[:])
	if err != nil {
		return "", err
	}

	// å°† r å’Œ s è¡¥è¶³è‡³ 32 å­—èŠ‚
	rBytes := r.Bytes()
	sBytes := s.Bytes()

	rBytesPadded := make([]byte, 32)
	sBytesPadded := make([]byte, 32)
	copy(rBytesPadded[32-len(rBytes):], rBytes)
	copy(sBytesPadded[32-len(sBytes):], sBytes)

	return hex.EncodeToString(rBytesPadded) + hex.EncodeToString(sBytesPadded), nil
}
func SignBlsMessage(message string) ([]byte, error) {
	priv := utils.GetKeyManager().PrivateKeyECDSA
	if priv == nil {
		return nil, errors.New("miner private key not initialized")
	}
	return utils.BLSSignWithCache(priv, message)
}
func PublicKeyToPEM(pub *ecdsa.PublicKey) string {
	derBytes, err := x509.MarshalPKIXPublicKey(pub)
	if err != nil {
		logs.Error("Failed to marshal public key: %v", err)
	}
	block := &pem.Block{
		Type:  "PUBLIC KEY",
		Bytes: derBytes,
	}
	return string(pem.EncodeToMemory(block))
}


æ–‡ä»¶è·¯å¾„: sender/doSendBatchGetTxs.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// pullBatchTxMessage å°è£…äº†æ‰¹é‡è·å–äº¤æ˜“è¯·æ±‚çš„payloadåŠå›è°ƒå‡½æ•°
type pullBatchTxMessage struct {
	requestData []byte
	// onSuccess å›è°ƒè¿”å›è·å–åˆ°çš„äº¤æ˜“åˆ‡ç‰‡
	onSuccess func([]*pb.AnyTx)
}

// æ‰§è¡ŒHTTP/3 POSTè¯·æ±‚è·å–æ‰¹é‡äº¤æ˜“
func doSendBatchGetTxs(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*pullBatchTxMessage)
	if !ok {
		return fmt.Errorf("doSendBatchGetTxs: message is not *pullBatchTxMessage, got %T", t.Message)
	}

	// æ„é€ è¯·æ±‚URLï¼Œè°ƒç”¨ /batchgetdata æ¥å£
	url := fmt.Sprintf("https://%s/batchgetdata", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(msg.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendBatchGetTxs: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	respBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	var respMsg pb.BatchGetShortTxResponse
	if err := proto.Unmarshal(respBytes, &respMsg); err != nil {
		return fmt.Errorf("doSendBatchGetTxs: unmarshal BatchGetDataResponse failed: %v", err)
	}

	// è°ƒç”¨å›è°ƒå‡½æ•°ä¼ å‡ºç»“æœ
	if msg.onSuccess != nil {
		msg.onSuccess(respMsg.Transactions)
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendBlock.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ‰§è¡ŒåŒºå—å‘é€
func doSendBlock(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*blockMessage)
	if !ok {
		return fmt.Errorf("doSendBlock: message is not *blockMessage, got %T", t.Message)
	}

	url := fmt.Sprintf("https://%s/put", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(msg.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendBlock: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendChits.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ‰§è¡ŒChitså‘é€
func doSendChits(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*chitsMessage)
	if !ok {
		return fmt.Errorf("doSendChits: message is not *chitsMessage, got %T", t.Message)
	}

	url := fmt.Sprintf("https://%s/chits", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(msg.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendChits: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendGetBlock.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// pullBlockMessage ç”¨æ¥åŒ…è£…ï¼šè¦è¯·æ±‚çš„ height + å›è°ƒå‡½æ•°
type pullBlockMessage struct {
	requestData []byte
	onSuccess   func(*pb.Block)
}

// çœŸæ­£æ‰§è¡Œ HTTP/3 POST /getblock å¹¶è§£æè¿”å›
func doSendGetBlock(t *SendTask, client *http.Client) error {
	pm, ok := t.Message.(*pullBlockMessage)
	if !ok {
		return fmt.Errorf("doSendGetBlock: t.Message is not *pullBlockMessage")
	}

	url := fmt.Sprintf("https://%s/getblock", t.Target)

	req, err := http.NewRequest("POST", url, bytes.NewReader(pm.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendGetBlock: status=%d, body=%s",
			resp.StatusCode, string(respData))
	}

	// å¦‚æœæœåŠ¡ç«¯ä½¿ç”¨ gzip å‹ç¼©ï¼Œåˆ™éœ€è¦è§£å‹
	var reader io.Reader = resp.Body
	if resp.Header.Get("Content-Encoding") == "gzip" {
		gzReader, err := gzip.NewReader(resp.Body)
		if err != nil {
			return fmt.Errorf("doSendGetBlock: cannot create gzip reader: %v", err)
		}
		defer gzReader.Close()
		reader = gzReader
	}

	// è¯»å–å“åº”ä½“å¹¶ååºåˆ—åŒ–
	respBytes, err := io.ReadAll(reader)
	if err != nil {
		return fmt.Errorf("doSendGetBlock: read body error: %v", err)
	}

	var blockResp pb.GetBlockResponse
	if err := proto.Unmarshal(respBytes, &blockResp); err != nil {
		return fmt.Errorf("doSendGetBlock: unmarshal GetBlockResponse err=%v", err)
	}
	if blockResp.Error != "" {
		return fmt.Errorf("doSendGetBlock: remote error: %s", blockResp.Error)
	}

	// è°ƒç”¨ onSuccess å›è°ƒ
	if pm.onSuccess != nil && blockResp.Block != nil {
		pm.onSuccess(blockResp.Block)
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendGetBlockByID.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ‰§è¡Œé€šè¿‡IDè·å–åŒºå—çš„è¯·æ±‚
func doSendGetBlockByID(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*pullBlockByIDMessage)
	if !ok {
		return fmt.Errorf("doSendGetBlockByID: message is not *pullBlockByIDMessage, got %T", t.Message)
	}

	url := fmt.Sprintf("https://%s/getblockbyid", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(msg.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendGetBlockByID: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	respBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	// è§£æ GetBlockResponse
	var gbr pb.GetBlockResponse
	if err := proto.Unmarshal(respBytes, &gbr); err != nil {
		return fmt.Errorf("doSendGetBlockByID: bad GetBlockResponse: %w", err)
	}
	if gbr.Block == nil {
		return fmt.Errorf("doSendGetBlockByID: empty block in response")
	}
	if gbr.Block.BlockHash != msg.blockID {
		return fmt.Errorf("doSendGetBlockByID: returned block ID mismatch, want %s, got %s",
			msg.blockID, gbr.Block.BlockHash)
	}

	if msg.onSuccess != nil {
		msg.onSuccess(gbr.Block)
	}
	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendHeightQuery.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ‰§è¡Œé«˜åº¦æŸ¥è¯¢
func doSendHeightQuery(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*heightQueryMessage)
	if !ok {
		return fmt.Errorf("doSendHeightQuery: message is not *heightQueryMessage, got %T", t.Message)
	}

	url := fmt.Sprintf("https://%s/heightquery", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(msg.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendHeightQuery: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	respBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	var heightResp pb.HeightResponse
	if err := proto.Unmarshal(respBytes, &heightResp); err != nil {
		return fmt.Errorf("doSendHeightQuery: unmarshal HeightResponse fail: %v", err)
	}

	if msg.onSuccess != nil {
		msg.onSuccess(&heightResp)
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendPullQuery.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

type pullQueryMsg struct {
	requestData []byte
}

func doSendPullQuery(t *SendTask, client *http.Client) error {
	pm, ok := t.Message.(*pullQueryMsg)
	if !ok {
		return fmt.Errorf("doSendPullQuery expect *pullQueryMsg, got %T", t.Message)
	}
	url := fmt.Sprintf("https://%s/pullquery", t.Target)
	req, _ := http.NewRequest("POST", url, bytes.NewReader(pm.requestData))
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		b, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("pullquery status=%d: %s", resp.StatusCode, string(b))
	}
	// ä¸éœ€è¦è¯»å–/ååºåˆ—åŒ– chitsï¼Œç­‰å¾…å¯¹ç«¯å¼‚æ­¥POST /chits è¿‡æ¥
	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendPushQuery.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

type pushQueryMsg struct {
	requestData []byte
}

func doSendPushQuery(t *SendTask, client *http.Client) error {
	pm, ok := t.Message.(*pushQueryMsg)
	if !ok {
		return fmt.Errorf("doSendPushQuery expect *pushQueryMsg, got %T", t.Message)
	}
	url := fmt.Sprintf("https://%s/pushquery", t.Target)
	req, _ := http.NewRequest("POST", url, bytes.NewReader(pm.requestData))
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		b, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("pushquery status=%d: %s", resp.StatusCode, string(b))
	}
	// ä¸éœ€è¦è¯»å–/ååºåˆ—åŒ– chitsï¼Œç­‰å¾…å¯¹ç«¯å¼‚æ­¥POST /chits è¿‡æ¥ï¼Œå› ä¸ºæ˜¯å¼‚æ­¥çš„
	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendSyncRequest.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ‰§è¡ŒåŒæ­¥è¯·æ±‚
func doSendSyncRequest(t *SendTask, client *http.Client) error {
	msg, ok := t.Message.(*syncRequestMessage)
	if !ok {
		return fmt.Errorf("doSendSyncRequest: message is not *syncRequestMessage, got %T", t.Message)
	}

	var blocks []*pb.Block

	for height := msg.fromHeight; height <= msg.toHeight; height++ {
		req := &pb.GetBlockRequest{Height: height}
		data, err := proto.Marshal(req)
		if err != nil {
			continue
		}

		url := fmt.Sprintf("https://%s/getblock", t.Target)
		httpReq, err := http.NewRequest("POST", url, bytes.NewReader(data))
		if err != nil {
			continue
		}
		httpReq.Header.Set("Content-Type", "application/x-protobuf")

		resp, err := client.Do(httpReq)
		if err != nil {
			continue
		}

		if resp.StatusCode == http.StatusOK {
			respBytes, err := io.ReadAll(resp.Body)
			resp.Body.Close()
			if err == nil {
				var blockResp pb.GetBlockResponse
				if err := proto.Unmarshal(respBytes, &blockResp); err == nil && blockResp.Block != nil {
					blocks = append(blocks, blockResp.Block)
				}
			}
		} else {
			resp.Body.Close()
		}
	}

	if msg.onSuccess != nil && len(blocks) > 0 {
		msg.onSuccess(blocks)
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/doSendTx.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// å®ç°å¯¹å•ä¸ªèŠ‚ç‚¹é€šè¿‡ HTTP/3 å‘é€ inv æ¶ˆæ¯
func doSendTx(t *SendTask, client *http.Client) error {
	url := fmt.Sprintf("https://%s/tx", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(t.Message.([]byte)))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	// ä½¿ç”¨ä¼ å…¥çš„ client è€Œéå…¨å±€å•ä¾‹
	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendTx: status %d, body %s", resp.StatusCode, string(respData))
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: sender/gossip_sender.go
æ–‡ä»¶å†…å®¹:
// æ–‡ä»¶è·¯å¾„: sender/gossip_sender.go

package sender

import (...)

// ------------------- ä»¥ä¸‹ä¸ºæ ¸å¿ƒå‘é€é€»è¾‘ -------------------

// ç”¨äºå‘å•ä¸ªç›®æ ‡èŠ‚ç‚¹å‘é€æ¶ˆæ¯ã€‚
// POSTåˆ°å¯¹æ–¹çš„ /gossipAnyMsgï¼ŒContent-Type=application/octet-streamã€‚
func doSendToOnePeer(t *SendTask, client *http.Client) error {
	// å…ˆæ£€æŸ¥ç±»å‹
	msgBytes, ok := t.Message.([]byte)
	if !ok {
		return fmt.Errorf("doSendToOnePeer: message is not []byte, got %T", t.Message)
	}
	if t.Target == "" {
		return errors.New("doSendToOnePeer: empty target ip")
	}

	// 1. æ„é€ URL
	url := fmt.Sprintf("https://%s/gossipAnyMsg", t.Target)

	// 2. æ„é€ HTTP/3è¯·æ±‚
	req, err := http.NewRequest("POST", url, bytes.NewReader(msgBytes))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/json")

	// 3. ç”¨http3.Clientæ‰§è¡Œè¯·æ±‚
	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// 4. ç®€å•æ ¡éªŒçŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		respBody, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendToOnePeer: status=%d, target=%s, resp=%s",
			resp.StatusCode, t.Target, string(respBody))
	}

	logs.Trace("[Gossip] success to %s, messageLen=%d", t.Target, len(msgBytes))
	return nil
}


æ–‡ä»¶è·¯å¾„: sender/http3_client.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// åˆ›å»ºéå•ä¾‹çš„ HTTP/3 å®¢æˆ·ç«¯
func createHttp3Client() *http.Client {
	tlsCfg := &tls.Config{
		InsecureSkipVerify: true,
		MinVersion:         tls.VersionTLS13,
		MaxVersion:         tls.VersionTLS13,
		ClientSessionCache: tls.NewLRUClientSessionCache(128),
		// æ·»åŠ ALPNåè®®æ”¯æŒ
		NextProtos: []string{"h3", "h3-29", "h3-28", "h3-27"},
	}

	tr := &http3.Transport{
		TLSClientConfig: tlsCfg,
		QUICConfig: &quic.Config{
			KeepAlivePeriod: 10 * time.Second,
			MaxIdleTimeout:  5 * time.Minute,
			// å¯é€‰ï¼šæ·»åŠ 0-RTTæ”¯æŒ
			Allow0RTT: true,
		},
	}

	return &http.Client{
		Transport: tr,
		Timeout:   30 * time.Second,
	}
}


æ–‡ä»¶è·¯å¾„: sender/manager.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// SenderManager ç®¡ç†æ‰€æœ‰å‘é€æ“ä½œåŠå…¶ä¾èµ–
type SenderManager struct {
	dbManager  *db.Manager
	txPool     *txpool.TxPool
	address    string     // æœ¬èŠ‚ç‚¹åœ°å€
	SendQueue  *SendQueue // æŒæœ‰SendQueueå®ä¾‹
	httpClient *http.Client
	nodeID     int // åªç”¨ä½œlog,ä¸å‚ä¸ä¸šåŠ¡é€»è¾‘
}

// ç”¨äºé€šè¿‡IDæ‹‰å–åŒºå—
type pullBlockByIDMessage struct {
	requestData []byte
	blockID     string
	onSuccess   func(*pb.Block)
}
type pullTxMessage struct {
	requestData []byte
	onSuccess   func(*pb.AnyTx)
	txPool      *txpool.TxPool
}

// åˆ›å»ºæ–°çš„å‘é€ç®¡ç†å™¨
func NewSenderManager(dbMgr *db.Manager, address string, pool *txpool.TxPool, nodeID int) *SenderManager {
	// åˆ›å»º HTTP/3 å®¢æˆ·ç«¯
	httpClient := createHttp3Client()
	cfg := config.DefaultConfig()
	// åˆ›å»ºSendQueueå®ä¾‹ï¼Œä¼ å…¥ httpClient
	queue := NewSendQueue(cfg.Sender.WorkerCount, cfg.Sender.QueueCapacity, httpClient, nodeID)

	return &SenderManager{
		dbManager:  dbMgr,
		txPool:     pool,
		address:    address,
		SendQueue:  queue,
		httpClient: httpClient,
	}
}

// BroadcastTx å¹¿æ’­äº¤æ˜“
func (sm *SenderManager) BroadcastTx(tx *pb.AnyTx) {
	data, err := proto.Marshal(tx)
	if err != nil {
		logs.Verbose("BroadcastTx: proto marshal failed: %v", err)
		return
	}

	peers, err := sm.getRandomMiners(3)
	if err != nil {
		logs.Error("BroadcastTx: failed to get miners: %v", err)
		return
	}

	for _, account := range peers {
		task := &SendTask{
			Target:     account.Ip,
			Message:    data,
			RetryCount: 0,
			MaxRetries: 1,
			SendFunc:   doSendTx,
			Priority:   PriorityData, // æ•°æ®é¢ä¼˜å…ˆçº§
		}
		sm.SendQueue.Enqueue(task) // ä½¿ç”¨å®ä¾‹çš„é˜Ÿåˆ—
	}
}

// SendTxToAllPeers å‘é€äº¤æ˜“ç»™æ‰€æœ‰èŠ‚ç‚¹
func (sm *SenderManager) SendTxToAllPeers(tx *pb.AnyTx) {
	data, err := proto.Marshal(tx)
	if err != nil {
		logs.Error("SendTxToAllPeers: marshal failed: %v", err)
		return
	}

	accounts, err := sm.getRandomMiners(20)
	if err != nil {
		logs.Error("SendTxToAllPeers: failed to get miners: %v", err)
		return
	}

	for _, acc := range accounts {
		task := &SendTask{
			Target:     acc.Ip,
			Message:    data,
			RetryCount: 0,
			MaxRetries: 3,
			SendFunc:   doSendTx,
		}
		sm.SendQueue.Enqueue(task)
	}
}

// æ‹‰å–æŒ‡å®šäº¤æ˜“
func (sm *SenderManager) PullTx(peerAddr, txID string, onSuccess func(*pb.AnyTx)) {
	getDataMsg := &pb.GetData{TxId: txID}
	data, err := proto.Marshal(getDataMsg)
	if err != nil {
		logs.Debug("[PullTx] marshal failed: %v", err)
		return
	}

	ip, err := sm.addressToIp(peerAddr)
	if err != nil {
		logs.Debug("[PullTx] get address failed: %v", err)
		return
	}

	msg := &pullTxMessage{
		requestData: data,
		onSuccess:   onSuccess,
		txPool:      sm.txPool,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 3,
		SendFunc:   doSendGetDataWithManager,
	}
	sm.SendQueue.Enqueue(task)
}

// é€šè¿‡BlockIDæ‹‰å–æŒ‡å®šåŒºå—
func (sm *SenderManager) PullGet(targetIP string, blockID string, onSuccess func(*pb.Block)) {
	// æ„é€ GetDataè¯·æ±‚æ¶ˆæ¯
	req := &pb.GetBlockByIDRequest{BlockId: blockID}

	data, err := proto.Marshal(req)
	if err != nil {
		logs.Debug("[PullGet] marshal failed: %v", err)
		return
	}

	// åˆ›å»ºä¸“é—¨çš„pullBlockByIDæ¶ˆæ¯
	msg := &pullBlockByIDMessage{
		requestData: data,
		blockID:     blockID,
		onSuccess:   onSuccess,
	}

	task := &SendTask{
		Target:     targetIP,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 2,
		SendFunc:   doSendGetBlockByID,
		Priority:   PriorityControl,
	}
	sm.SendQueue.Enqueue(task)
}

// æ‹‰å–æŒ‡å®šé«˜åº¦çš„åŒºå—
func (sm *SenderManager) PullBlock(targetAddress string, height uint64, onSuccess func(*pb.Block)) {
	account, err := sm.dbManager.GetAccount(targetAddress)
	if err != nil || account == nil {
		logs.Debug("[PullBlock] account not found for address %s", targetAddress)
		return
	}

	if account.Ip == "" {
		logs.Debug("[PullBlock] IP is empty for address %s", targetAddress)
		return
	}

	req := &pb.GetBlockRequest{Height: height}
	data, err := proto.Marshal(req)
	if err != nil {
		logs.Debug("[PullBlock] marshal GetBlockRequest error: %v", err)
		return
	}

	msg := &pullBlockMessage{
		requestData: data,
		onSuccess:   onSuccess,
	}

	task := &SendTask{
		Target:     account.Ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 1,
		SendFunc:   doSendGetBlock,
	}
	sm.SendQueue.Enqueue(task)
}

// æ‰¹é‡è·å–äº¤æ˜“
func (sm *SenderManager) BatchGetTxs(peerAddress string, shortHashes map[string]bool, onSuccess func([]*pb.AnyTx)) {
	var result [][]byte
	for hexStr := range shortHashes {
		bytes, err := hex.DecodeString(hexStr)
		if err != nil {
			continue
		}
		result = append(result, bytes)
	}

	reqMsg := &pb.BatchGetShortTxRequest{
		ShortHashes: result,
	}
	data, err := proto.Marshal(reqMsg)
	if err != nil {
		fmt.Printf("failed to marshal BatchGetDataRequest: %v\n", err)
		return
	}

	ip, err := sm.addressToIp(peerAddress)
	if err != nil {
		fmt.Printf("failed to get IP for peerAddress %s: %v\n", peerAddress, err)
		return
	}

	msg := &pullBatchTxMessage{
		requestData: data,
		onSuccess:   onSuccess,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 1,
		SendFunc:   doSendBatchGetTxs,
	}
	sm.SendQueue.Enqueue(task)
}

// å¹¿æ’­æ¶ˆæ¯ç»™éšæœºçŸ¿å·¥
func (sm *SenderManager) BroadcastGossipToTarget(targetAddr string, payload *types.GossipPayload) error {
	// åºåˆ—åŒ–æ•´ä¸ª payload
	data, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("failed to marshal gossip payload: %w", err)
	}
	if targetAddr == "" {
		return nil
	}
	task := &SendTask{
		Target:     targetAddr,
		Message:    data,
		RetryCount: 0,
		MaxRetries: 3,
		SendFunc:   doSendToOnePeer,
	}
	sm.SendQueue.Enqueue(task)
	return nil
}

// å‘é€PushQueryï¼ˆSnowmanå…±è¯†ï¼‰
func (sm *SenderManager) PushQuery(peerAddr string, pq *pb.PushQuery) {
	// ç¡®ä¿ PushQuery åŒ…å«å‘é€æ–¹åœ°å€
	pq.Address = sm.address // ä½¿ç”¨èŠ‚ç‚¹è‡ªå·±çš„åœ°å€
	data, err := proto.Marshal(pq)
	if err != nil {
		logs.Debug("[PushQuery] marshal fail: %v", err)
		return
	}

	ip, err := sm.addressToIp(peerAddr)
	if err != nil || ip == "" {
		logs.Debug("[PushQuery] resolve ip err: %v", err)
		return
	}

	msg := &pushQueryMsg{requestData: data}
	task := &SendTask{
		Target:     ip,
		Message:    msg,
		MaxRetries: 2,
		SendFunc:   doSendPushQuery,
		Priority:   PriorityControl, // è®¾ç½®ä¸ºæ§åˆ¶é¢ä¼˜å…ˆçº§
	}
	sm.SendQueue.Enqueue(task)
}

// PullQuery å‘é€PullQueryï¼ˆSnowmanå…±è¯†ï¼‰
func (sm *SenderManager) PullQuery(peerAddr string, pq *pb.PullQuery) {
	data, err := proto.Marshal(pq)
	if err != nil {
		logs.Debug("[PullQuery] marshal fail: %v", err)
		return
	}

	ip, err := sm.addressToIp(peerAddr)
	if err != nil || ip == "" {
		logs.Debug("[PullQuery] resolve ip err: %v", err)
		return
	}

	msg := &pullQueryMsg{requestData: data}
	task := &SendTask{
		Target:     ip,
		Message:    msg,
		MaxRetries: 2,
		SendFunc:   doSendPullQuery,
		Priority:   PriorityControl, // æ§åˆ¶é¢ä¼˜å…ˆçº§
	}
	sm.SendQueue.Enqueue(task)
}

// è¾…åŠ©æ–¹æ³•

// getRandomMiners è·å–éšæœºçŸ¿å·¥åˆ—è¡¨
func (sm *SenderManager) getRandomMiners(count int) ([]*pb.Account, error) {
	// ä½¿ç”¨æ³¨å…¥çš„dbManagerï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°çš„
	return sm.dbManager.GetRandomMinersFast(count)
}

// å°†åœ°å€è½¬æ¢ä¸ºIPï¼ˆç¡®ä¿åŒ…å«ç«¯å£ï¼‰
func (sm *SenderManager) addressToIp(peerAddr string) (string, error) {
	// æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯IP:Portæ ¼å¼
	if host, _, err := net.SplitHostPort(peerAddr); err == nil {
		if parsedIP := net.ParseIP(host); parsedIP != nil {
			return peerAddr, nil // å·²ç»æ˜¯IP:Portæ ¼å¼
		}
	}

	// æ£€æŸ¥æ˜¯å¦æ˜¯çº¯IPï¼ˆéœ€è¦æŸ¥è¯¢é»˜è®¤ç«¯å£ï¼‰
	if parsedIP := net.ParseIP(peerAddr); parsedIP != nil {
		// è¿™æ˜¯çº¯IPï¼Œéœ€è¦ä»æ•°æ®åº“æŸ¥è¯¢ç«¯å£æˆ–ä½¿ç”¨é»˜è®¤ç«¯å£
		return peerAddr, nil
	}

	// ä»æ•°æ®åº“æŸ¥è¯¢åœ°å€å¯¹åº”çš„IPï¼ˆåº”è¯¥åŒ…å«ç«¯å£ï¼‰
	account, err := sm.dbManager.GetAccount(peerAddr)
	if err != nil {
		return "", fmt.Errorf("failed to get account for address %s: %v", peerAddr, err)
	}

	if account == nil || account.Ip == "" {
		return "", fmt.Errorf("no IP configured for address %s", peerAddr)
	}

	// account.Ip åº”è¯¥å·²åŒ…å«ç«¯å£ï¼Œå¦‚ "127.0.0.1:6000"
	return account.Ip, nil
}

// æ–°çš„å‘é€å‡½æ•°ï¼Œä½¿ç”¨txPoolå¼•ç”¨
func doSendGetDataWithManager(t *SendTask, client *http.Client) error {
	pm, ok := t.Message.(*pullTxMessage)
	if !ok {
		return fmt.Errorf("doSendGetData: t.Message is not *pullTxMessage")
	}

	url := fmt.Sprintf("https://%s/getdata", t.Target)
	req, err := http.NewRequest("POST", url, bytes.NewReader(pm.requestData))
	if err != nil {
		return err
	}
	req.Header.Set("Content-Type", "application/x-protobuf")

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		respData, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("doSendGetData: status=%d, body=%s", resp.StatusCode, string(respData))
	}

	respBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	var anyTx pb.AnyTx
	if err := proto.Unmarshal(respBytes, &anyTx); err != nil {
		return fmt.Errorf("doSendGetData: unmarshal AnyTx fail: %v", err)
	}

	// ä½¿ç”¨ä¼ é€’çš„txPoolå¼•ç”¨
	if pm.txPool != nil {
		txId := anyTx.GetTxId()
		if txId != "" {
			if err := pm.txPool.StoreAnyTx(&anyTx); err != nil {
				logs.Debug("[doSendGetData] storeAnyTx fail: %v", err)
			}
		}
	}

	if pm.onSuccess != nil {
		pm.onSuccess(&anyTx)
	}

	return nil
}

// å‘é€Chitsæ¶ˆæ¯ï¼ˆSnowmanå…±è¯†å“åº”ï¼‰
func (sm *SenderManager) SendChits(targetAddress string, chits *pb.Chits) error {
	chits.Address = sm.address // æ·»åŠ å‘é€æ–¹åœ°å€
	data, err := proto.Marshal(chits)
	if err != nil {
		logs.Debug("[SendChits] marshal failed: %v", err)
		return err
	}

	ip, err := sm.addressToIp(targetAddress)
	if err != nil {
		logs.Debug("[SendChits] failed to get IP for address %s: %v", targetAddress, err)
		return err
	}

	msg := &chitsMessage{
		requestData: data,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 2,
		SendFunc:   doSendChits,
	}
	sm.SendQueue.Enqueue(task)
	return nil
}

// å‘é€å®Œæ•´åŒºå—æ•°æ®
func (sm *SenderManager) SendBlock(targetAddress string, block *pb.Block) error {
	data, err := proto.Marshal(block)
	if err != nil {
		logs.Debug("[SendBlock] marshal failed: %v", err)
		return err
	}

	ip, err := sm.addressToIp(targetAddress)
	if err != nil {
		logs.Debug("[SendBlock] failed to get IP for address %s: %v", targetAddress, err)
		return err
	}

	msg := &blockMessage{
		requestData: data,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 2,
		SendFunc:   doSendBlock,
	}
	sm.SendQueue.Enqueue(task)
	return nil
}

// SendHeightQuery å‘é€é«˜åº¦æŸ¥è¯¢è¯·æ±‚
func (sm *SenderManager) SendHeightQuery(targetAddress string, onSuccess func(*pb.HeightResponse)) error {
	// æ„é€ ç©ºçš„é«˜åº¦æŸ¥è¯¢è¯·æ±‚
	req := &pb.StatusRequest{} // ä½¿ç”¨StatusRequestæˆ–åˆ›å»ºä¸“é—¨çš„HeightQueryRequest
	data, err := proto.Marshal(req)
	if err != nil {
		logs.Debug("[SendHeightQuery] marshal failed: %v", err)
		return err
	}

	ip, err := sm.addressToIp(targetAddress)
	if err != nil {
		logs.Debug("[SendHeightQuery] failed to get IP for address %s: %v", targetAddress, err)
		return err
	}

	msg := &heightQueryMessage{
		requestData: data,
		onSuccess:   onSuccess,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 2,
		SendFunc:   doSendHeightQuery,
	}
	sm.SendQueue.Enqueue(task)
	return nil
}

// SendSyncRequest å‘é€åŒæ­¥è¯·æ±‚
func (sm *SenderManager) SendSyncRequest(targetAddress string, fromHeight, toHeight uint64, onSuccess func([]*pb.Block)) error {
	req := &pb.GetBlockRequest{
		Height: fromHeight, // å¯ä»¥æ‰©å±•ä¸ºæ”¯æŒèŒƒå›´æŸ¥è¯¢
	}
	data, err := proto.Marshal(req)
	if err != nil {
		logs.Debug("[SendSyncRequest] marshal failed: %v", err)
		return err
	}

	ip, err := sm.addressToIp(targetAddress)
	if err != nil {
		logs.Debug("[SendSyncRequest] failed to get IP for address %s: %v", targetAddress, err)
		return err
	}

	msg := &syncRequestMessage{
		requestData: data,
		fromHeight:  fromHeight,
		toHeight:    toHeight,
		onSuccess:   onSuccess,
	}

	task := &SendTask{
		Target:     ip,
		Message:    msg,
		RetryCount: 0,
		MaxRetries: 2,
		SendFunc:   doSendSyncRequest,
	}
	sm.SendQueue.Enqueue(task)
	return nil
}

// Stop åœæ­¢SenderManagerï¼ˆåŒ…æ‹¬å…¶é˜Ÿåˆ—ï¼‰
func (sm *SenderManager) Stop() {
	if sm.SendQueue != nil {
		sm.SendQueue.Stop()
	}
}


æ–‡ä»¶è·¯å¾„: sender/queue.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

// æ·»åŠ ä»»åŠ¡ç±»å‹æšä¸¾
type TaskPriority int

const (
	PriorityControl TaskPriority = iota // æ§åˆ¶é¢ï¼šconsensusç›¸å…³
	PriorityData                        // æ•°æ®é¢ï¼šæ™®é€šæ•°æ®ä¼ è¾“
)

// SendTask å°è£…ä¸€æ¬¡å‘é€æ‰€éœ€çš„ä¿¡æ¯
type SendTask struct {
	Target      string
	Message     interface{}
	RetryCount  int
	MaxRetries  int
	NextAttempt time.Time
	SendFunc    func(task *SendTask, client *http.Client) error
	HttpClient  *http.Client
	Priority    TaskPriority // ä»»åŠ¡ä¼˜å…ˆçº§

}

// SendQueue è´Ÿè´£ç®¡ç†ä»»åŠ¡é˜Ÿåˆ— + worker
type SendQueue struct {
	workerCount   int
	TaskChan      chan *SendTask
	stopChan      chan struct{}
	wg            sync.WaitGroup
	httpClient    *http.Client
	nodeID        int              // åªç”¨ä½œlog,ä¸å‚ä¸ä¸šåŠ¡é€»è¾‘
	InflightMap   map[string]int32 // ç›®æ ‡->åœ¨é€”è¯·æ±‚æ•°
	InflightMutex sync.RWMutex
}

// ç§»é™¤ GlobalQueue å’Œ InitQueue

// åˆ›å»ºæ–°çš„å‘é€é˜Ÿåˆ—
func NewSendQueue(workerCount, queueCapacity int, httpClient *http.Client, nodeID int) *SendQueue {
	sq := &SendQueue{
		nodeID:      nodeID,
		workerCount: workerCount,
		TaskChan:    make(chan *SendTask, queueCapacity),
		stopChan:    make(chan struct{}),
		httpClient:  httpClient,
		InflightMap: make(map[string]int32),
	}
	sq.Start()
	return sq
}

// Start å¯åŠ¨ workerCount ä¸ªåç¨‹
func (sq *SendQueue) Start() {
	sq.wg.Add(sq.workerCount)
	for i := 0; i < sq.workerCount; i++ {
		go sq.workerLoop(i)
	}
	logs.Verbose("[SendQueue] Started with %d workers", sq.workerCount)
}

// Stop åœæ­¢é˜Ÿåˆ—, ç­‰å¾…æ‰€æœ‰workeré€€å‡º
func (sq *SendQueue) Stop() {
	close(sq.stopChan)
	sq.wg.Wait()
	log.Println("[SendQueue] Stopped.")
}

func (sq *SendQueue) Enqueue(task *SendTask) {
	if task == nil {
		return
	}
	if task.NextAttempt.IsZero() {
		task.NextAttempt = time.Now()
	}
	now := time.Now()
	if task.NextAttempt.After(now) {
		// æœªåˆ°æ‰§è¡Œæ—¶é—´ï¼šå…ˆç­‰åˆ° NextAttemptï¼Œå†çœŸæ­£å…¥é˜Ÿ
		delay := time.Until(task.NextAttempt)
		go func(t *SendTask, d time.Duration) {
			timer := time.NewTimer(d)
			defer timer.Stop()
			select {
			case <-timer.C:
				sq.enqueueNow(t) // è§ä¸‹
			case <-sq.stopChan: // è‹¥ä½ æœ‰ stopChan
				return
			}
		}(task, delay)
		return
	}
	sq.enqueueNow(task)
}

func (sq *SendQueue) enqueueNow(task *SendTask) {
	cfg := config.DefaultConfig()
	// æ§åˆ¶é¢ä»»åŠ¡ï¼šç»™ä¸€ä¸ªçŸ­æš‚çš„é˜»å¡çª—å£
	if task.Priority == PriorityControl {
		select {
		case sq.TaskChan <- task:
			// æˆåŠŸå…¥é˜Ÿ
			return
		case <-time.After(cfg.Sender.ControlTaskTimeout):

			// 80ms åä»æ— æ³•å…¥é˜Ÿï¼Œè®°å½•é”™è¯¯
			logs.Error("[Node %d][SendQueue] Control task timeout: len=%d cap=%d target=%s",
				sq.nodeID, len(sq.TaskChan), cap(sq.TaskChan), task.Target)
			// å¯ä»¥é€‰æ‹©ä¸¢å¼ƒæˆ–è€…è¿›ä¸€æ­¥å¤„ç†
			return
		}
	}

	// æ•°æ®é¢ä»»åŠ¡ï¼šé˜Ÿåˆ—æ»¡äº†ç›´æ¥ä¸¢å¼ƒ
	select {
	case sq.TaskChan <- task:
		// æˆåŠŸå…¥é˜Ÿ
	default:
		logs.Debug("[Node %d][SendQueue] Data task dropped: queue full, target=%s",
			sq.nodeID, task.Target)
	}
}

// workerLoop é€ä¸ªè·å–é˜Ÿåˆ—ä»»åŠ¡å¹¶æ‰§è¡Œ
func (sq *SendQueue) workerLoop(workerID int) {
	defer sq.wg.Done()

	for {
		select {
		case <-sq.stopChan:
			return
		case task := <-sq.TaskChan:
			if task == nil {
				return
			}
			now := time.Now()
			if task.NextAttempt.After(now) {
				sleepDur := task.NextAttempt.Sub(now)
				time.Sleep(sleepDur)
			}
			// åœ¨ err := sq.doSend(task, workerID) ä¹‹å‰æ·»åŠ 
			sq.InflightMutex.Lock()
			sq.InflightMap[task.Target]++
			sq.InflightMutex.Unlock()

			err := sq.doSend(task, workerID)
			// åœ¨ err := sq.doSend(task, workerID) ä¹‹åæ·»åŠ 
			sq.InflightMutex.Lock()
			sq.InflightMap[task.Target]--
			if sq.InflightMap[task.Target] <= 0 {
				delete(sq.InflightMap, task.Target)
			}
			sq.InflightMutex.Unlock()
			if err != nil {
				sq.handleRetry(task, err)
			}
		}
	}
}

func (sq *SendQueue) doSend(task *SendTask, workerID int) error {
	if task.SendFunc == nil {
		return fmt.Errorf("SendFunc is nil, cannot send")
	}
	// è®¾ç½®ä»»åŠ¡çš„ HTTP å®¢æˆ·ç«¯
	task.HttpClient = sq.httpClient

	start := time.Now()
	err := task.SendFunc(task, sq.httpClient)
	elapsed := time.Since(start)

	if err != nil {
		logs.Error("[SendQueue] worker=%d,%s send to %s FAILED after %v: %v",
			workerID, task.FuncName(), task.Target, elapsed, err)
	} else {
		logs.Trace("[SendQueue] worker=%d,%s send to %s success in %v",
			workerID, task.FuncName(), task.Target, elapsed)
	}
	return err
}

func (sq *SendQueue) handleRetry(task *SendTask, sendErr error) {
	task.RetryCount++
	if task.RetryCount > task.MaxRetries {
		logs.Debug("[SendQueue] Exceed max retries(%d) target=%s, giving up",
			task.MaxRetries, task.Target)
		return
	}
	cfg := config.DefaultConfig()
	// å¹‚æ¬¡é€€é¿
	baseDelay := cfg.Sender.BaseRetryDelay
	backoff := baseDelay * time.Duration(math.Pow(2, float64(task.RetryCount-1)))
	task.NextAttempt = time.Now().Add(backoff)
	sq.Enqueue(task)
	logs.Debug("[SendQueue] Retry %d/%d after %v for %s (err=%v)",
		task.RetryCount, task.MaxRetries, backoff, task.Target, sendErr)
}
func (task *SendTask) FuncName() string {
	if task.SendFunc == nil {
		return ""
	}
	// é€šè¿‡åå°„æ‹¿åˆ°å‡½æ•°æŒ‡é’ˆï¼Œç„¶åç”¨ runtime.FuncForPC è·å¾—å‡½æ•°ä¿¡æ¯
	funcPtr := reflect.ValueOf(task.SendFunc).Pointer()
	f := runtime.FuncForPC(funcPtr)
	if f != nil {
		return f.Name()
	} else {
		return ""
	}
}


æ–‡ä»¶è·¯å¾„: sender/validate.go
æ–‡ä»¶å†…å®¹:
package sender

import (...)

func test() {
	// å‡è®¾è¿™æ˜¯è¯ä¹¦çš„ PEM æ ¼å¼
	certPEM := `
-----BEGIN CERTIFICATE-----
MIIBqzCCAVGgAwIBAgIIGA+Dizzc51AwCgYIKoZIzj0EAwIwNTEzMDEGA1UEChMq
YmMxcXg1cDI4YXh4YWd3ZG5xOGUzZ3lqanNscmt2NnMzNGxzMmdycmhsMB4XDTI0
MTIwOTEyNTY1NVoXDTI1MTIwOTEyNTY1NVowNTEzMDEGA1UEChMqYmMxcXg1cDI4
YXh4YWd3ZG5xOGUzZ3lqanNscmt2NnMzNGxzMmdycmhsMFkwEwYHKoZIzj0CAQYI
KoZIzj0DAQcDQgAEfknoCSZdayWjt3okKDDNRuwEkoDI3ck/jrpt/1eBh/mQvgfv
Y4H98yS9UJJ2qyjwRv4mf/eCjynaVqCc3uX9uKNLMEkwDgYDVR0PAQH/BAQDAgWg
MBMGA1UdJQQMMAoGCCsGAQUFBwMBMAwGA1UdEwEB/wQCMAAwFAYDVR0RBA0wC4IJ
bG9jYWxob3N0MAoGCCqGSM49BAMCA0gAMEUCIBj8lF97FBjYg1LHRyYzlNA705ME
K/OVNewOFXgmcXmtAiEA5/VJ3qy+5J2+oyZXU27WRTy5iM1Eantv6pTJ2KLL9cw=
-----END CERTIFICATE-----
`

	// è§£æè¯ä¹¦
	block, _ := pem.Decode([]byte(certPEM))
	if block == nil {
		logs.Error("Failed to decode PEM block")
	}

	cert, err := x509.ParseCertificate(block.Bytes)
	if err != nil {
		logs.Error("Failed to parse certificate: %v", err)
	}

	// è·å–ç»„ç»‡å­—æ®µä¸­çš„æ¯”ç‰¹å¸åœ°å€
	if len(cert.Subject.Organization) == 0 {
		logs.Error("Certificate has no organization field")
	}
	btcAddress := cert.Subject.Organization[0]

	// æ£€æŸ¥åœ°å€æ˜¯å¦åˆæ³•
	address, err := btcutil.DecodeAddress(btcAddress, &chaincfg.MainNetParams)
	if err != nil {
		logs.Error("Invalid Bitcoin address: %v", err)
	}

	// ä»è¯ä¹¦ä¸­è·å–å…¬é’¥
	pubKey, ok := cert.PublicKey.(*ecdsa.PublicKey)
	if !ok {
		logs.Error("Public key is not of type ECDSA")
	}

	// åˆ›å»ºæ¯”ç‰¹å¸åœ°å€
	generatedAddress, err := crt.GenerateBitcoinAddress(pubKey)
	if err != nil {
		logs.Error("Failed to create Bitcoin address from public key: %v", err)
	}

	// æ¯”è¾ƒåœ°å€æ˜¯å¦åŒ¹é…
	if address.String() == generatedAddress {
		fmt.Println("Address matches the public key!")
	} else {
		logs.Warn("Address does not match the public key! %s\n", generatedAddress)
	}
}


æ–‡ä»¶è·¯å¾„: stats/stats.go
æ–‡ä»¶å†…å®¹:
package stats

import (...)

type Stats struct {
	statsLock     sync.RWMutex
	apiCallCounts map[string]uint64
}

func NewStats() *Stats {
	return &Stats{
		apiCallCounts: make(map[string]uint64),
	}
}

// è®°å½•APIè°ƒç”¨
func (h *Stats) RecordAPICall(apiName string) {
	h.statsLock.Lock()
	defer h.statsLock.Unlock()

	if h.apiCallCounts == nil {
		h.apiCallCounts = make(map[string]uint64)
	}
	h.apiCallCounts[apiName]++
}

// è·å–APIè°ƒç”¨ç»Ÿè®¡
func (h *Stats) GetAPICallStats() map[string]uint64 {
	h.statsLock.RLock()
	defer h.statsLock.RUnlock()

	// å¤åˆ¶ç»Ÿè®¡æ•°æ®
	stats := make(map[string]uint64)
	for api, count := range h.apiCallCounts {
		stats[api] = count
	}
	return stats
}


æ–‡ä»¶è·¯å¾„: txpool/txpool.go
æ–‡ä»¶å†…å®¹:
package txpool

import (...)

// TxPool äº¤æ˜“æ± ç»“æ„ä½“
type TxPool struct {
	dbManager *db.Manager
	network   *network.Network

	// ç¼“å­˜
	mu                     sync.RWMutex
	pendingAnyTxCache      *lru.Cache
	shortPendingAnyTxCache *lru.Cache
	cacheTx                *lru.Cache
	shortTxCache           *lru.Cache

	// å†…éƒ¨é˜Ÿåˆ—ç®¡ç†
	Queue     *txPoolQueue
	validator TxValidator

	// æ§åˆ¶
	stopChan chan struct{}
	wg       sync.WaitGroup
}

// NewTxPool åˆ›å»ºæ–°çš„TxPoolå®ä¾‹ï¼ˆæ›¿ä»£GetInstanceï¼‰
func NewTxPool(dbManager *db.Manager, validator TxValidator) (*TxPool, error) {
	cfg := config.DefaultConfig()
	pendingAnyTxCache, err := lru.New(cfg.TxPool.PendingTxCacheSize)
	if err != nil {
		return nil, err
	}
	shortPendingAnyTxCache, _ := lru.New(cfg.TxPool.ShortPendingTxCacheSize)
	cacheTx, _ := lru.New(cfg.TxPool.CacheTxSize)
	shortTxCache, _ := lru.New(cfg.TxPool.ShortTxCacheSize)

	net := network.NewNetwork(dbManager)

	tp := &TxPool{
		dbManager:              dbManager,
		network:                net,
		pendingAnyTxCache:      pendingAnyTxCache,
		shortPendingAnyTxCache: shortPendingAnyTxCache,
		cacheTx:                cacheTx,
		shortTxCache:           shortTxCache,
		validator:              validator,
		stopChan:               make(chan struct{}),
	}

	// åˆ›å»ºå†…éƒ¨é˜Ÿåˆ—
	tp.Queue = newTxPoolQueue(tp, validator)

	// ä»DBåŠ è½½å·²æœ‰pendingTx
	tp.loadFromDB()

	return tp, nil
}

// Start å¯åŠ¨äº¤æ˜“æ± 
func (tp *TxPool) Start() error {
	// å¯åŠ¨å†…éƒ¨é˜Ÿåˆ—å¤„ç†
	tp.wg.Add(1)
	go tp.Queue.runLoop()

	logs.Info("[TxPool] Started")
	return nil
}

// Stop åœæ­¢äº¤æ˜“æ± 
func (tp *TxPool) Stop() error {
	close(tp.stopChan)
	tp.wg.Wait()
	logs.Info("[TxPool] Stopped")
	return nil
}

// æäº¤äº¤æ˜“ï¼ˆå¯¹å¤–çš„ä¸»è¦æ¥å£ï¼‰
func (tp *TxPool) SubmitTx(anyTx *pb.AnyTx, fromIP string, onAdded OnTxAddedCallback) error {
	if anyTx == nil {
		return fmt.Errorf("nil transaction")
	}

	msg := &txPoolMessage{
		Type:    msgAddTx,
		AnyTx:   anyTx,
		IP:      fromIP,
		OnAdded: onAdded,
	}

	select {
	case tp.Queue.MsgChan <- msg:
		return nil
	default:
		return fmt.Errorf("txpool queue is full")
	}
}

// RemoveTx ç§»é™¤äº¤æ˜“
func (tp *TxPool) RemoveTx(txID string) error {
	if txID == "" {
		return fmt.Errorf("empty txID")
	}

	tp.mu.Lock()
	defer tp.mu.Unlock()

	tp.pendingAnyTxCache.Remove(txID)
	tp.shortPendingAnyTxCache.Remove(txID[2:18])

	// åŒæ—¶ä»DBåˆ é™¤
	return tp.dbManager.DeletePendingAnyTx(txID)
}

// å…¶ä»–å…¬å¼€æ–¹æ³•ä¿æŒä¸å˜...
func (tp *TxPool) HasTransaction(txID string) bool {
	tp.mu.RLock()
	defer tp.mu.RUnlock()
	_, exists := tp.pendingAnyTxCache.Get(txID)
	return exists
}

func (tp *TxPool) GetTransactionById(txID string) *pb.AnyTx {
	tp.mu.RLock()
	defer tp.mu.RUnlock()
	if v, ok := tp.pendingAnyTxCache.Get(txID); ok {
		if tx, ok := v.(*pb.AnyTx); ok {
			return tx
		}
	}
	return nil
}

func (tp *TxPool) GetPendingTxs() []*pb.AnyTx {
	tp.mu.RLock()
	defer tp.mu.RUnlock()

	var result []*pb.AnyTx
	keys := tp.pendingAnyTxCache.Keys()
	for _, k := range keys {
		keyStr, ok := k.(string)
		if !ok {
			continue
		}
		if value, exists := tp.pendingAnyTxCache.Get(keyStr); exists {
			if anyTx, ok := value.(*pb.AnyTx); ok {
				base := anyTx.GetBase()
				if base != nil {
					result = append(result, anyTx)
				}
			}
		}
	}
	return result
}

// å†…éƒ¨æ–¹æ³•
func (tp *TxPool) storeAnyTx(anyTx *pb.AnyTx) error {
	txID := anyTx.GetTxId()
	if txID == "" {
		return fmt.Errorf("txID is empty")
	}

	tp.mu.Lock()
	defer tp.mu.Unlock()

	// å¦‚æœæ± é‡Œå·²ç»æœ‰äº†å°±è·³è¿‡
	if _, exists := tp.pendingAnyTxCache.Get(txID); exists {
		return nil
	}

	// åŠ å…¥å†…å­˜ç¼“å­˜
	tp.pendingAnyTxCache.Add(txID, anyTx)
	tp.cacheTx.Add(txID, anyTx)
	tp.shortPendingAnyTxCache.Add(txID[2:18], txID)
	tp.shortTxCache.Add(txID[2:18], txID)

	// ä¿å­˜åˆ°DB
	if err := tp.dbManager.SavePendingAnyTx(anyTx); err != nil {
		return err
	}
	return nil
}

// loadFromDB ä»æ•°æ®åº“åŠ è½½"pending_tx_"è®°å½•åˆ°å†…å­˜
func (p *TxPool) loadFromDB() {
	pendingAnyTxs, err := p.dbManager.LoadPendingAnyTx()
	if err != nil {
		logs.Verbose("[TxPool] Failed to load pending AnyTx from DB: %v", err)
		return
	}

	p.mu.Lock()
	defer p.mu.Unlock()
	for _, anyTx := range pendingAnyTxs {
		txID := ExtractAnyTxId(anyTx)
		if txID == "" {
			continue
		}
		p.pendingAnyTxCache.Add(txID, anyTx)
	}
	logs.Verbose("[TxPool] Loaded %d pending AnyTx from DB.\n", len(pendingAnyTxs))
}

func (p *TxPool) StoreAnyTx(anyTx *pb.AnyTx) error {
	txID := anyTx.GetTxId()
	if txID == "" {
		return fmt.Errorf("txID is empty")
	}

	p.mu.Lock()
	defer p.mu.Unlock()

	// å¦‚æœæ± é‡Œå·²ç»æœ‰äº†å°±è·³è¿‡
	if _, exists := p.pendingAnyTxCache.Get(txID); exists {
		return nil
	}
	// åŠ å…¥å†…å­˜ç¼“å­˜
	p.pendingAnyTxCache.Add(txID, anyTx)
	p.cacheTx.Add(txID, anyTx)
	p.shortPendingAnyTxCache.Add(txID[2:18], txID)
	p.shortTxCache.Add(txID[2:18], txID)
	//logs.Trace("[TxPool] Added TxId %s to shortPendingAnyTxCache.", txID[2:18])
	// â€”â€” ç›´æ¥è½DB
	if err := p.dbManager.SavePendingAnyTx(anyTx); err != nil {
		return err
	}
	return nil
}

func (p *TxPool) RemoveAnyTx(txID string) {
	p.mu.Lock()
	defer p.mu.Unlock()

	p.pendingAnyTxCache.Remove(txID)
	p.shortPendingAnyTxCache.Remove(txID[2:18])
	// â€”â€” ç›´æ¥åˆ DB
	_ = p.dbManager.DeletePendingAnyTx(txID)
}

// è¿”å›å†…å­˜é‡Œçš„ pendingTx
func (p *TxPool) GetPendingAnyTx() []*pb.AnyTx {

	p.mu.RLock()
	defer p.mu.RUnlock()

	var result []*pb.AnyTx
	// Step 1: è·å–æ‰€æœ‰ keyï¼Œå¹¶è½¬ä¸º []string
	rawKeys := p.pendingAnyTxCache.Keys()
	var keys []string
	for _, k := range rawKeys {
		if keyStr, ok := k.(string); ok {
			keys = append(keys, keyStr)
		}
	}

	// Step 2: æ’åº
	sort.Strings(keys)

	// Step 3: éå†å·²æ’åºçš„ key è·å–å€¼
	for _, k := range keys {
		if value, exists := p.pendingAnyTxCache.Get(k); exists {
			if anyTx, ok := value.(*pb.AnyTx); ok {
				result = append(result, anyTx)
			}
		}
	}
	return result
}

// GetPending65500Tx returns up to the first 65500 AnyTx from pendingAnyTxCache.
func (p *TxPool) GetPending65500Tx() []*pb.AnyTx {
	p.mu.RLock()
	defer p.mu.RUnlock()
	cfg := config.DefaultConfig()
	var result []*pb.AnyTx
	keys := p.pendingAnyTxCache.Keys()
	maxCount := cfg.TxPool.MaxPendingTxs
	count := 0

	for _, k := range keys {
		if count >= maxCount {
			break
		}
		keyStr, ok := k.(string)
		if !ok {
			continue
		}
		if value, exists := p.pendingAnyTxCache.Get(keyStr); exists {
			if anyTx, ok := value.(*pb.AnyTx); ok {
				result = append(result, anyTx)
				count++
			}
		}
	}
	return result
}

func (p *TxPool) ConcatFirst8Bytes(txs []*pb.AnyTx) []byte {
	start := time.Now()
	defer func() {
		elapsed := time.Since(start)
		logs.Info("[ConcatFirst8Bytes] elapsed=%s", elapsed)
	}()
	var result []byte
	for _, tx := range txs {
		txID := tx.GetTxId()
		idBytes, err := hex.DecodeString(txID[2:])
		if err != nil {
			log.Fatalf("invalid hex string: %v\n%s", err, debug.Stack())
		}
		// å¦‚æœäº¤æ˜“æ ‡è¯†çš„é•¿åº¦å°äº3ï¼Œåˆ™è·³è¿‡æˆ–æŒ‰éœ€æ±‚å¤„ç†
		if len(idBytes) < 3 {
			continue
		}
		// æˆªå–8ä¸ªå­—èŠ‚
		endIndex := 8
		if len(idBytes) < endIndex {
			endIndex = len(idBytes)
		}
		//logs.Trace("endIndex := 8 %x", idBytes[:endIndex])
		result = append(result, idBytes[:endIndex]...)
	}
	return result
}

// ExtractAnyTxId ---------------------------------------------------------------------------
//
//	ç”¨äºä» AnyTx æå– TxId
//
// ---------------------------------------------------------------------------
func ExtractAnyTxId(a *pb.AnyTx) string {
	switch content := a.GetContent().(type) {
	case *pb.AnyTx_IssueTokenTx:
		if content.IssueTokenTx.Base != nil {
			return content.IssueTokenTx.Base.TxId
		}
	case *pb.AnyTx_FreezeTx:
		if content.FreezeTx.Base != nil {
			return content.FreezeTx.Base.TxId
		}
	case *pb.AnyTx_Transaction:
		if content.Transaction.Base != nil {
			return content.Transaction.Base.TxId
		}
	case *pb.AnyTx_OrderTx:
		if content.OrderTx.Base != nil {
			return content.OrderTx.Base.TxId
		}
	case *pb.AnyTx_AddressTx:
		if content.AddressTx.Base != nil {
			return content.AddressTx.Base.TxId
		}
	case *pb.AnyTx_CandidateTx:
		if content.CandidateTx.Base != nil {
			return content.CandidateTx.Base.TxId
		}

	}
	return ""
}

// æ ¹æ®æ¯ç¬”Txçš„å‘èµ·æ–¹(FBä½™é¢)ç”±å¤§åˆ°å°æ’åºï¼Œ
// å¹¶å°†æ’åºååºåˆ—ç”Ÿæˆä¸€ä¸ªèšåˆå“ˆå¸Œ(txs_hash)ã€‚
// è¿”å›ï¼š (sortedTxs, txsHashHexString, error)
func SortTxsByFBBalanceAndComputeHash(dbMgr *db.Manager, txs []*pb.AnyTx) ([]*pb.AnyTx, string, error) {

	// 1. å‡†å¤‡ä¸€ä¸ªä¸´æ—¶ç»“æ„ï¼Œç”¨æ¥åŒæ—¶ä¿å­˜ Tx å’Œ å¯¹åº”FBä½™é¢
	type txWithBal struct {
		anyTx   *pb.AnyTx
		balance decimal.Decimal
	}

	tmpList := make([]txWithBal, 0, len(txs))

	for _, tx := range txs {
		base := tx.GetBase()
		if base == nil {
			// å¦‚æœè¯¥ç¬”Txæ²¡æœ‰BaseMessageï¼Œä¸æ»¡è¶³è¦æ±‚ï¼Œè·³è¿‡æˆ–åšé”™è¯¯å¤„ç†
			continue
		}
		fromAddr := base.FromAddress
		if fromAddr == "" {
			continue
		}
		// 2. ä»DBä¸­è·å–è¯¥ fromAddr çš„è´¦æˆ·å¹¶æ‹¿åˆ°å…¶"FB"çš„å¯ç”¨ä½™é¢
		acc, err := dbMgr.GetAccount(fromAddr)
		if err != nil {
			return nil, "", fmt.Errorf("get account %s error: %v", fromAddr, err)
		}
		var fbBalance decimal.Decimal
		if acc != nil {
			if tokenBal, ok := acc.Balances["FB"]; ok && tokenBal != nil {
				fbBalance, _ = decimal.NewFromString(tokenBal.Balance)
			}
		}
		tmpList = append(tmpList, txWithBal{
			anyTx:   tx,
			balance: fbBalance,
		})
	}

	// 3. æ’åºï¼šæŒ‰ FBä½™é¢ ä»å¤§åˆ°å° æ’åˆ—
	sort.Slice(tmpList, func(i, j int) bool {
		return tmpList[i].balance.Cmp(tmpList[j].balance) > 0 // i>j => descending
	})

	// 4. ç”Ÿæˆæ’åºåçš„ç»“æœåˆ‡ç‰‡
	sortedTxs := make([]*pb.AnyTx, len(tmpList))
	for i, v := range tmpList {
		sortedTxs[i] = v.anyTx
	}

	// 5. è®¡ç®—èšåˆå“ˆå¸Œ(txs_hash)
	var allBytes []byte
	for _, v := range tmpList {
		base := v.anyTx.GetBase()
		if base == nil {
			continue
		}
		fromAddr := base.FromAddress
		balStr := v.balance.String()
		segment := []byte(base.TxId + "|" + fromAddr + "|" + balStr + "||")
		allBytes = append(allBytes, segment...)
	}

	finalHash := utils.Sha256Hash(allBytes)
	txsHashHex := fmt.Sprintf("%x", finalHash)

	return sortedTxs, txsHashHex, nil
}
func (p *TxPool) GetTxsByShortHashes(shortHashes [][]byte, isSync bool) []*pb.AnyTx {
	//start := time.Now()
	//defer func() {
	//	elapsed := time.Since(start)
	//	logs.Info("[GetTxsByShortHashes] elapsed=%s", elapsed)
	//}()
	p.mu.RLock()
	defer p.mu.RUnlock()

	//logs.Trace("GetTxsByShortHashes called: %d shortHashes", len(shortHashes))

	var results []*pb.AnyTx
	seen := make(map[string]struct{}, len(shortHashes))

	for _, shortHash := range shortHashes {
		shortHex := hex.EncodeToString(shortHash)
		//logs.Trace("Looking up short hash: %s", shortHex)
		var v interface{}
		var exists bool
		if isSync { //ä¸ºäº†è§£å†³ä¸€ä¸ªå¾ˆå¥‡æ€ªçš„bug
			v, exists = p.shortTxCache.Get(shortHex)
		} else {
			v, exists = p.shortPendingAnyTxCache.Get(shortHex)
		}
		if !exists {
			//logs.Trace("No mapping in shortPendingAnyTxCache for %s", shortHex)
			continue
		}
		txID, ok := v.(string)
		if !ok {
			//logs.Trace("Invalid type for cache value, expected string, got %T", v)
			continue
		}
		//logs.Trace("shortHex %s -> full txID %s", shortHex, txID)

		if _, added := seen[txID]; added {
			//logs.Trace("txID %s already added, skipping", txID)
			continue
		}

		txData, found := p.cacheTx.Get(txID)
		if !found {
			//logs.Trace("pendingAnyTxCache miss for txID %s", txID)
			continue
		}
		anyTx, ok := txData.(*pb.AnyTx)
		if !ok {
			//logs.Trace("pendingAnyTxCache value for %s is not *db.AnyTx (got %T)", txID, txData)
			continue
		}

		//logs.Trace("Appending AnyTx with txID %s", txID)
		results = append(results, anyTx)
		seen[txID] = struct{}{}
	}

	//logs.Trace("GetTxsByShortHashes returning %d results", len(results))
	return results
}

// æ ¹æ®ä¼ å…¥çš„ proposalTxsï¼ˆå¤šä¸ª8å­—èŠ‚çŸ­ hashæ‹¼æ¥è€Œæˆï¼‰
// å¯¹æ¯” txpool å†…éƒ¨çš„ pendingAnyTxCacheï¼Œè¿”å›ä¸¤ä¸ªç»“æœï¼š
// missingï¼šé”®ä¸º hex æ ¼å¼çš„çŸ­ hashï¼ˆé‚£äº›æœªåœ¨æœ¬åœ°æ‰¾åˆ°çš„ï¼‰
func (p *TxPool) AnalyzeProposalTxs(proposalTxs []byte) (missing map[string]bool, existTx map[string]bool) {
	start := time.Now()
	defer func() {
		elapsed := time.Since(start)
		logs.Info("[AnalyzeProposalTxs] elapsed=%s", elapsed)
	}()
	missing = make(map[string]bool)
	existTx = make(map[string]bool)
	const shortHashSize = 8
	for i := 0; i+shortHashSize <= len(proposalTxs); i += shortHashSize {
		shortHash := proposalTxs[i : i+shortHashSize]
		shortHashHex := hex.EncodeToString(shortHash)
		//logs.Trace("proposalTxs=%x", proposalTxs)
		matchedTxs := p.GetTxsByShortHashes([][]byte{shortHash}, false)
		if len(matchedTxs) == 0 {
			// æ²¡æœ‰åŒ¹é…åˆ°ï¼Œè®°ä¸ºç¼ºå¤±
			missing[shortHashHex] = true
		} else {
			// å¦‚æœå­˜åœ¨åˆ™æ£€æŸ¥äº¤æ˜“çŠ¶æ€ï¼Œå‡è®¾åªæœ‰ PENDING çŠ¶æ€çš„äº¤æ˜“æ‰ç®—æœ‰æ•ˆ
			for _, tx := range matchedTxs {
				existTx[tx.GetTxId()] = true
			}
		}
	}
	return missing, existTx
}


æ–‡ä»¶è·¯å¾„: txpool/txpool_queue.go
æ–‡ä»¶å†…å®¹:
package txpool

import (...)

// å†…éƒ¨æ¶ˆæ¯ç±»å‹
type txMsgType int

const (
	msgAddTx txMsgType = iota
	msgRemoveTx
)

// å›è°ƒå‡½æ•°ç±»å‹ï¼šåœ¨äº¤æ˜“çœŸæ­£åŠ å…¥TxPoolä¹‹åï¼Œæ˜¯å¦è¦åšé¢å¤–æ“ä½œ
type OnTxAddedCallback func(txID string)

// TxPoolMessage å°è£…äº†è¦åœ¨ txpool é‡Œå¤„ç†çš„å„ç§ä»»åŠ¡
type txPoolMessage struct {
	Type    txMsgType
	AnyTx   *pb.AnyTx
	IP      string
	OnAdded OnTxAddedCallback
}

type txPoolQueue struct {
	pool      *TxPool
	validator TxValidator
	MsgChan   chan *txPoolMessage
}

// TxValidator ç”¨äºæŠ½è±¡äº¤æ˜“æ ¡éªŒ
type TxValidator interface {
	CheckAnyTx(tx *pb.AnyTx) error
}

// NewTxPoolQueue åˆ›å»ºæ–°çš„é˜Ÿåˆ—å®ä¾‹
func newTxPoolQueue(pool *TxPool, validator TxValidator) *txPoolQueue {
	return &txPoolQueue{
		pool:      pool,
		validator: validator,
		MsgChan:   make(chan *txPoolMessage, 10000),
	}
}

func (tq *txPoolQueue) runLoop() {
	defer tq.pool.wg.Done()

	for {
		select {
		case <-tq.pool.stopChan:
			return
		case msg := <-tq.MsgChan:
			if msg == nil {
				continue
			}
			switch msg.Type {
			case msgAddTx:
				tq.handleAddTx(msg.AnyTx, msg.IP, msg.OnAdded)
			case msgRemoveTx:
				txID := msg.AnyTx.GetTxId()
				tq.pool.RemoveTx(txID)
				logs.Debug("[TxPoolQueue] removed tx=%s from TxPool", txID)
			default:
				logs.Debug("[TxPoolQueue] unknown msg type: %d", msg.Type)
			}
		}
	}
}

func (tq *txPoolQueue) handleAddTx(incoming *pb.AnyTx, ip string, onAdded OnTxAddedCallback) {
	txID := incoming.GetTxId()
	if txID == "" {
		log.Println("[TxPoolQueue] AddTx but no txID, skip.")
		return
	}

	if tq.pool.HasTransaction(txID) {
		return
	}

	base := incoming.GetBase()
	if base == nil {
		logs.Debug("[TxPoolQueue] missing BaseMessage, skip.")
		return
	}

	pubKeyPem := base.PublicKey

	// æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥èŠ‚ç‚¹
	isKnown := false
	if pubKeyPem != "" {
		if pubKeyObj, err := utils.DecodePublicKey(pubKeyPem); err == nil {
			pubKeyStr := utils.ExtractPublicKeyString(pubKeyObj)
			isKnown = tq.pool.network.IsKnownNode(pubKeyStr)
		}
	}

	if isKnown {
		// å·²çŸ¥èŠ‚ç‚¹ï¼šå…ˆå¹¿æ’­åéªŒè¯
		if onAdded != nil {
			onAdded(txID)
		}

		// å¼‚æ­¥æ ¡éªŒ & å…¥æ± 
		go func(tx *pb.AnyTx) {
			if err := tq.validator.CheckAnyTx(tx); err != nil {
				return
			}
			if err := tq.pool.storeAnyTx(tx); err != nil {
				logs.Debug("[TxPoolQueue] StoreAnyTx fail: %v", err)
			}
		}(incoming)

	} else {
		// æœªçŸ¥èŠ‚ç‚¹ï¼šå…ˆéªŒè¯åå¹¿æ’­
		if err := tq.validator.CheckAnyTx(incoming); err != nil {
			logs.Debug("[TxPoolQueue] unknown node, tx=%s invalid: %v", txID, err)
			return
		}

		// æ›´æ–°ç½‘ç»œèŠ‚ç‚¹ä¿¡æ¯
		if pubKeyPem != "" {
			if pubKeyObj, err := utils.DecodePublicKey(pubKeyPem); err == nil {
				pubKeyStr := utils.ExtractPublicKeyString(pubKeyObj)
				tq.pool.network.AddOrUpdateNode(pubKeyStr, ip, true)
			}
		}

		// å…¥æ± 
		if err := tq.pool.storeAnyTx(incoming); err != nil {
			logs.Debug("[TxPoolQueue] unknown node => store tx=%s fail: %v", txID, err)
			return
		}

		// æœ€åå¹¿æ’­
		if onAdded != nil {
			onAdded(txID)
		}
	}
}


æ–‡ä»¶è·¯å¾„: types/block.go
æ–‡ä»¶å†…å®¹:
package types

// åŒºå—å®šä¹‰
type Block struct {
	ID       string
	Height   uint64
	ParentID string
	Data     string
	Proposer string
	Round    int
}


æ–‡ä»¶è·¯å¾„: types/event.go
æ–‡ä»¶å†…å®¹:
package types

// ============================================
// äº‹ä»¶ç³»ç»Ÿ
// ============================================

type EventType string

const (
	EventPreferenceChanged EventType = "snowball.preference"
	EventBlockFinalized    EventType = "block.finalized"
	EventBlockReceived     EventType = "block.received"
	EventQueryComplete     EventType = "query.complete"
	EventSyncComplete      EventType = "sync.complete"
	EventNewBlock          EventType = "block.new"
	EventSnapshotCreated   EventType = "snapshot.created" // æ–°å¢
	EventSnapshotLoaded    EventType = "snapshot.loaded"  // æ–°å¢
)

type BaseEvent struct {
	EventType EventType
	EventData interface{}
}

func (e BaseEvent) Type() EventType   { return e.EventType }
func (e BaseEvent) Data() interface{} { return e.EventData }


æ–‡ä»¶è·¯å¾„: types/gossip.go
æ–‡ä»¶å†…å®¹:
// types/gossip.go æˆ– types/network.go
package types

import (...)

// GossipPayload ç”¨äºèŠ‚ç‚¹é—´çš„åŒºå—ä¼ æ’­
type GossipPayload struct {
	Block     *pb.Block `json:"block"`
	RequestID uint32    `json:"request_id"`
}


æ–‡ä»¶è·¯å¾„: types/message.go
æ–‡ä»¶å†…å®¹:
package types

import (...)
type NodeID string

func (id NodeID) Last2Mod100() int {
	s := string(id)
	if len(s) < 2 {
		return 0
	}
	last2 := s[len(s)-2:] // å–æœ€åä¸¤ä½å­—ç¬¦ä¸²

	n, err := strconv.Atoi(last2)
	if err != nil {
		return 0 // å¦‚æœä¸æ˜¯æ•°å­—ï¼Œè¿”å›0ï¼ˆä½ ä¹Ÿå¯ä»¥é€‰æ‹©è¿”å›-1è¡¨ç¤ºé”™è¯¯ï¼‰
	}
	return n % 100
}

// æ¶ˆæ¯ç±»å‹
type MessageType string

const (
	MsgPullQuery        = "MsgPullQuery"
	MsgPushQuery        = "MsgPushQuery"
	MsgChits            = "MsgChits"
	MsgGet              = "MsgGet" // è¯·æ±‚åŒºå—æ•°æ®
	MsgPut              = "MsgPut" // å‘é€åŒºå—æ•°æ®
	MsgGossip           = "MsgGossip"
	MsgSyncRequest      = "MsgSyncRequest"
	MsgSyncResponse     = "MsgSyncResponse"
	MsgHeightQuery      = "MsgHeightQuery"
	MsgHeightResponse   = "MsgHeightResponse"
	MsgSnapshotRequest  = "MsgSnapshotRequest"  // è¯·æ±‚å¿«ç…§
	MsgSnapshotResponse = "MsgSnapshotResponse" // å¿«ç…§å“åº”
)

// åŸºç¡€æ¶ˆæ¯ç»“æ„
type Message struct {
	Type      MessageType
	From      NodeID
	RequestID uint32
	BlockID   string
	Block     *Block
	Height    uint64
	// For Chits
	PreferredID       string
	PreferredIDHeight uint64
	AcceptedID        string
	AcceptedHeight    uint64
	// For Sync
	FromHeight uint64
	ToHeight   uint64
	Blocks     []*Block
	SyncID     uint32
	// For Height Query
	CurrentHeight uint64
	// For Snapshot
	Snapshot        *Snapshot
	SnapshotHeight  uint64
	RequestSnapshot bool
}


æ–‡ä»¶è·¯å¾„: types/snapshot.go
æ–‡ä»¶å†…å®¹:
package types

import (...)

type Snapshot struct {
	Height             uint64            `json:"height"`
	Timestamp          time.Time         `json:"timestamp"`
	FinalizedBlocks    map[uint64]*Block `json:"finalized_blocks"`
	LastAcceptedID     string            `json:"last_accepted_id"`
	LastAcceptedHeight uint64            `json:"last_accepted_height"`
	BlockHashes        map[string]bool   `json:"block_hashes"` // ç”¨äºå¿«é€Ÿå»é‡
}

è·³è¿‡æ’é™¤çš„ç›®å½•: utils

æ–‡ä»¶è·¯å¾„: vm/candidate_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// CandidateTxHandler å§”æ‰˜äººæŠ•ç¥¨äº¤æ˜“å¤„ç†å™¨
type CandidateTxHandler struct{}

func (h *CandidateTxHandler) Kind() string {
	return "candidate"
}

func (h *CandidateTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–CandidateTx
	candidateTx, ok := tx.GetContent().(*pb.AnyTx_CandidateTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not a candidate transaction",
		}, fmt.Errorf("not a candidate transaction")
	}

	candidate := candidateTx.CandidateTx
	if candidate == nil || candidate.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid candidate transaction",
		}, fmt.Errorf("invalid candidate transaction")
	}

	// 2. æ ¹æ®æ“ä½œç±»å‹åˆ†å‘å¤„ç†
	switch candidate.Op {
	case pb.OrderOp_ADD:
		return h.handleAddVote(candidate, sv)
	case pb.OrderOp_REMOVE:
		return h.handleRemoveVote(candidate, sv)
	default:
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "unknown candidate operation",
		}, fmt.Errorf("unknown candidate operation: %v", candidate.Op)
	}
}

// handleAddVote å¤„ç†æŠ•ç¥¨ï¼ˆå§”æ‰˜ï¼‰
func (h *CandidateTxHandler) handleAddVote(candidate *pb.CandidateTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// éªŒè¯æŠ•ç¥¨é‡‘é¢
	amount, ok := new(big.Int).SetString(candidate.Amount, 10)
	if !ok || amount.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "invalid vote amount",
		}, fmt.Errorf("invalid vote amount: %s", candidate.Amount)
	}

	// è¯»å–æŠ•ç¥¨è€…è´¦æˆ·
	voterAccountKey := fmt.Sprintf("account_%s", candidate.Base.FromAddress)
	voterAccountData, voterExists, err := sv.Get(voterAccountKey)
	if err != nil || !voterExists {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "voter account not found",
		}, fmt.Errorf("voter account not found: %s", candidate.Base.FromAddress)
	}

	var voterAccount pb.Account
	if err := json.Unmarshal(voterAccountData, &voterAccount); err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse voter account",
		}, err
	}

	// è¯»å–å€™é€‰äººè´¦æˆ·ï¼ˆéªŒè¯å€™é€‰äººæ˜¯å¦å­˜åœ¨ï¼‰
	candidateAccountKey := fmt.Sprintf("account_%s", candidate.CandidateAddress)
	candidateAccountData, candidateExists, err := sv.Get(candidateAccountKey)
	if err != nil || !candidateExists {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "candidate account not found",
		}, fmt.Errorf("candidate account not found: %s", candidate.CandidateAddress)
	}

	var candidateAccount pb.Account
	if err := json.Unmarshal(candidateAccountData, &candidateAccount); err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse candidate account",
		}, err
	}

	// å‡è®¾ä½¿ç”¨åŸç”Ÿä»£å¸è¿›è¡ŒæŠ•ç¥¨ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´tokenåœ°å€ï¼‰
	nativeTokenAddr := "native_token" // è¿™åº”è¯¥æ˜¯ç³»ç»Ÿå®šä¹‰çš„åŸç”Ÿä»£å¸åœ°å€

	// æ£€æŸ¥æŠ•ç¥¨è€…ä½™é¢
	if voterAccount.Balances == nil || voterAccount.Balances[nativeTokenAddr] == nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance for voting",
		}, fmt.Errorf("no balance for native token")
	}

	voterBalance, _ := new(big.Int).SetString(voterAccount.Balances[nativeTokenAddr].Balance, 10)
	if voterBalance == nil || voterBalance.Cmp(amount) < 0 {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance for voting",
		}, fmt.Errorf("insufficient balance: has %s, need %s", voterBalance.String(), amount.String())
	}

	// æ£€æŸ¥æ˜¯å¦å·²ç»æŠ•ç¥¨ç»™å…¶ä»–å€™é€‰äºº
	if voterAccount.Candidate != "" && voterAccount.Candidate != candidate.CandidateAddress {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "already voted for another candidate, please remove vote first",
		}, fmt.Errorf("already voted for: %s", voterAccount.Candidate)
	}

	ws := make([]WriteOp, 0)

	// ä»å¯ç”¨ä½™é¢è½¬ç§»åˆ°é”å®šä½™é¢
	newVoterBalance := new(big.Int).Sub(voterBalance, amount)
	voterAccount.Balances[nativeTokenAddr].Balance = newVoterBalance.String()

	currentLockedBalance, _ := new(big.Int).SetString(voterAccount.Balances[nativeTokenAddr].CandidateLockedBalance, 10)
	if currentLockedBalance == nil {
		currentLockedBalance = big.NewInt(0)
	}
	newLockedBalance := new(big.Int).Add(currentLockedBalance, amount)
	voterAccount.Balances[nativeTokenAddr].CandidateLockedBalance = newLockedBalance.String()

	// è®¾ç½®æŠ•ç¥¨çš„å€™é€‰äºº
	voterAccount.Candidate = candidate.CandidateAddress

	// ä¿å­˜æŠ•ç¥¨è€…è´¦æˆ·
	updatedVoterData, err := json.Marshal(&voterAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal voter account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   voterAccountKey,
		Value: updatedVoterData,
		Del:   false,
	})

	// æ›´æ–°å€™é€‰äººæ”¶åˆ°çš„æŠ•ç¥¨æ•°
	candidateVotes, _ := new(big.Int).SetString(candidateAccount.ReceiveVotes, 10)
	if candidateVotes == nil {
		candidateVotes = big.NewInt(0)
	}
	newCandidateVotes := new(big.Int).Add(candidateVotes, amount)
	candidateAccount.ReceiveVotes = newCandidateVotes.String()

	// ä¿å­˜å€™é€‰äººè´¦æˆ·
	updatedCandidateData, err := json.Marshal(&candidateAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal candidate account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   candidateAccountKey,
		Value: updatedCandidateData,
		Del:   false,
	})

	// åˆ›å»ºå€™é€‰äººç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥è¯¢å€™é€‰äººçš„æ‰€æœ‰å§”æ‰˜äºº
	// keyæ ¼å¼: candidate:xxx|user:xxx
	candidateIndexKey := fmt.Sprintf("candidate:%s|user:%s", candidate.CandidateAddress, candidate.Base.FromAddress)
	candidateIndex := &pb.CandidateIndex{Ok: true}
	candidateIndexData, _ := json.Marshal(candidateIndex)
	
	ws = append(ws, WriteOp{
		Key:   candidateIndexKey,
		Value: candidateIndexData,
		Del:   false,
	})

	// è®°å½•æŠ•ç¥¨å†å²
	historyKey := fmt.Sprintf("candidate_history_%s", candidate.Base.TxId)
	historyData, _ := json.Marshal(candidate)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       candidate.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

// handleRemoveVote å¤„ç†å–æ¶ˆæŠ•ç¥¨
func (h *CandidateTxHandler) handleRemoveVote(candidate *pb.CandidateTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// è¯»å–æŠ•ç¥¨è€…è´¦æˆ·
	voterAccountKey := fmt.Sprintf("account_%s", candidate.Base.FromAddress)
	voterAccountData, voterExists, err := sv.Get(voterAccountKey)
	if err != nil || !voterExists {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "voter account not found",
		}, fmt.Errorf("voter account not found")
	}

	var voterAccount pb.Account
	if err := json.Unmarshal(voterAccountData, &voterAccount); err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse voter account",
		}, err
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰æŠ•ç¥¨è®°å½•
	if voterAccount.Candidate == "" {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "no active vote found",
		}, fmt.Errorf("no active vote")
	}

	// å¦‚æœæŒ‡å®šäº†å€™é€‰äººåœ°å€ï¼ŒéªŒè¯æ˜¯å¦åŒ¹é…
	if candidate.CandidateAddress != "" && voterAccount.Candidate != candidate.CandidateAddress {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "candidate address mismatch",
		}, fmt.Errorf("voted for %s, not %s", voterAccount.Candidate, candidate.CandidateAddress)
	}

	targetCandidateAddr := voterAccount.Candidate

	// è¯»å–å€™é€‰äººè´¦æˆ·
	candidateAccountKey := fmt.Sprintf("account_%s", targetCandidateAddr)
	candidateAccountData, candidateExists, err := sv.Get(candidateAccountKey)
	if err != nil || !candidateExists {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "candidate account not found",
		}, fmt.Errorf("candidate account not found")
	}

	var candidateAccount pb.Account
	if err := json.Unmarshal(candidateAccountData, &candidateAccount); err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse candidate account",
		}, err
	}

	nativeTokenAddr := "native_token"

	// è·å–é”å®šçš„æŠ•ç¥¨é‡‘é¢
	if voterAccount.Balances == nil || voterAccount.Balances[nativeTokenAddr] == nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "no locked balance found",
		}, fmt.Errorf("no locked balance")
	}

	lockedBalance, _ := new(big.Int).SetString(voterAccount.Balances[nativeTokenAddr].CandidateLockedBalance, 10)
	if lockedBalance == nil || lockedBalance.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "no locked balance to release",
		}, fmt.Errorf("no locked balance")
	}

	ws := make([]WriteOp, 0)

	// ä»é”å®šä½™é¢è½¬å›å¯ç”¨ä½™é¢
	voterAccount.Balances[nativeTokenAddr].CandidateLockedBalance = "0"
	
	currentBalance, _ := new(big.Int).SetString(voterAccount.Balances[nativeTokenAddr].Balance, 10)
	if currentBalance == nil {
		currentBalance = big.NewInt(0)
	}
	newBalance := new(big.Int).Add(currentBalance, lockedBalance)
	voterAccount.Balances[nativeTokenAddr].Balance = newBalance.String()

	// æ¸…é™¤æŠ•ç¥¨è®°å½•
	voterAccount.Candidate = ""

	// ä¿å­˜æŠ•ç¥¨è€…è´¦æˆ·
	updatedVoterData, err := json.Marshal(&voterAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal voter account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   voterAccountKey,
		Value: updatedVoterData,
		Del:   false,
	})

	// å‡å°‘å€™é€‰äººæ”¶åˆ°çš„æŠ•ç¥¨æ•°
	candidateVotes, _ := new(big.Int).SetString(candidateAccount.ReceiveVotes, 10)
	if candidateVotes == nil {
		candidateVotes = big.NewInt(0)
	}
	newCandidateVotes := new(big.Int).Sub(candidateVotes, lockedBalance)
	if newCandidateVotes.Sign() < 0 {
		newCandidateVotes = big.NewInt(0)
	}
	candidateAccount.ReceiveVotes = newCandidateVotes.String()

	// ä¿å­˜å€™é€‰äººè´¦æˆ·
	updatedCandidateData, err := json.Marshal(&candidateAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   candidate.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal candidate account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   candidateAccountKey,
		Value: updatedCandidateData,
		Del:   false,
	})

	// åˆ é™¤å€™é€‰äººç´¢å¼•
	candidateIndexKey := fmt.Sprintf("candidate:%s|user:%s", targetCandidateAddr, candidate.Base.FromAddress)
	ws = append(ws, WriteOp{
		Key:   candidateIndexKey,
		Value: nil,
		Del:   true,
	})

	// è®°å½•å–æ¶ˆæŠ•ç¥¨å†å²
	historyKey := fmt.Sprintf("candidate_history_%s", candidate.Base.TxId)
	historyData, _ := json.Marshal(candidate)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       candidate.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *CandidateTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/default_handlers.go
æ–‡ä»¶å†…å®¹:
package vm

// RegisterDefaultHandlers æ³¨å†Œæ‰€æœ‰é»˜è®¤çš„äº¤æ˜“å¤„ç†å™¨
func RegisterDefaultHandlers(reg *HandlerRegistry) error {
	handlers := []TxHandler{
		&IssueTokenTxHandler{},  // å‘å¸äº¤æ˜“
		&FreezeTxHandler{},      // å†»ç»“/è§£å†»Tokenäº¤æ˜“
		&TransferTxHandler{},    // è½¬è´¦äº¤æ˜“
		&OrderTxHandler{},       // è®¢å•äº¤æ˜“
		&RechargeTxHandler{},    // ä¸Šè´¦äº¤æ˜“
		&CandidateTxHandler{},   // å§”æ‰˜äººæŠ•ç¥¨äº¤æ˜“
		&MinerTxHandler{},       // çŸ¿å·¥äº¤æ˜“
	}

	for _, h := range handlers {
		if err := reg.Register(h); err != nil {
			return err
		}
	}

	return nil
}


æ–‡ä»¶è·¯å¾„: vm/example/main.go
æ–‡ä»¶å†…å®¹:
package main

import (...)

// SimpleDB ç®€å•çš„å†…å­˜æ•°æ®åº“å®ç°
type SimpleDB struct {
	data map[string][]byte
}

func NewSimpleDB() *SimpleDB {
	return &SimpleDB{
		data: make(map[string][]byte),
	}
}

func (db *SimpleDB) Get(key string) ([]byte, error) {
	val, exists := db.data[key]
	if !exists {
		return nil, nil
	}
	return val, nil
}

func (db *SimpleDB) EnqueueSet(key, value string) {
	db.data[key] = []byte(value)
}

func (db *SimpleDB) EnqueueDel(key string) {
	delete(db.data, key)
}

func (db *SimpleDB) ForceFlush() error {
	// å†…å­˜æ•°æ®åº“ï¼Œæ— éœ€åˆ·æ–°
	return nil
}

// CustomHandler è‡ªå®šä¹‰Handlerç¤ºä¾‹
type CustomHandler struct {
	name string
}

func NewCustomHandler(name string) *CustomHandler {
	return &CustomHandler{name: name}
}

func (h *CustomHandler) Kind() string {
	return h.name
}

func (h *CustomHandler) DryRun(tx *pb.AnyTx, sv vm.StateView) ([]vm.WriteOp, *vm.Receipt, error) {
	// ç®€å•ç¤ºä¾‹ï¼šå°†äº¤æ˜“æ•°æ®ç›´æ¥å†™å…¥
	txID := tx.GetTxId()
	key := fmt.Sprintf("%s_%s", h.name, txID)

	// å°†æ•´ä¸ªpb.AnyTxåºåˆ—åŒ–å­˜å‚¨
	data, _ := json.Marshal(tx)
	ws := []vm.WriteOp{
		{Key: key, Value: data, Del: false},
	}

	return ws, &vm.Receipt{
		TxID:       txID,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *CustomHandler) Apply(tx *pb.AnyTx) error {
	return vm.ErrNotImplemented
}

func main() {
	// 1. åˆå§‹åŒ–ç»„ä»¶
	db := NewSimpleDB()
	registry := vm.NewHandlerRegistry()
	cache := vm.NewSpecExecLRU(100)

	// 2. æ³¨å†ŒHandler
	// ä½¿ç”¨é»˜è®¤Handler
	if err := vm.RegisterDefaultHandlers(registry); err != nil {
		log.Fatal("Failed to register handlers:", err)
	}

	// æ·»åŠ è‡ªå®šä¹‰Handler
	customHandler := NewCustomHandler("custom")
	if err := registry.Register(customHandler); err != nil {
		log.Fatal("Failed to register custom handler:", err)
	}

	// 3. åˆ›å»ºæ‰§è¡Œå™¨
	executor := vm.NewExecutor(db, registry, cache)

	// 4. åˆå§‹åŒ–ä¸€äº›è´¦æˆ·æ•°æ®
	db.data["balance_alice_token123"] = []byte("10000")
	db.data["balance_bob_token123"] = []byte("5000")
	db.data["balance_charlie_token123"] = []byte("3000")

	fmt.Println("Initial balances:")
	fmt.Printf("  Alice: %s token123\n", db.data["balance_alice_token123"])
	fmt.Printf("  Bob: %s token123\n", db.data["balance_bob_token123"])
	fmt.Printf("  Charlie: %s token123\n", db.data["balance_charlie_token123"])

	// 5. åˆ›å»ºpb.AnyTxäº¤æ˜“
	txs := []*pb.AnyTx{
		// è½¬è´¦äº¤æ˜“1
		{
			Content: &pb.AnyTx_Transaction{
				Transaction: &pb.Transaction{
					Base: &pb.BaseMessage{
						TxId:        "tx_001",
						FromAddress: "alice",
						Status:      pb.Status_PENDING,
					},
					To:           "bob",
					TokenAddress: "token123",
					Amount:       "100",
				},
			},
		},
		// è½¬è´¦äº¤æ˜“2
		{
			Content: &pb.AnyTx_Transaction{
				Transaction: &pb.Transaction{
					Base: &pb.BaseMessage{
						TxId:        "tx_002",
						FromAddress: "bob",
						Status:      pb.Status_PENDING,
					},
					To:           "charlie",
					TokenAddress: "token123",
					Amount:       "50",
				},
			},
		},
		// çŸ¿å·¥å¥–åŠ±
		{
			Content: &pb.AnyTx_MinerTx{
				MinerTx: &pb.MinerTx{
					Base: &pb.BaseMessage{
						TxId:           "tx_003",
						FromAddress:    "alice",
						ExecutedHeight: 1,
						Status:         pb.Status_PENDING,
					},
					Op:     pb.OrderOp_ADD,
					Amount: "100",
				},
			},
		},
	}

	// 6. åˆ›å»ºpb.BlockåŒºå—
	block := &pb.Block{
		BlockHash:     "block_001",
		PrevBlockHash: "genesis",
		Height:        1,
		Body:          txs,
	}

	// 7. é¢„æ‰§è¡ŒåŒºå—
	fmt.Println("\n=== Pre-executing block ===")
	result, err := executor.PreExecuteBlock(block)
	if err != nil {
		log.Fatal("PreExecute failed:", err)
	}

	fmt.Printf("Block Valid: %v\n", result.Valid)
	if !result.Valid {
		fmt.Printf("Reason: %s\n", result.Reason)
		return
	}

	fmt.Printf("Transactions processed: %d\n", len(result.Receipts))
	for _, receipt := range result.Receipts {
		fmt.Printf("  %s: %s (writes: %d)\n",
			receipt.TxID, receipt.Status, receipt.WriteCount)
		if receipt.Error != "" {
			fmt.Printf("    Error: %s\n", receipt.Error)
		}
	}

	fmt.Printf("State changes: %d\n", len(result.Diff))

	// 8. æ¨¡æ‹Ÿå…±è¯†è¿‡ç¨‹
	fmt.Println("\n=== Simulating consensus ===")
	fmt.Println("Block accepted by consensus")

	// 9. æäº¤åŒºå—
	fmt.Println("\n=== Committing block ===")
	if err := executor.CommitFinalizedBlock(block); err != nil {
		log.Fatal("Commit failed:", err)
	}
	fmt.Println("Block committed successfully")

	// 10. éªŒè¯æœ€ç»ˆçŠ¶æ€
	fmt.Println("\n=== Final state ===")

	// æ£€æŸ¥åŒºå—æäº¤çŠ¶æ€
	if committed, blockID := executor.IsBlockCommitted(1); committed {
		fmt.Printf("Block at height 1: %s\n", blockID)
	}

	// æ£€æŸ¥äº¤æ˜“çŠ¶æ€
	for _, tx := range txs {
		txID := tx.GetTxId()
		status, _ := executor.GetTransactionStatus(txID)
		fmt.Printf("Transaction %s: %s\n", txID, status)
	}

	// æ˜¾ç¤ºæœ€ç»ˆä½™é¢ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥æ­£ç¡®å¤„ç†ä½™é¢å˜æ›´ï¼‰
	fmt.Println("\nFinal balances (ç¤ºä¾‹ï¼Œå®é™…éœ€è¦æ­£ç¡®çš„ä½™é¢è®¡ç®—):")
	fmt.Printf("  Alice: %s token123\n", db.data["balance_alice_token123"])
	fmt.Printf("  Bob: %s token123\n", db.data["balance_bob_token123"])
	fmt.Printf("  Charlie: %s token123\n", db.data["balance_charlie_token123"])

	// 11. æ¼”ç¤ºç¼“å­˜æ•ˆæœ
	fmt.Println("\n=== Cache demonstration ===")

	// å†æ¬¡æ‰§è¡Œç›¸åŒåŒºå—ï¼ˆä»ç¼“å­˜è·å–ï¼‰
	result2, err := executor.PreExecuteBlock(block)
	if err != nil {
		log.Fatal("Second PreExecute failed:", err)
	}

	if result2.BlockID == result.BlockID {
		fmt.Println("Successfully retrieved result from cache")
	}

	// 12. æ¸…ç†æ—§ç¼“å­˜
	fmt.Println("\n=== Cache cleanup ===")
	executor.CleanupCache(100) // æ¸…ç†é«˜åº¦100ä»¥ä¸‹çš„ç¼“å­˜
	fmt.Println("Old cache entries cleaned")

	// 13. æ˜¾ç¤ºæ³¨å†Œçš„Handler
	fmt.Println("\n=== Registered handlers ===")
	handlers := registry.List()
	for _, h := range handlers {
		fmt.Printf("  - %s\n", h)
	}

	fmt.Println("\n=== Example completed successfully ===")
}

func mustMarshal(v interface{}) []byte {
	data, err := json.Marshal(v)
	if err != nil {
		panic(err)
	}
	return data
}


æ–‡ä»¶è·¯å¾„: vm/executor.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// Executor VMæ‰§è¡Œå™¨
type Executor struct {
	mu     sync.RWMutex
	DB     DBManager
	Reg    *HandlerRegistry
	Cache  SpecExecCache
	KFn    KindFn
	ReadFn ReadThroughFn
}

// åˆ›å»ºæ–°çš„æ‰§è¡Œå™¨
func NewExecutor(db DBManager, reg *HandlerRegistry, cache SpecExecCache) *Executor {
	if reg == nil {
		reg = NewHandlerRegistry()
	}
	if cache == nil {
		cache = NewSpecExecLRU(1024)
	}

	executor := &Executor{
		DB:    db,
		Reg:   reg,
		Cache: cache,
		KFn:   DefaultKindFn,
	}

	// è®¾ç½®ReadFn
	executor.ReadFn = func(key string) ([]byte, error) {
		return db.Get(key)
	}

	return executor
}

// SetKindFn è®¾ç½®Kindæå–å‡½æ•°
func (x *Executor) SetKindFn(fn KindFn) {
	x.mu.Lock()
	defer x.mu.Unlock()
	x.KFn = fn
}

// PreExecuteBlock é¢„æ‰§è¡ŒåŒºå—ï¼ˆä¸å†™æ•°æ®åº“ï¼‰
func (x *Executor) PreExecuteBlock(b *pb.Block) (*SpecResult, error) {
	if b == nil {
		return nil, ErrNilBlock
	}

	// æ£€æŸ¥ç¼“å­˜
	if cached, ok := x.Cache.Get(b.BlockHash); ok {
		return cached, nil
	}

	// åˆ›å»ºæ–°çš„çŠ¶æ€è§†å›¾
	sv := NewStateView(x.ReadFn)
	receipts := make([]*Receipt, 0, len(b.Body))

	// éå†æ‰§è¡Œæ¯ä¸ªäº¤æ˜“
	for idx, tx := range b.Body {
		// æå–äº¤æ˜“ç±»å‹
		kind, err := x.KFn(tx)
		if err != nil {
			return &SpecResult{
				BlockID:  b.BlockHash,
				ParentID: b.PrevBlockHash,
				Height:   b.Height,
				Valid:    false,
				Reason:   fmt.Sprintf("tx %d: %v", idx, err),
			}, nil
		}

		// è·å–å¯¹åº”çš„Handler
		h, ok := x.Reg.Get(kind)
		if !ok {
			return &SpecResult{
				BlockID:  b.BlockHash,
				ParentID: b.PrevBlockHash,
				Height:   b.Height,
				Valid:    false,
				Reason:   fmt.Sprintf("no handler for tx %d (kind: %s)", idx, kind),
			}, nil
		}

		// åˆ›å»ºå¿«ç…§ç‚¹ï¼Œç”¨äºå¤±è´¥æ—¶å›æ»š
		snapshot := sv.Snapshot()

		// æ‰§è¡Œäº¤æ˜“
		ws, rc, err := h.DryRun(tx, sv)
		if err != nil {
			// å›æ»šçŠ¶æ€
			sv.Revert(snapshot)
			return &SpecResult{
				BlockID:  b.BlockHash,
				ParentID: b.PrevBlockHash,
				Height:   b.Height,
				Valid:    false,
				Reason:   fmt.Sprintf("tx %d invalid: %v", idx, err),
			}, nil
		}

		// å°†wsåº”ç”¨åˆ°overlayï¼ˆå¦‚æœDryRunæ²¡æœ‰ç›´æ¥å†™svï¼‰
		for _, w := range ws {
			if w.Del {
				sv.Del(w.Key)
			} else {
				sv.Set(w.Key, w.Value)
			}
		}
		receipts = append(receipts, rc)
	}

	// åˆ›å»ºæ‰§è¡Œç»“æœ
	res := &SpecResult{
		BlockID:  b.BlockHash,
		ParentID: b.PrevBlockHash,
		Height:   b.Height,
		Valid:    true,
		Receipts: receipts,
		Diff:     sv.Diff(),
	}

	// ç¼“å­˜ç»“æœ
	x.Cache.Put(res)
	return res, nil
}

// CommitFinalizedBlock æœ€ç»ˆåŒ–æäº¤ï¼ˆå†™å…¥æ•°æ®åº“ï¼‰
func (x *Executor) CommitFinalizedBlock(b *pb.Block) error {
	if b == nil {
		return ErrNilBlock
	}

	x.mu.Lock()
	defer x.mu.Unlock()

	// ä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„æ‰§è¡Œç»“æœ
	if res, ok := x.Cache.Get(b.BlockHash); ok && res.Valid {
		return x.applyResult(res, b)
	}

	// ç¼“å­˜ç¼ºå¤±ï¼šé‡æ–°æ‰§è¡Œ
	res, err := x.PreExecuteBlock(b)
	if err != nil {
		return fmt.Errorf("re-execute block failed: %v", err)
	}

	if !res.Valid {
		return fmt.Errorf("block invalid: %s", res.Reason)
	}

	return x.applyResult(res, b)
}

// applyResult åº”ç”¨æ‰§è¡Œç»“æœåˆ°æ•°æ®åº“
func (x *Executor) applyResult(res *SpecResult, b *pb.Block) error {
	// æ‰¹é‡å†™å…¥çŠ¶æ€å˜æ›´
	for _, w := range res.Diff {
		if w.Del {
			x.DB.EnqueueDel(w.Key)
		} else {
			x.DB.EnqueueSet(w.Key, string(w.Value))
		}
	}

	// å†™å…¥å¹‚ç­‰æ ‡è®°ï¼šé«˜åº¦æäº¤
	heightKey := fmt.Sprintf("vm_commit_h_%d", b.Height)
	x.DB.EnqueueSet(heightKey, b.BlockHash)

	// å†™å…¥äº¤æ˜“å¤„ç†çŠ¶æ€
	for _, rc := range res.Receipts {
		txKey := fmt.Sprintf("vm_applied_tx_%s", rc.TxID)
		x.DB.EnqueueSet(txKey, rc.Status)

		// å¯é€‰ï¼šå†™å…¥å®Œæ•´çš„Receipt
		if rc.Error != "" {
			errKey := fmt.Sprintf("vm_tx_error_%s", rc.TxID)
			x.DB.EnqueueSet(errKey, rc.Error)
		}
	}

	// å¼ºåˆ¶åˆ·æ–°åˆ°æ•°æ®åº“
	return x.DB.ForceFlush()
}

// IsBlockCommitted æ£€æŸ¥åŒºå—æ˜¯å¦å·²æäº¤
func (x *Executor) IsBlockCommitted(height uint64) (bool, string) {
	key := fmt.Sprintf("vm_commit_h_%d", height)
	blockID, err := x.DB.Get(key)
	if err != nil || blockID == nil {
		return false, ""
	}
	return true, string(blockID)
}

// GetTransactionStatus è·å–äº¤æ˜“çŠ¶æ€
func (x *Executor) GetTransactionStatus(txID string) (string, error) {
	key := fmt.Sprintf("vm_applied_tx_%s", txID)
	status, err := x.DB.Get(key)
	if err != nil {
		return "", err
	}
	if status == nil {
		return "PENDING", nil
	}
	return string(status), nil
}

// GetTransactionError è·å–äº¤æ˜“é”™è¯¯ä¿¡æ¯
func (x *Executor) GetTransactionError(txID string) (string, error) {
	key := fmt.Sprintf("vm_tx_error_%s", txID)
	errMsg, err := x.DB.Get(key)
	if err != nil {
		return "", err
	}
	if errMsg == nil {
		return "", nil
	}
	return string(errMsg), nil
}

// CleanupCache æ¸…ç†ç¼“å­˜
func (x *Executor) CleanupCache(finalizedHeight uint64) {
	if finalizedHeight > 100 {
		// ä¿ç•™æœ€è¿‘100ä¸ªé«˜åº¦çš„ç¼“å­˜
		x.Cache.EvictBelow(finalizedHeight - 100)
	}
}

// ValidateBlock éªŒè¯åŒºå—åŸºæœ¬ä¿¡æ¯
func ValidateBlock(b *pb.Block) error {
	if b == nil {
		return ErrNilBlock
	}
	if b.BlockHash == "" {
		return fmt.Errorf("empty block hash")
	}
	if b.Height == 0 && b.PrevBlockHash != "" {
		return fmt.Errorf("genesis block should not have parent")
	}
	if b.Height > 0 && b.PrevBlockHash == "" {
		return fmt.Errorf("non-genesis block should have parent")
	}
	return nil
}


æ–‡ä»¶è·¯å¾„: vm/freeze_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// FreezeTxHandler å†»ç»“/è§£å†»Tokenäº¤æ˜“å¤„ç†å™¨
type FreezeTxHandler struct{}

func (h *FreezeTxHandler) Kind() string {
	return "freeze"
}

func (h *FreezeTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–FreezeTx
	freezeTx, ok := tx.GetContent().(*pb.AnyTx_FreezeTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not a freeze transaction",
		}, fmt.Errorf("not a freeze transaction")
	}

	freeze := freezeTx.FreezeTx
	if freeze == nil || freeze.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid freeze transaction",
		}, fmt.Errorf("invalid freeze transaction")
	}

	// 2. éªŒè¯Tokenæ˜¯å¦å­˜åœ¨
	tokenKey := fmt.Sprintf("token_%s", freeze.TokenAddr)
	tokenData, tokenExists, err := sv.Get(tokenKey)
	if err != nil {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "read token failed",
		}, err
	}

	if !tokenExists {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "token not found",
		}, fmt.Errorf("token not found: %s", freeze.TokenAddr)
	}

	// è§£æTokenæ•°æ®
	var token pb.Token
	if err := json.Unmarshal(tokenData, &token); err != nil {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse token data",
		}, err
	}

	// 3. éªŒè¯æ“ä½œè€…æ˜¯å¦æ˜¯Tokençš„owner
	if token.Owner != freeze.Base.FromAddress {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "only token owner can freeze/unfreeze",
		}, fmt.Errorf("only token owner can freeze/unfreeze: owner=%s, from=%s", token.Owner, freeze.Base.FromAddress)
	}

	// 4. è¯»å–ç›®æ ‡è´¦æˆ·
	targetAccountKey := fmt.Sprintf("account_%s", freeze.TargetAddr)
	targetAccountData, targetExists, err := sv.Get(targetAccountKey)
	if err != nil {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "read target account failed",
		}, err
	}

	if !targetExists {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "target account not found",
		}, fmt.Errorf("target account not found: %s", freeze.TargetAddr)
	}

	// è§£æç›®æ ‡è´¦æˆ·
	var targetAccount pb.Account
	if err := json.Unmarshal(targetAccountData, &targetAccount); err != nil {
		return nil, &Receipt{
			TxID:   freeze.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse target account data",
		}, err
	}

	// 5. æ‰§è¡Œå†»ç»“/è§£å†»é€»è¾‘
	// è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç‰¹æ®Šçš„keyæ¥æ ‡è®°è´¦æˆ·çš„æŸä¸ªtokenæ˜¯å¦è¢«å†»ç»“
	freezeKey := fmt.Sprintf("freeze_%s_%s", freeze.TargetAddr, freeze.TokenAddr)
	
	ws := make([]WriteOp, 0)

	if freeze.Freeze {
		// å†»ç»“ï¼šè®¾ç½®å†»ç»“æ ‡è®°
		ws = append(ws, WriteOp{
			Key:   freezeKey,
			Value: []byte("true"),
			Del:   false,
		})
	} else {
		// è§£å†»ï¼šåˆ é™¤å†»ç»“æ ‡è®°
		ws = append(ws, WriteOp{
			Key:   freezeKey,
			Value: nil,
			Del:   true,
		})
	}

	// 6. è®°å½•å†»ç»“/è§£å†»å†å²
	historyKey := fmt.Sprintf("freeze_history_%s", freeze.Base.TxId)
	historyData, _ := json.Marshal(freeze)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	// 7. è¿”å›æ‰§è¡Œç»“æœ
	action := "frozen"
	if !freeze.Freeze {
		action = "unfrozen"
	}

	rc := &Receipt{
		TxID:       freeze.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
		Error:      fmt.Sprintf("token %s for account %s", action, freeze.TargetAddr),
	}

	return ws, rc, nil
}

func (h *FreezeTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/handlers.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// HandlerRegistry Handleræ³¨å†Œè¡¨
type HandlerRegistry struct {
	mu sync.RWMutex
	m  map[string]TxHandler
}

// NewHandlerRegistry åˆ›å»ºæ–°çš„æ³¨å†Œè¡¨
func NewHandlerRegistry() *HandlerRegistry {
	return &HandlerRegistry{m: make(map[string]TxHandler)}
}

// æ³¨å†ŒHandler
func (r *HandlerRegistry) Register(h TxHandler) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	if h == nil {
		return errors.New("nil handler")
	}

	kind := h.Kind()
	if kind == "" {
		return errors.New("empty handler kind")
	}

	if _, ok := r.m[kind]; ok {
		return fmt.Errorf("duplicate handler kind: %s", kind)
	}
	r.m[kind] = h
	return nil
}

// Get è·å–Handler
func (r *HandlerRegistry) Get(kind string) (TxHandler, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()
	h, ok := r.m[kind]
	return h, ok
}

// List åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„Handlerç±»å‹
func (r *HandlerRegistry) List() []string {
	r.mu.RLock()
	defer r.mu.RUnlock()

	kinds := make([]string, 0, len(r.m))
	for k := range r.m {
		kinds = append(kinds, k)
	}
	return kinds
}

// DefaultKindFn é»˜è®¤çš„KindFnå®ç°ï¼Œæ ¹æ®pb.AnyTxçš„oneofç»“æ„æå–äº¤æ˜“ç±»å‹
func DefaultKindFn(tx *pb.AnyTx) (string, error) {
	if tx == nil {
		return "", ErrNilTx
	}

	// æ ¹æ® pb.AnyTx çš„ oneof content å­—æ®µåˆ¤æ–­äº¤æ˜“ç±»å‹
	switch tx.GetContent().(type) {
	case *pb.AnyTx_IssueTokenTx:
		return "issue_token", nil
	case *pb.AnyTx_FreezeTx:
		return "freeze", nil
	case *pb.AnyTx_Transaction:
		return "transfer", nil
	case *pb.AnyTx_OrderTx:
		return "order", nil
	case *pb.AnyTx_AddressTx:
		return "recharge", nil
	case *pb.AnyTx_CandidateTx:
		return "candidate", nil
	case *pb.AnyTx_MinerTx:
		return "miner", nil
	default:
		return "", fmt.Errorf("unknown tx type: %v", tx.GetTxId())
	}
}


æ–‡ä»¶è·¯å¾„: vm/interfaces.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)
// ========== æ ¸å¿ƒæ¥å£å®šä¹‰ ==========

// StateView çŠ¶æ€è§†å›¾æ¥å£
type StateView interface {
	//è¯»/å†™/åˆ æŸä¸ª key çš„çŠ¶æ€ï¼›å†™å…¥åªå†™è¿›è¿™ä¸ªè§†å›¾ï¼Œä¸ç›´æ¥è½åˆ°åº•å±‚ DBã€‚
	Get(key string) ([]byte, bool, error)
	Set(key string, val []byte)
	Del(key string)
	//åšä¸€ä¸ªå¿«ç…§ç‚¹ã€å¿…è¦æ—¶å›æ»šåˆ°è¯¥ç‚¹ï¼Œå®ç°å¹‚ç­‰é¢„æ‰§è¡Œä¸å¤±è´¥å›æ»šã€‚
	Snapshot() int
	Revert(snap int) error
	//æŠŠè¿™æ®µé¢„æ‰§è¡ŒæœŸé—´ç´¯ç§¯çš„å†™å…¥é›†åˆï¼ˆå†™é›†ï¼‰å¯¼å‡ºæ¥ï¼Œç»™åç»­â€œçœŸæ­£è½åº“â€ç”¨ã€‚
	Diff() []WriteOp
}

// TxHandler äº¤æ˜“å¤„ç†å™¨æ¥å£
type TxHandler interface {
	//æ ‡è¯†è¿™ä¸ª Handler å¤„ç†å“ªç§äº¤æ˜“ç±»å‹ï¼ˆæ¯”å¦‚ "order"ï¼‰ã€‚
	Kind() string
	//åœ¨ç»™å®š StateView ä¸Šé¢„æ‰§è¡Œï¼Œè¿”å›å†™é›† []WriteOp ä¸æ‰§è¡Œå›æ‰§ *Receiptï¼ˆæˆåŠŸ/å¤±è´¥ã€é”™è¯¯åŸå› ã€å†™å…¥æ¡æ•°ç­‰ï¼‰
	DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error)
	//å¯é€‰çš„â€œå…œåº•â€è½åº“æ–¹æ³•ï¼ˆä¹Ÿå¯ä»¥è¿”å› ErrNotImplementedï¼Œè®©ä½ ç»Ÿä¸€ç”¨ Diff() + DB æ‰¹é‡å…¥åº“ï¼‰ã€‚
	Apply(tx *pb.AnyTx) error // å¯é€‰å…œåº•ï¼›æˆ–è¿”å› ErrNotImplemented
}

// ï¼ˆé¢„æ‰§è¡Œç»“æœç¼“å­˜ï¼‰
// ç»™â€œæŒ‰åŒºå—ç»´åº¦çš„é¢„æ‰§è¡Œç»“æœï¼ˆåˆæ³•æ€§ã€å†™é›†ã€å›æ‰§ï¼‰â€åšç¼“å­˜
type SpecExecCache interface {
	//ä»¥ blockID ä¸ºé”®è·å–/å†™å…¥é¢„æ‰§è¡Œç»“æœ SpecResult
	Get(blockID string) (*SpecResult, bool)
	Put(res *SpecResult)
	//æŠŠä½äºæŸé«˜åº¦çš„ç¼“å­˜é€æ­¥æ·˜æ±°ï¼Œé˜²æ­¢å†…å­˜æ— é™å¢é•¿ã€‚
	//è¿™èƒ½é¿å…åŒä¸€å€™é€‰åŒºå—åœ¨å¤šè½®æŠ•ç¥¨ä¸­åå¤é¢„æ‰§è¡Œï¼Œç›´æ¥å¤ç”¨ç»“æœï¼Œå‡å°‘å»¶è¿Ÿä¸ CPU å¼€é”€ã€‚
	EvictBelow(height uint64)
}

// DBManager æ•°æ®åº“ç®¡ç†å™¨æ¥å£
type DBManager interface {
	EnqueueSet(key, value string)
	EnqueueDel(key string)
	ForceFlush() error
	Get(key string) ([]byte, error)
}

// ï¼ˆè¯»ç©¿å‡½æ•°ï¼‰
// å½“ StateView.Get æœ¬åœ° overlay æ²¡å‘½ä¸­æ—¶ï¼Œå®šä¹‰â€œå¦‚ä½•ä»åº•å±‚å­˜å‚¨è¯»çœŸå®å€¼â€çš„å‡½æ•°ç­¾å
// è®© é¢„æ‰§è¡Œçš„ StateView åœ¨ä¸è½åº“çš„æƒ…å†µä¸‹ä¾ç„¶èƒ½è¯»åˆ°é“¾ä¸Šæœ€æ–°æŒä¹…çŠ¶æ€ï¼Œä»è€Œå®ç° é¢„æ‰§è¡Œ + å»¶è¿Ÿè½åº“ çš„é—­ç¯ã€‚
type ReadThroughFn func(key string) ([]byte, error)

// ï¼ˆäº¤æ˜“ç±»å‹æå–å‡½æ•°ï¼‰
// ç»™ AnyTx æå–â€œäº¤æ˜“ç§ç±»â€çš„å°å·¥å…·ã€‚é»˜è®¤å®ç°ä¼šä¼˜å…ˆçœ‹ tx.Typeï¼Œå¦åˆ™çœ‹ tx.Kindï¼Œå¤±è´¥åˆ™æŠ¥é”™ï¼›è¿™è®© VM èƒ½ç”¨ Kind() å»è·¯ç”±åˆ°æ­£ç¡®çš„ TxHandler
type KindFn func(tx *pb.AnyTx) (string, error)


æ–‡ä»¶è·¯å¾„: vm/issue_token_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// IssueTokenTxHandler å‘å¸äº¤æ˜“å¤„ç†å™¨
type IssueTokenTxHandler struct{}

func (h *IssueTokenTxHandler) Kind() string {
	return "issue_token"
}

func (h *IssueTokenTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–IssueTokenTx
	issueTokenTx, ok := tx.GetContent().(*pb.AnyTx_IssueTokenTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not an issue token transaction",
		}, fmt.Errorf("not an issue token transaction")
	}

	issueTx := issueTokenTx.IssueTokenTx
	if issueTx == nil || issueTx.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid issue token transaction",
		}, fmt.Errorf("invalid issue token transaction")
	}

	// 2. éªŒè¯å‘è¡Œè€…è´¦æˆ·æ˜¯å¦å­˜åœ¨
	accountKey := fmt.Sprintf("account_%s", issueTx.Base.FromAddress)
	accountData, exists, err := sv.Get(accountKey)
	if err != nil {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "read account failed",
		}, err
	}

	if !exists {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "account not found",
		}, fmt.Errorf("account not found: %s", issueTx.Base.FromAddress)
	}

	// è§£æè´¦æˆ·æ•°æ®
	var account pb.Account
	if err := json.Unmarshal(accountData, &account); err != nil {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse account data",
		}, err
	}

	// 3. ç”ŸæˆTokenåœ°å€ï¼ˆä½¿ç”¨tx_idä½œä¸ºtokenåœ°å€ï¼‰
	tokenAddress := issueTx.Base.TxId

	// æ£€æŸ¥tokenæ˜¯å¦å·²å­˜åœ¨
	tokenKey := fmt.Sprintf("token_%s", tokenAddress)
	_, tokenExists, _ := sv.Get(tokenKey)
	if tokenExists {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "token already exists",
		}, fmt.Errorf("token already exists: %s", tokenAddress)
	}

	// 4. åˆ›å»ºTokenè®°å½•
	token := &pb.Token{
		Address:     tokenAddress,
		Symbol:      issueTx.TokenSymbol,
		Name:        issueTx.TokenName,
		Owner:       issueTx.Base.FromAddress,
		TotalSupply: issueTx.TotalSupply,
		CanMint:     issueTx.CanMint,
	}

	tokenData, err := json.Marshal(token)
	if err != nil {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal token",
		}, err
	}

	ws := make([]WriteOp, 0)

	// ä¿å­˜Tokenè®°å½•
	ws = append(ws, WriteOp{
		Key:   tokenKey,
		Value: tokenData,
		Del:   false,
	})

	// 5. å°†æ€»ä¾›åº”é‡åˆ†é…ç»™å‘è¡Œè€…
	// åˆå§‹åŒ–æˆ–æ›´æ–°å‘è¡Œè€…çš„tokenä½™é¢
	if account.Balances == nil {
		account.Balances = make(map[string]*pb.TokenBalance)
	}

	if account.Balances[tokenAddress] == nil {
		account.Balances[tokenAddress] = &pb.TokenBalance{
			Balance:                  issueTx.TotalSupply,
			CandidateLockedBalance:   "0",
			MinerLockedBalance:       "0",
			LiquidLockedBalance:      "0",
			WitnessLockedBalance:     "0",
			LeverageLockedBalance:    "0",
		}
	} else {
		// å¦‚æœå·²å­˜åœ¨ä½™é¢ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œç´¯åŠ 
		account.Balances[tokenAddress].Balance = issueTx.TotalSupply
	}

	// ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// 6. æ›´æ–°TokenRegistry
	registryKey := "token_registry"
	registryData, _, _ := sv.Get(registryKey)
	
	var registry pb.TokenRegistry
	if registryData != nil {
		if err := json.Unmarshal(registryData, &registry); err != nil {
			// å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºæ–°çš„registry
			registry.Tokens = make(map[string]*pb.Token)
		}
	} else {
		registry.Tokens = make(map[string]*pb.Token)
	}

	registry.Tokens[tokenAddress] = token

	updatedRegistryData, err := json.Marshal(&registry)
	if err != nil {
		return nil, &Receipt{
			TxID:   issueTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal token registry",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   registryKey,
		Value: updatedRegistryData,
		Del:   false,
	})

	// 7. è¿”å›æ‰§è¡Œç»“æœ
	rc := &Receipt{
		TxID:       issueTx.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}

	return ws, rc, nil
}

func (h *IssueTokenTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/miner_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// MinerTxHandler çŸ¿å·¥äº¤æ˜“å¤„ç†å™¨
type MinerTxHandler struct{}

func (h *MinerTxHandler) Kind() string {
	return "miner"
}

func (h *MinerTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–MinerTx
	minerTxWrapper, ok := tx.GetContent().(*pb.AnyTx_MinerTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not a miner transaction",
		}, fmt.Errorf("not a miner transaction")
	}

	minerTx := minerTxWrapper.MinerTx
	if minerTx == nil || minerTx.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid miner transaction",
		}, fmt.Errorf("invalid miner transaction")
	}

	// 2. æ ¹æ®æ“ä½œç±»å‹åˆ†å‘å¤„ç†
	switch minerTx.Op {
	case pb.OrderOp_ADD:
		return h.handleStartMining(minerTx, sv)
	case pb.OrderOp_REMOVE:
		return h.handleStopMining(minerTx, sv)
	default:
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "unknown miner operation",
		}, fmt.Errorf("unknown miner operation: %v", minerTx.Op)
	}
}

// handleStartMining å¤„ç†å¯åŠ¨æŒ–çŸ¿
func (h *MinerTxHandler) handleStartMining(minerTx *pb.MinerTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// éªŒè¯é”å®šé‡‘é¢
	amount, ok := new(big.Int).SetString(minerTx.Amount, 10)
	if !ok || amount.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "invalid mining amount",
		}, fmt.Errorf("invalid mining amount: %s", minerTx.Amount)
	}

	// è¯»å–çŸ¿å·¥è´¦æˆ·
	accountKey := fmt.Sprintf("account_%s", minerTx.Base.FromAddress)
	accountData, exists, err := sv.Get(accountKey)
	if err != nil || !exists {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "miner account not found",
		}, fmt.Errorf("miner account not found: %s", minerTx.Base.FromAddress)
	}

	var account pb.Account
	if err := json.Unmarshal(accountData, &account); err != nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse miner account",
		}, err
	}

	// å‡è®¾ä½¿ç”¨åŸç”Ÿä»£å¸è¿›è¡ŒæŒ–çŸ¿è´¨æŠ¼
	nativeTokenAddr := "native_token"

	// æ£€æŸ¥ä½™é¢
	if account.Balances == nil || account.Balances[nativeTokenAddr] == nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance for mining",
		}, fmt.Errorf("no balance for native token")
	}

	balance, _ := new(big.Int).SetString(account.Balances[nativeTokenAddr].Balance, 10)
	if balance == nil || balance.Cmp(amount) < 0 {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance for mining",
		}, fmt.Errorf("insufficient balance: has %s, need %s", balance.String(), amount.String())
	}

	ws := make([]WriteOp, 0)

	// ä»å¯ç”¨ä½™é¢è½¬ç§»åˆ°æŒ–çŸ¿é”å®šä½™é¢
	newBalance := new(big.Int).Sub(balance, amount)
	account.Balances[nativeTokenAddr].Balance = newBalance.String()

	currentLockedBalance, _ := new(big.Int).SetString(account.Balances[nativeTokenAddr].MinerLockedBalance, 10)
	if currentLockedBalance == nil {
		currentLockedBalance = big.NewInt(0)
	}
	newLockedBalance := new(big.Int).Add(currentLockedBalance, amount)
	account.Balances[nativeTokenAddr].MinerLockedBalance = newLockedBalance.String()

	// è®¾ç½®ä¸ºçŸ¿å·¥çŠ¶æ€
	account.IsMiner = true

	// ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// è®°å½•æŒ–çŸ¿å†å²
	historyKey := fmt.Sprintf("miner_history_%s", minerTx.Base.TxId)
	historyData, _ := json.Marshal(minerTx)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       minerTx.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

// handleStopMining å¤„ç†åœæ­¢æŒ–çŸ¿
func (h *MinerTxHandler) handleStopMining(minerTx *pb.MinerTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// è¯»å–çŸ¿å·¥è´¦æˆ·
	accountKey := fmt.Sprintf("account_%s", minerTx.Base.FromAddress)
	accountData, exists, err := sv.Get(accountKey)
	if err != nil || !exists {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "miner account not found",
		}, fmt.Errorf("miner account not found")
	}

	var account pb.Account
	if err := json.Unmarshal(accountData, &account); err != nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse miner account",
		}, err
	}

	// æ£€æŸ¥æ˜¯å¦æ˜¯çŸ¿å·¥
	if !account.IsMiner {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "account is not a miner",
		}, fmt.Errorf("account is not a miner")
	}

	nativeTokenAddr := "native_token"

	// æ£€æŸ¥æ˜¯å¦æœ‰é”å®šä½™é¢
	if account.Balances == nil || account.Balances[nativeTokenAddr] == nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "no locked balance found",
		}, fmt.Errorf("no locked balance")
	}

	lockedBalance, _ := new(big.Int).SetString(account.Balances[nativeTokenAddr].MinerLockedBalance, 10)
	if lockedBalance == nil || lockedBalance.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "no locked balance to release",
		}, fmt.Errorf("no locked balance")
	}

	ws := make([]WriteOp, 0)

	// å°†é”å®šä½™é¢è½¬å›å¯ç”¨ä½™é¢
	account.Balances[nativeTokenAddr].MinerLockedBalance = "0"

	currentBalance, _ := new(big.Int).SetString(account.Balances[nativeTokenAddr].Balance, 10)
	if currentBalance == nil {
		currentBalance = big.NewInt(0)
	}
	newBalance := new(big.Int).Add(currentBalance, lockedBalance)
	account.Balances[nativeTokenAddr].Balance = newBalance.String()

	// å–æ¶ˆçŸ¿å·¥çŠ¶æ€
	account.IsMiner = false

	// ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   minerTx.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// è®°å½•åœæ­¢æŒ–çŸ¿å†å²
	historyKey := fmt.Sprintf("miner_history_%s", minerTx.Base.TxId)
	historyData, _ := json.Marshal(minerTx)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       minerTx.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *MinerTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/order_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// OrderTxHandler è®¢å•äº¤æ˜“å¤„ç†å™¨
type OrderTxHandler struct {
	// å¯ä»¥æ³¨å…¥å…¶ä»–ä¾èµ–ï¼Œå¦‚OrderBookManagerç­‰
}

func (h *OrderTxHandler) Kind() string {
	return "order"
}

func (h *OrderTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–OrderTx
	orderTx, ok := tx.GetContent().(*pb.AnyTx_OrderTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not an order transaction",
		}, fmt.Errorf("not an order transaction")
	}

	ord := orderTx.OrderTx
	if ord == nil || ord.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid order transaction",
		}, fmt.Errorf("invalid order transaction")
	}

	// 2. æ ¹æ®æ“ä½œç±»å‹åˆ†å‘å¤„ç†
	switch ord.Op {
	case pb.OrderOp_ADD:
		return h.handleAddOrder(ord, sv)
	case pb.OrderOp_REMOVE:
		return h.handleRemoveOrder(ord, sv)
	default:
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "unknown order operation",
		}, fmt.Errorf("unknown order operation: %v", ord.Op)
	}
}

// handleAddOrder å¤„ç†æ·»åŠ /æ›´æ–°è®¢å•
func (h *OrderTxHandler) handleAddOrder(ord *pb.OrderTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// éªŒè¯è®¢å•å‚æ•°
	amount, ok := new(big.Int).SetString(ord.Amount, 10)
	if !ok || amount.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "invalid order amount",
		}, fmt.Errorf("invalid order amount: %s", ord.Amount)
	}

	price, ok := new(big.Int).SetString(ord.Price, 10)
	if !ok || price.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "invalid order price",
		}, fmt.Errorf("invalid order price: %s", ord.Price)
	}

	// è¯»å–è´¦æˆ·
	accountKey := fmt.Sprintf("account_%s", ord.Base.FromAddress)
	accountData, exists, err := sv.Get(accountKey)
	if err != nil || !exists {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "account not found",
		}, fmt.Errorf("account not found: %s", ord.Base.FromAddress)
	}

	var account pb.Account
	if err := json.Unmarshal(accountData, &account); err != nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse account",
		}, err
	}

	// æ£€æŸ¥base_tokenä½™é¢ï¼ˆä¹°å•éœ€è¦é”å®šbase_tokenï¼Œå³æ”¯ä»˜tokenï¼‰
	if account.Balances == nil || account.Balances[ord.BaseToken] == nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient base token balance",
		}, fmt.Errorf("no balance for base token: %s", ord.BaseToken)
	}

	// è®¡ç®—éœ€è¦é”å®šçš„é‡‘é¢ï¼ˆä¹°å•ï¼šamount * priceï¼Œå–å•ï¼šamountï¼‰
	// è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦æ ¹æ®ä¹°å–æ–¹å‘åˆ¤æ–­
	// å‡è®¾ï¼šä¹°BTCç”¨USDTï¼Œåˆ™base_token=USDT, quote_token=BTC
	// ä¹°å•éœ€è¦é”å®š amount * price çš„ base_token

	ws := make([]WriteOp, 0)

	// ä¿å­˜è®¢å•
	orderKey := fmt.Sprintf("order_%s", ord.Base.TxId)
	orderData, _ := json.Marshal(ord)
	ws = append(ws, WriteOp{
		Key:   orderKey,
		Value: orderData,
		Del:   false,
	})

	// æ·»åŠ è®¢å•åˆ°è´¦æˆ·çš„è®¢å•åˆ—è¡¨
	if account.Orders == nil {
		account.Orders = make([]string, 0)
	}
	account.Orders = append(account.Orders, ord.Base.TxId)

	// ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// åˆ›å»ºä»·æ ¼ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥è¯¢
	// keyæ ¼å¼: pair:base_quote|price:xxx|is_filled:false|order_id:xxx
	priceIndexKey := fmt.Sprintf("pair:%s_%s|price:%s|is_filled:%v|order_id:%s",
		ord.BaseToken, ord.QuoteToken, ord.Price, ord.IsFilled, ord.Base.TxId)

	priceIndex := &pb.OrderPriceIndex{Ok: true}
	priceIndexData, _ := json.Marshal(priceIndex)
	ws = append(ws, WriteOp{
		Key:   priceIndexKey,
		Value: priceIndexData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       ord.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

// handleRemoveOrder å¤„ç†æ’¤å•
func (h *OrderTxHandler) handleRemoveOrder(ord *pb.OrderTx, sv StateView) ([]WriteOp, *Receipt, error) {
	if ord.OpTargetId == "" {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "op_target_id is required for REMOVE operation",
		}, fmt.Errorf("op_target_id is required")
	}

	// è¯»å–è¦æ’¤é”€çš„è®¢å•
	targetOrderKey := fmt.Sprintf("order_%s", ord.OpTargetId)
	targetOrderData, exists, err := sv.Get(targetOrderKey)
	if err != nil || !exists {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "target order not found",
		}, fmt.Errorf("target order not found: %s", ord.OpTargetId)
	}

	var targetOrder pb.OrderTx
	if err := json.Unmarshal(targetOrderData, &targetOrder); err != nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse target order",
		}, err
	}

	// éªŒè¯æƒé™ï¼šåªæœ‰è®¢å•åˆ›å»ºè€…å¯ä»¥æ’¤å•
	if targetOrder.Base.FromAddress != ord.Base.FromAddress {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "only order creator can remove the order",
		}, fmt.Errorf("permission denied")
	}

	// è¯»å–è´¦æˆ·
	accountKey := fmt.Sprintf("account_%s", ord.Base.FromAddress)
	accountData, exists, err := sv.Get(accountKey)
	if err != nil || !exists {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "account not found",
		}, fmt.Errorf("account not found")
	}

	var account pb.Account
	if err := json.Unmarshal(accountData, &account); err != nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse account",
		}, err
	}

	ws := make([]WriteOp, 0)

	// åˆ é™¤è®¢å•
	ws = append(ws, WriteOp{
		Key:   targetOrderKey,
		Value: nil,
		Del:   true,
	})

	// ä»è´¦æˆ·çš„è®¢å•åˆ—è¡¨ä¸­ç§»é™¤
	if account.Orders != nil {
		newOrders := make([]string, 0)
		for _, orderId := range account.Orders {
			if orderId != ord.OpTargetId {
				newOrders = append(newOrders, orderId)
			}
		}
		account.Orders = newOrders
	}

	// ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   ord.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// åˆ é™¤ä»·æ ¼ç´¢å¼•
	priceIndexKey := fmt.Sprintf("pair:%s_%s|price:%s|is_filled:%v|order_id:%s",
		targetOrder.BaseToken, targetOrder.QuoteToken, targetOrder.Price, targetOrder.IsFilled, ord.OpTargetId)

	ws = append(ws, WriteOp{
		Key:   priceIndexKey,
		Value: nil,
		Del:   true,
	})

	return ws, &Receipt{
		TxID:       ord.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *OrderTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/recharge_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// RechargeTxHandler ä¸Šè´¦äº¤æ˜“å¤„ç†å™¨
type RechargeTxHandler struct{}

func (h *RechargeTxHandler) Kind() string {
	return "recharge"
}

func (h *RechargeTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–RechargeTx
	rechargeTx, ok := tx.GetContent().(*pb.AnyTx_AddressTx)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not a recharge transaction",
		}, fmt.Errorf("not a recharge transaction")
	}

	recharge := rechargeTx.AddressTx
	if recharge == nil || recharge.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid recharge transaction",
		}, fmt.Errorf("invalid recharge transaction")
	}

	// 2. éªŒè¯å¿…è¦å­—æ®µ
	if recharge.TokenAddress == "" {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "token_address is required",
		}, fmt.Errorf("token_address is required")
	}

	if recharge.Tweak == "" {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "tweak is required",
		}, fmt.Errorf("tweak is required")
	}

	// 3. éªŒè¯Tokenæ˜¯å¦å­˜åœ¨
	tokenKey := fmt.Sprintf("token_%s", recharge.TokenAddress)
	_, tokenExists, err := sv.Get(tokenKey)
	if err != nil {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "read token failed",
		}, err
	}

	if !tokenExists {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "token not found",
		}, fmt.Errorf("token not found: %s", recharge.TokenAddress)
	}

	// 4. æ£€æŸ¥è¯¥å……å€¼åœ°å€æ˜¯å¦å·²ç»è¢«ä½¿ç”¨è¿‡
	// ä½¿ç”¨ tweak ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œé˜²æ­¢é‡å¤ä¸Šè´¦
	rechargeRecordKey := fmt.Sprintf("recharge_record_%s_%s", recharge.Base.FromAddress, recharge.Tweak)
	_, recordExists, _ := sv.Get(rechargeRecordKey)
	if recordExists {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "recharge address already used",
		}, fmt.Errorf("recharge address already used for tweak: %s", recharge.Tweak)
	}

	// 5. è¯»å–æˆ–åˆ›å»ºç”¨æˆ·è´¦æˆ·
	accountKey := fmt.Sprintf("account_%s", recharge.Base.FromAddress)
	accountData, accountExists, _ := sv.Get(accountKey)

	var account pb.Account
	if accountExists {
		if err := json.Unmarshal(accountData, &account); err != nil {
			return nil, &Receipt{
				TxID:   recharge.Base.TxId,
				Status: "FAILED",
				Error:  "failed to parse account",
			}, err
		}
	} else {
		// åˆ›å»ºæ–°è´¦æˆ·
		account = pb.Account{
			Address:  recharge.Base.FromAddress,
			Balances: make(map[string]*pb.TokenBalance),
		}
	}

	// 6. ç”Ÿæˆå……å€¼åœ°å€ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™åº”è¯¥åœ¨æ‰“åŒ…åŒºå—æ—¶ç”±çŸ¿å·¥ç”Ÿæˆï¼‰
	// è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ from_address + tweak çš„ç»„åˆ
	generatedAddress := fmt.Sprintf("%s_%s", recharge.Base.FromAddress, recharge.Tweak)
	
	// TODO: å®é™…åº”è¯¥ä»é“¾å¤–æ•°æ®æºï¼ˆå¦‚BTCåŒºå—é“¾ï¼‰æŸ¥è¯¢è¯¥åœ°å€çš„å……å€¼é‡‘é¢
	// è¿™é‡Œå‡è®¾å……å€¼é‡‘é¢å·²ç»é€šè¿‡æŸç§æ–¹å¼éªŒè¯ï¼Œæš‚æ—¶ç¡¬ç¼–ç ä¸ºç¤ºä¾‹å€¼
	// åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œéœ€è¦ï¼š
	// 1. éªŒè¯è¯¥åœ°å€åœ¨å¯¹åº”åŒºå—é“¾ä¸Šç¡®å®æ”¶åˆ°äº†èµ„é‡‘
	// 2. éªŒè¯å……å€¼é‡‘é¢
	// 3. é˜²æ­¢åŒèŠ±æ”»å‡»
	
	// ç¤ºä¾‹ï¼šå‡è®¾å……å€¼äº† 100 ä¸ªtoken
	rechargeAmount := big.NewInt(100)

	// 7. æ›´æ–°è´¦æˆ·ä½™é¢
	if account.Balances == nil {
		account.Balances = make(map[string]*pb.TokenBalance)
	}

	if account.Balances[recharge.TokenAddress] == nil {
		account.Balances[recharge.TokenAddress] = &pb.TokenBalance{
			Balance:                  "0",
			CandidateLockedBalance:   "0",
			MinerLockedBalance:       "0",
			LiquidLockedBalance:      "0",
			WitnessLockedBalance:     "0",
			LeverageLockedBalance:    "0",
		}
	}

	currentBalance, _ := new(big.Int).SetString(account.Balances[recharge.TokenAddress].Balance, 10)
	if currentBalance == nil {
		currentBalance = big.NewInt(0)
	}
	newBalance := new(big.Int).Add(currentBalance, rechargeAmount)
	account.Balances[recharge.TokenAddress].Balance = newBalance.String()

	ws := make([]WriteOp, 0)

	// 8. ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	updatedAccountData, err := json.Marshal(&account)
	if err != nil {
		return nil, &Receipt{
			TxID:   recharge.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   accountKey,
		Value: updatedAccountData,
		Del:   false,
	})

	// 9. ä¿å­˜å……å€¼è®°å½•ï¼Œé˜²æ­¢é‡å¤ä¸Šè´¦
	rechargeRecord := map[string]string{
		"tx_id":             recharge.Base.TxId,
		"from_address":      recharge.Base.FromAddress,
		"token_address":     recharge.TokenAddress,
		"generated_address": generatedAddress,
		"tweak":             recharge.Tweak,
		"amount":            rechargeAmount.String(),
	}
	rechargeRecordData, _ := json.Marshal(rechargeRecord)
	
	ws = append(ws, WriteOp{
		Key:   rechargeRecordKey,
		Value: rechargeRecordData,
		Del:   false,
	})

	// 10. ä¿å­˜å……å€¼äº¤æ˜“å†å²
	historyKey := fmt.Sprintf("recharge_history_%s", recharge.Base.TxId)
	historyData, _ := json.Marshal(recharge)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	// 11. ä¿å­˜ç”Ÿæˆçš„åœ°å€æ˜ å°„ï¼ˆç”¨äºæŸ¥è¯¢ï¼‰
	addressMappingKey := fmt.Sprintf("recharge_address_%s", generatedAddress)
	addressMapping := map[string]string{
		"user_address":  recharge.Base.FromAddress,
		"token_address": recharge.TokenAddress,
		"tx_id":         recharge.Base.TxId,
	}
	addressMappingData, _ := json.Marshal(addressMapping)
	ws = append(ws, WriteOp{
		Key:   addressMappingKey,
		Value: addressMappingData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       recharge.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *RechargeTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/spec_cache.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// ========== LRUç¼“å­˜å®ç° ==========

type lruCache struct {
	mu    sync.RWMutex
	cap   int
	ll    *list.List
	items map[string]*list.Element
}

type lruItem struct {
	key string
	val *SpecResult
}

// NewSpecExecLRU åˆ›å»ºLRUç¼“å­˜
func NewSpecExecLRU(capacity int) SpecExecCache {
	if capacity <= 0 {
		capacity = 1024
	}
	return &lruCache{
		cap:   capacity,
		ll:    list.New(),
		items: make(map[string]*list.Element, capacity),
	}
}

// Get è·å–ç¼“å­˜é¡¹
func (c *lruCache) Get(key string) (*SpecResult, bool) {
	c.mu.Lock()
	defer c.mu.Unlock()

	if e, ok := c.items[key]; ok {
		c.ll.MoveToFront(e)
		return e.Value.(*lruItem).val, true
	}
	return nil, false
}

// Put æ·»åŠ ç¼“å­˜é¡¹
func (c *lruCache) Put(res *SpecResult) {
	if res == nil {
		return
	}

	c.mu.Lock()
	defer c.mu.Unlock()

	// å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°å¹¶ç§»åˆ°å‰é¢
	if e, ok := c.items[res.BlockID]; ok {
		e.Value.(*lruItem).val = res
		c.ll.MoveToFront(e)
		return
	}

	// æ·»åŠ æ–°é¡¹
	e := c.ll.PushFront(&lruItem{key: res.BlockID, val: res})
	c.items[res.BlockID] = e

	// å¦‚æœè¶…è¿‡å®¹é‡ï¼Œåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
	if c.ll.Len() > c.cap {
		last := c.ll.Back()
		if last != nil {
			it := last.Value.(*lruItem)
			delete(c.items, it.key)
			c.ll.Remove(last)
		}
	}
}

// EvictBelow æ¸…ç†ä½äºæŒ‡å®šé«˜åº¦çš„ç¼“å­˜é¡¹
func (c *lruCache) EvictBelow(height uint64) {
	c.mu.Lock()
	defer c.mu.Unlock()

	// åˆ›å»ºå¾…åˆ é™¤åˆ—è¡¨ï¼Œé¿å…åœ¨éå†ä¸­ä¿®æ”¹map
	toDelete := make([]string, 0)
	for k, e := range c.items {
		if e.Value.(*lruItem).val.Height < height {
			toDelete = append(toDelete, k)
		}
	}

	// æ‰§è¡Œåˆ é™¤
	for _, k := range toDelete {
		if e, ok := c.items[k]; ok {
			delete(c.items, k)
			c.ll.Remove(e)
		}
	}
}

// Size è¿”å›ç¼“å­˜å¤§å°
func (c *lruCache) Size() int {
	c.mu.RLock()
	defer c.mu.RUnlock()
	return c.ll.Len()
}

// Clear æ¸…ç©ºç¼“å­˜
func (c *lruCache) Clear() {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.items = make(map[string]*list.Element, c.cap)
	c.ll.Init()
}


æ–‡ä»¶è·¯å¾„: vm/state.go
æ–‡ä»¶å†…å®¹:
package vm

// åˆè¡·ï¼š1ã€å‡å°ç½‘ç»œä¼ è¾“ï¼šæ–¹ä¾¿ç½‘ç»œåŒæ­¥å’Œå¿«ç…§çš„æ•°æ®ä¼ è¾“ï¼Œç›´æ¥ä¼ è¾“çŠ¶æ€æ•°æ®åº“ï¼Œè€Œä¸æ˜¯å†å²block
//      2ã€ç»Ÿä¸€å…±è¯†çŠ¶æ€ï¼šæ ¹æ®çŠ¶æ€æ ¹ç»Ÿä¸€å…±è¯†ï¼Œä¿æŒå…¨ç½‘ä¸€è‡´ã€‚
//		3ã€æ–¹ä¾¿è½»èŠ‚ç‚¹å…±è¯†ï¼šä¸å¿…æŒæœ‰åºå¤§çš„å†å²æ•°æ®ä¹Ÿèƒ½å‚ä¸å…±è¯†ã€‚
//      4ã€æ–¹ä¾¿VMåšå¹¶è¡Œè®¡ç®—ï¼Œå†…å­˜ç»Ÿè®¡æœ€åæäº¤flushã€‚
// çŠ¶æ€æ•°æ®åº“å†…å®¹ï¼šmessage Accountã€ä»¥åŠå†…éƒ¨ç›¸å…³æ•°æ®ã€‚
// è·¯å¾„ï¼šå¾…å®šï¼Œéœ€è¦å•ç‹¬ä¸€ä¸ªæ•°æ®åº“è·¯å¾„ï¼Ÿè¿˜æ˜¯å°†å°±ç°åœ¨çš„æ•°æ®åº“ä¸æ–°å¢ã€‚

// é—®ï¼šæ•°æ®æ˜¯ç¦»æ•£çš„ï¼Œå¦‚ä½•ä¿è¯åŒæ­¥è¿›åº¦ï¼Ÿ
// ç­”ï¼šå…ˆåŒæ­¥æœ€è¿‘çš„çŠ¶æ€æ•°æ®åº“ï¼Œå†ä¸‹è½½ç¼ºå¤±åŒºå—å¼¥è¡¥çŠ¶æ€æ›´æ–°

// é—®ï¼šçŠ¶æ€æ•°æ®åº“éœ€è¦ä¸€ä¸ªæ ‘å½¢ç»“æ„å—ï¼Ÿ
// ç­”ï¼šä¸éœ€è¦ï¼Œç›´æ¥ç”¨pohçš„å†å²è¯æ˜ï¼Œæ‰€æœ‰txs hashä¸²è¡Œï¼Œæ¯ä¸ªåŒºå—çš„æœ€åä¸€ä¸ªtx hashä¹‹åå°±æ˜¯å½“å‰é«˜åº¦çš„state hash

// é—®ï¼šæ•°æ®æ˜¯KVå‹å¼å­˜å‚¨çš„ï¼Œå¦‚ä½•åˆ†æ•£åˆ°ä¸åŒçŸ¿å·¥æ‹‰å–å‘¢ï¼Ÿ
// ç­”ï¼šBadger ç”¨ Prefix åªéå†ä¸€ç±»é”®ï¼Œâ€œåˆ†æ•£å¹¶è¡Œâ€éå†ï¼šå¯ä»¥å†ç”¨**å‰ç¼€çš„ä¸‹ä¸€æ®µï¼ˆå“ˆå¸Œçš„å‰ 1ï½2 ä¸ªå­—ç¬¦ï¼‰**åšäºŒçº§åˆ†ç‰‡ï¼Œæ¯”å¦‚ blockdata_0*â€¦ã€blockdata_a*â€¦ï¼ˆ16 ç‰‡ï¼‰ï¼Œæˆ–è€… blockdata_ab*â€¦ï¼ˆ256 ç‰‡ï¼‰


æ–‡ä»¶è·¯å¾„: vm/stateview.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// ========== StateViewå†…éƒ¨ç±»å‹ ==========

// ovVal overlayä¸­çš„å€¼
type ovVal struct {
	val   []byte
	exist bool // falseè¡¨ç¤ºå·²åˆ é™¤
}

// change å˜æ›´è®°å½•ï¼Œç”¨äºå›æ»š
type change struct {
	key     string
	prev    ovVal
	hasPrev bool
}

// ========== StateViewå®ç° ==========

// overlayStateView StateViewçš„å†…å­˜å®ç°
type overlayStateView struct {
	mu        sync.RWMutex
	read      ReadThroughFn
	overlay   map[string]ovVal
	changelog []change
}

// NewStateView åˆ›å»ºæ–°çš„StateView
func NewStateView(read ReadThroughFn) StateView {
	return &overlayStateView{
		read:      read,
		overlay:   make(map[string]ovVal, 1024),
		changelog: make([]change, 0, 1024),
	}
}

func (s *overlayStateView) Get(key string) ([]byte, bool, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if v, ok := s.overlay[key]; ok {
		if !v.exist { // å·²è¢«æ ‡è®°åˆ é™¤
			return nil, false, nil
		}
		// è¿”å›å‰¯æœ¬ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹
		result := make([]byte, len(v.val))
		copy(result, v.val)
		return result, true, nil
	}

	// è¯»ç©¿åˆ°åº•å±‚å­˜å‚¨
	val, err := s.read(key)
	if err != nil {
		return nil, false, err
	}
	if val == nil {
		return nil, false, nil
	}
	return val, true, nil
}

func (s *overlayStateView) Set(key string, val []byte) {
	s.mu.Lock()
	defer s.mu.Unlock()

	prev, has := s.overlay[key]
	s.changelog = append(s.changelog, change{key: key, prev: prev, hasPrev: has})
	// å¤åˆ¶å€¼ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹å½±å“å†…éƒ¨çŠ¶æ€
	valCopy := make([]byte, len(val))
	copy(valCopy, val)
	s.overlay[key] = ovVal{val: valCopy, exist: true}
}

func (s *overlayStateView) Del(key string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	prev, has := s.overlay[key]
	s.changelog = append(s.changelog, change{key: key, prev: prev, hasPrev: has})
	s.overlay[key] = ovVal{val: nil, exist: false}
}

func (s *overlayStateView) Snapshot() int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return len(s.changelog)
}

func (s *overlayStateView) Revert(snap int) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	if snap < 0 || snap > len(s.changelog) {
		return ErrInvalidSnapshot
	}

	// å›æ»šåˆ°snapä¹‹å‰çš„çŠ¶æ€
	for i := len(s.changelog) - 1; i >= snap; i-- {
		c := s.changelog[i]
		if c.hasPrev {
			s.overlay[c.key] = c.prev
		} else {
			delete(s.overlay, c.key)
		}
	}
	s.changelog = s.changelog[:snap]
	return nil
}

func (s *overlayStateView) Diff() []WriteOp {
	s.mu.RLock()
	defer s.mu.RUnlock()

	diff := make([]WriteOp, 0, len(s.overlay))
	for k, v := range s.overlay {
		valCopy := make([]byte, len(v.val))
		copy(valCopy, v.val)
		diff = append(diff, WriteOp{Key: k, Value: valCopy, Del: !v.exist})
	}
	return diff
}


æ–‡ä»¶è·¯å¾„: vm/transfer_handler.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)

// TransferTxHandler è½¬è´¦äº¤æ˜“å¤„ç†å™¨
type TransferTxHandler struct{}

func (h *TransferTxHandler) Kind() string {
	return "transfer"
}

func (h *TransferTxHandler) DryRun(tx *pb.AnyTx, sv StateView) ([]WriteOp, *Receipt, error) {
	// 1. æå–Transaction
	transferTx, ok := tx.GetContent().(*pb.AnyTx_Transaction)
	if !ok {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "not a transfer transaction",
		}, fmt.Errorf("not a transfer transaction")
	}

	transfer := transferTx.Transaction
	if transfer == nil || transfer.Base == nil {
		return nil, &Receipt{
			TxID:   tx.GetTxId(),
			Status: "FAILED",
			Error:  "invalid transfer transaction",
		}, fmt.Errorf("invalid transfer transaction")
	}

	// éªŒè¯è½¬è´¦é‡‘é¢
	amount, ok := new(big.Int).SetString(transfer.Amount, 10)
	if !ok || amount.Sign() <= 0 {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "invalid transfer amount",
		}, fmt.Errorf("invalid transfer amount: %s", transfer.Amount)
	}

	// 2. æ£€æŸ¥å‘é€æ–¹è´¦æˆ·æ˜¯å¦è¢«å†»ç»“
	freezeKey := fmt.Sprintf("freeze_%s_%s", transfer.Base.FromAddress, transfer.TokenAddress)
	freezeData, isFrozen, _ := sv.Get(freezeKey)
	if isFrozen && string(freezeData) == "true" {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "sender account is frozen for this token",
		}, fmt.Errorf("sender account is frozen for token: %s", transfer.TokenAddress)
	}

	// 3. è¯»å–å‘é€æ–¹è´¦æˆ·
	fromAccountKey := fmt.Sprintf("account_%s", transfer.Base.FromAddress)
	fromAccountData, fromExists, err := sv.Get(fromAccountKey)
	if err != nil || !fromExists {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "sender account not found",
		}, fmt.Errorf("sender account not found")
	}

	var fromAccount pb.Account
	if err := json.Unmarshal(fromAccountData, &fromAccount); err != nil {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "failed to parse sender account",
		}, err
	}

	// 4. æ£€æŸ¥å‘é€æ–¹ä½™é¢
	if fromAccount.Balances == nil || fromAccount.Balances[transfer.TokenAddress] == nil {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance",
		}, fmt.Errorf("sender has no balance for token: %s", transfer.TokenAddress)
	}

	fromBalance, ok := new(big.Int).SetString(fromAccount.Balances[transfer.TokenAddress].Balance, 10)
	if !ok {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "invalid sender balance format",
		}, fmt.Errorf("invalid balance format")
	}

	if fromBalance.Cmp(amount) < 0 {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "insufficient balance",
		}, fmt.Errorf("insufficient balance: has %s, need %s", fromBalance.String(), amount.String())
	}

	// 5. è¯»å–æ¥æ”¶æ–¹è´¦æˆ·ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
	toAccountKey := fmt.Sprintf("account_%s", transfer.To)
	toAccountData, toExists, _ := sv.Get(toAccountKey)

	var toAccount pb.Account
	if toExists {
		if err := json.Unmarshal(toAccountData, &toAccount); err != nil {
			return nil, &Receipt{
				TxID:   transfer.Base.TxId,
				Status: "FAILED",
				Error:  "failed to parse receiver account",
			}, err
		}
	} else {
		// åˆ›å»ºæ–°è´¦æˆ·
		toAccount = pb.Account{
			Address:  transfer.To,
			Balances: make(map[string]*pb.TokenBalance),
		}
	}

	// 6. æ‰§è¡Œè½¬è´¦
	// å‡å°‘å‘é€æ–¹ä½™é¢
	newFromBalance := new(big.Int).Sub(fromBalance, amount)
	fromAccount.Balances[transfer.TokenAddress].Balance = newFromBalance.String()

	// å¢åŠ æ¥æ”¶æ–¹ä½™é¢
	if toAccount.Balances == nil {
		toAccount.Balances = make(map[string]*pb.TokenBalance)
	}
	if toAccount.Balances[transfer.TokenAddress] == nil {
		toAccount.Balances[transfer.TokenAddress] = &pb.TokenBalance{
			Balance:                  "0",
			CandidateLockedBalance:   "0",
			MinerLockedBalance:       "0",
			LiquidLockedBalance:      "0",
			WitnessLockedBalance:     "0",
			LeverageLockedBalance:    "0",
		}
	}

	toBalance, _ := new(big.Int).SetString(toAccount.Balances[transfer.TokenAddress].Balance, 10)
	if toBalance == nil {
		toBalance = big.NewInt(0)
	}
	newToBalance := new(big.Int).Add(toBalance, amount)
	toAccount.Balances[transfer.TokenAddress].Balance = newToBalance.String()

	// 7. ä¿å­˜æ›´æ–°åçš„è´¦æˆ·
	ws := make([]WriteOp, 0)

	updatedFromData, err := json.Marshal(&fromAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal sender account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   fromAccountKey,
		Value: updatedFromData,
		Del:   false,
	})

	updatedToData, err := json.Marshal(&toAccount)
	if err != nil {
		return nil, &Receipt{
			TxID:   transfer.Base.TxId,
			Status: "FAILED",
			Error:  "failed to marshal receiver account",
		}, err
	}

	ws = append(ws, WriteOp{
		Key:   toAccountKey,
		Value: updatedToData,
		Del:   false,
	})

	// 8. è®°å½•è½¬è´¦å†å²
	historyKey := fmt.Sprintf("transfer_history_%s", transfer.Base.TxId)
	historyData, _ := json.Marshal(transfer)
	ws = append(ws, WriteOp{
		Key:   historyKey,
		Value: historyData,
		Del:   false,
	})

	return ws, &Receipt{
		TxID:       transfer.Base.TxId,
		Status:     "SUCCEED",
		WriteCount: len(ws),
	}, nil
}

func (h *TransferTxHandler) Apply(tx *pb.AnyTx) error {
	return ErrNotImplemented
}



æ–‡ä»¶è·¯å¾„: vm/types.go
æ–‡ä»¶å†…å®¹:
package vm

import (...)
// ========== é”™è¯¯å®šä¹‰ ==========

var (
	ErrNotImplemented  = errors.New("not implemented")
	ErrNilBlock        = errors.New("nil block")
	ErrNilTx           = errors.New("nil transaction")
	ErrInvalidSnapshot = errors.New("invalid snapshot index")
)

// ========== åŸºç¡€ç±»å‹å®šä¹‰ ==========

// â€œè¦æ€ä¹ˆæ”¹çŠ¶æ€â€çš„æ¸…å•
type WriteOp struct {
	Key   string
	Value []byte
	Del   bool // trueè¡¨ç¤ºåˆ é™¤æ“ä½œ
}

// è®°å½•æ‰§è¡Œç»“æœ
type Receipt struct {
	TxID       string
	Status     string // "SUCCEED" or "FAILED"
	Error      string
	WriteCount int
}

// SpecResult æ‰§è¡Œç»“æœ
type SpecResult struct {
	BlockID  string
	ParentID string
	Height   uint64
	Valid    bool
	Reason   string     // æ— æ•ˆæ—¶çš„åŸå› 
	Receipts []*Receipt // äº¤æ˜“æ‰§è¡Œç»“æœ
	Diff     []WriteOp  // çŠ¶æ€å˜æ›´é›†åˆ
}

