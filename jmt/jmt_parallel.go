package smt

import (
	"errors"
	"sync"

	"github.com/dgraph-io/badger/v4"
)

// ============================================
// JMT å¹¶è¡Œæ›´æ–°å®ç°
// åˆ©ç”¨ 16 å‰æ ‘çš„å¤©ç„¶åˆ†åŒºç»“æ„å®ç°å¤šæ ¸å¹¶è¡Œ
// ============================================

// BucketUpdate è¡¨ç¤ºä¸€ä¸ª Bucket å†…çš„å¾…æ›´æ–°æ•°æ®
type BucketUpdate struct {
	Nibble byte     // Bucket ç¼–å· (0-15)
	Keys   [][]byte // å±äºæ­¤ Bucket çš„ Keys
	Values [][]byte // å¯¹åº”çš„ Values
	Paths  [][]byte // é¢„è®¡ç®—çš„ Key å“ˆå¸Œè·¯å¾„
}

// BucketResult è¡¨ç¤ºä¸€ä¸ª Bucket æ›´æ–°çš„ç»“æœ
type BucketResult struct {
	Nibble    byte   // Bucket ç¼–å·
	ChildHash []byte // æ›´æ–°åçš„å­æ ‘æ ¹å“ˆå¸Œ
	Err       error  // é”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
	// æ”¶é›†çš„å†™æ“ä½œï¼Œå¾…ä¸»çº¿ç¨‹ç»Ÿä¸€æäº¤
	Writes []WriteOp
	// æœ¬åœ°èŠ‚ç‚¹ç¼“å­˜ï¼šå­˜å‚¨å½“å‰ Bucket è®¡ç®—è¿‡ç¨‹ä¸­åˆ›å»ºçš„èŠ‚ç‚¹
	// key ä¸ºèŠ‚ç‚¹å“ˆå¸Œçš„å­—ç¬¦ä¸²å½¢å¼
	LocalNodes map[string][]byte
	// æœ¬åœ°è¯»å–ç¼“å­˜ï¼šå­˜å‚¨ä»å­˜å‚¨ä¸­è¯»å–çš„å·²æœ‰èŠ‚ç‚¹ï¼Œé¿å…é‡å¤è¯»å–å’Œå…¨å±€é”ç«äº‰
	ReadCache map[string][]byte
}

// WriteOp è¡¨ç¤ºä¸€ä¸ªå¾…å†™å…¥çš„æ“ä½œ
type WriteOp struct {
	Key     []byte
	Value   []byte
	Version Version
}

// ParallelUpdateConfig å¹¶è¡Œæ›´æ–°é…ç½®
type ParallelUpdateConfig struct {
	MaxWorkers          int // æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤ 16
	MinBatchForParallel int // è§¦å‘å¹¶è¡Œçš„æœ€å°æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ 100
}

// DefaultParallelConfig è¿”å›é»˜è®¤çš„å¹¶è¡Œé…ç½®
func DefaultParallelConfig() ParallelUpdateConfig {
	return ParallelUpdateConfig{
		MaxWorkers:          16,
		MinBatchForParallel: 100,
	}
}

// ParallelUpdate å¹¶è¡Œæ‰¹é‡æ›´æ–°
// å°† keys æŒ‰é¦–ä¸ª Nibble åˆ†ç»„ï¼Œæ¯ä¸ª Bucket ç”±ç‹¬ç«‹ goroutine å¤„ç†
func (jmt *JellyfishMerkleTree) ParallelUpdate(
	sess VersionedStoreSession,
	keys [][]byte,
	values [][]byte,
	newVersion Version,
	cfg ParallelUpdateConfig,
) ([]byte, error) {
	if len(keys) != len(values) {
		return nil, errors.New("keys and values must have the same length")
	}

	// å°æ‰¹æ¬¡å›é€€åˆ°ä¸²è¡Œæ›´æ–°
	if len(keys) < cfg.MinBatchForParallel {
		return jmt.UpdateWithSession(sess, keys, values, newVersion)
	}

	jmt.mu.Lock()
	defer jmt.mu.Unlock()

	// 1. æŒ‰ Nibble åˆ†ç»„
	buckets := jmt.groupByNibble(keys, values)

	// 2. è·å–å½“å‰æ ¹èŠ‚ç‚¹
	var currentRoot *InternalNode
	if !jmt.hasher.IsPlaceholder(jmt.root) {
		rootData, err := jmt.getNodeDataLocked(sess, jmt.root, newVersion)
		if err != nil {
			return nil, err
		}
		if IsInternalNodeData(rootData) {
			currentRoot, err = jmt.hasher.ParseInternalNode(rootData)
			if err != nil {
				return nil, err
			}
		}
	}

	// 3. ç»Ÿè®¡æ´»è·ƒ Bucket æ•°é‡
	activeBuckets := 0
	for i := byte(0); i < 16; i++ {
		if len(buckets[i].Keys) > 0 {
			activeBuckets++
		}
	}

	// å¦‚æœæ´»è·ƒ Bucket å¤ªå°‘ï¼Œä¸å€¼å¾—å¹¶è¡Œ
	if activeBuckets <= 2 {
		return jmt.updateWithSessionInternalLocked(sess, keys, values, newVersion)
	}

	// 4. å¹¶è¡Œå¤„ç†æ¯ä¸ª Bucketï¼ˆåªåšè®¡ç®—ï¼Œä¸å†™å­˜å‚¨ï¼‰
	var wg sync.WaitGroup
	results := make([]BucketResult, 16)

	for i := byte(0); i < 16; i++ {
		bucket := buckets[i]
		if len(bucket.Keys) == 0 {
			// æ— æ›´æ–°çš„ Bucket ä¿æŒåŸæœ‰å­èŠ‚ç‚¹
			if currentRoot != nil {
				results[i] = BucketResult{
					Nibble:    i,
					ChildHash: currentRoot.GetChild(i),
				}
			} else {
				results[i] = BucketResult{
					Nibble:    i,
					ChildHash: jmt.hasher.Placeholder(),
				}
			}
			continue
		}

		// è·å–å½“å‰å­æ ‘æ ¹
		var childHash []byte
		if currentRoot != nil {
			childHash = currentRoot.GetChild(i)
		}
		if childHash == nil {
			childHash = jmt.hasher.Placeholder()
		}

		wg.Add(1)
		go func(nibble byte, b BucketUpdate, currentChildHash []byte) {
			defer wg.Done()

			// ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šæ¯ä¸ª Worker ä»…å¼€å¯ä¸€ä¸ªè¯»äº‹åŠ¡ï¼Œè·¨è¶Šæ•´ä¸ªå­æ ‘çš„å¤„ç†è¿‡ç¨‹
			// é¿å…äº†æ•°ä¸‡æ¬¡ db.View() çš„é‡å¤å¼€å¯/å…³é—­å¼€é”€
			var result BucketResult
			badgerStore, ok := jmt.store.(*VersionedBadgerStore)
			if ok {
				err := badgerStore.db.View(func(txn *badger.Txn) error {
					reader := func(key []byte, ver Version) ([]byte, error) {
						return badgerStore.GetWithTxn(txn, key, ver)
					}
					result = jmt.computeBucketUpdate(b, currentChildHash, newVersion, reader)
					return nil
				})
				if err != nil {
					result.Err = err
				}
			} else {
				// é™çº§æ–¹æ¡ˆï¼šå¦‚æœä¸æ˜¯ BadgerStoreï¼Œåˆ™ä½¿ç”¨é€šç”¨è¯»å–å™¨ï¼ˆè™½ç„¶ä¾ç„¶ä¼šæœ‰å¼€é”€ï¼‰
				reader := func(key []byte, ver Version) ([]byte, error) {
					return jmt.store.Get(key, ver)
				}
				result = jmt.computeBucketUpdate(b, currentChildHash, newVersion, reader)
			}
			results[nibble] = result
		}(i, bucket, childHash)
	}

	wg.Wait()

	// 5. æ£€æŸ¥é”™è¯¯ & æ”¶é›†å¹¶å»é‡æ‰€æœ‰å†™æ“ä½œ
	// ç”±äº JMT æ˜¯å†…å®¹å¯»å€ï¼ŒåŒä¸€ä¸ª Batch ä¸­å¯èƒ½ä¼šäº§ç”Ÿå¤šæ¬¡ç›¸åŒçš„ä¸­é—´èŠ‚ç‚¹å†™å…¥
	// å»é‡å¯ä»¥æå¤§åœ°ç¼©å‡ BadgerDB äº‹åŠ¡å¤§å°
	uniqueWrites := make(map[string]WriteOp)
	for i := byte(0); i < 16; i++ {
		if results[i].Err != nil {
			return nil, results[i].Err
		}
		for _, w := range results[i].Writes {
			uniqueWrites[string(w.Key)] = w
		}
	}

	// 6. åˆå¹¶ç»“æœåˆ°æ–°çš„æ ¹èŠ‚ç‚¹
	newRoot, rootWrites, err := jmt.mergeResultsCollect(results, newVersion)
	if err != nil {
		return nil, err
	}
	for _, w := range rootWrites {
		uniqueWrites[string(w.Key)] = w
	}

	// 7. é¡ºåºæäº¤å»é‡åçš„å†™æ“ä½œåˆ° Session
	// fmt.Printf("Batch size %d: committing %d unique nodes\n", len(keys), len(uniqueWrites))
	for _, w := range uniqueWrites {
		if err := sess.Set(w.Key, w.Value, w.Version); err != nil {
			return nil, err
		}
	}

	// 8. ä¿å­˜æ ¹å“ˆå¸Œ
	if err := sess.Set(rootKey(newVersion), newRoot, newVersion); err != nil {
		return nil, err
	}

	// 9. æ›´æ–°æ ‘çŠ¶æ€
	jmt.rootHistory[newVersion] = newRoot
	jmt.root = newRoot
	jmt.version = newVersion

	return newRoot, nil
}

// groupByNibble æŒ‰é¦–ä¸ª Nibble åˆ†ç»„
func (jmt *JellyfishMerkleTree) groupByNibble(keys, values [][]byte) [16]BucketUpdate {
	var buckets [16]BucketUpdate
	for i := byte(0); i < 16; i++ {
		buckets[i] = BucketUpdate{Nibble: i}
	}

	for i, key := range keys {
		path := jmt.hasher.Path(key)
		nibble := getNibbleAt(path, 0)

		buckets[nibble].Keys = append(buckets[nibble].Keys, key)
		buckets[nibble].Values = append(buckets[nibble].Values, values[i])
		buckets[nibble].Paths = append(buckets[nibble].Paths, path)
	}

	return buckets
}

// computeBucketUpdate è®¡ç®—å•ä¸ª Bucket çš„æ›´æ–°ï¼ˆçº¯è®¡ç®—ï¼Œä¸å†™å­˜å‚¨ï¼‰
// æ­¤æ–¹æ³•å¯è¢«å¤šä¸ª goroutine å®‰å…¨å¹¶å‘è°ƒç”¨
func (jmt *JellyfishMerkleTree) computeBucketUpdate(
	bucket BucketUpdate,
	currentChildHash []byte,
	version Version,
	reader func([]byte, Version) ([]byte, error),
) BucketResult {
	result := BucketResult{
		Nibble:     bucket.Nibble,
		Writes:     make([]WriteOp, 0, len(bucket.Keys)*3), // é¢„åˆ†é…
		LocalNodes: make(map[string][]byte),                // æœ¬åœ°èŠ‚ç‚¹ç¼“å­˜
		ReadCache:  make(map[string][]byte),                // æœ¬åœ°è¯»å–ç¼“å­˜
	}

	// é€ä¸ªæ›´æ–°å­æ ‘ä¸­çš„ Key
	childHash := currentChildHash
	for i := 0; i < len(bucket.Keys); i++ {
		path := bucket.Paths[i]
		value := bucket.Values[i]
		valueHash := jmt.hasher.Digest(value)

		// æ”¶é›†å€¼å†™æ“ä½œ
		result.Writes = append(result.Writes, WriteOp{
			Key:     valueKey(path),
			Value:   value,
			Version: version,
		})

		// ä» depth=1 å¼€å§‹è®¡ç®—æ›´æ–°
		var err error
		childHash, err = jmt.computeSubtreeUpdate(&result, path, valueHash, childHash, 1, version, reader)
		if err != nil {
			result.Err = err
			return result
		}
	}

	result.ChildHash = childHash
	return result
}

// computeSubtreeUpdate è®¡ç®—å­æ ‘æ›´æ–°ï¼ˆçº¯è®¡ç®—ï¼Œæ”¶é›†å†™æ“ä½œï¼‰
func (jmt *JellyfishMerkleTree) computeSubtreeUpdate(
	result *BucketResult,
	path, valueHash, nodeHash []byte,
	depth int,
	version Version,
	reader func([]byte, Version) ([]byte, error),
) ([]byte, error) {
	if jmt.hasher.IsPlaceholder(nodeHash) {
		// åˆ°è¾¾ç©ºèŠ‚ç‚¹ï¼Œåˆ›å»ºå¶å­
		leafHash, leafData := jmt.hasher.DigestLeafNode(path, valueHash)
		result.Writes = append(result.Writes, WriteOp{
			Key:     leafHash,
			Value:   leafData,
			Version: version,
		})
		// å­˜å…¥æœ¬åœ°ç¼“å­˜
		result.LocalNodes[string(leafHash)] = leafData
		return leafHash, nil
	}

	// 1. å…ˆä»æœ¬åœ°å†™å…¥ç¼“å­˜æŸ¥æ‰¾ï¼ˆåŒä¸€ Bucket å†…åˆšåˆ›å»ºçš„èŠ‚ç‚¹ï¼‰
	nodeData, found := result.LocalNodes[string(nodeHash)]

	// 2. å†ä»æœ¬åœ°è¯»å–ç¼“å­˜æŸ¥æ‰¾ï¼ˆé¿å…å…¨å±€é”ç«äº‰ï¼‰
	if !found {
		nodeData, found = result.ReadCache[string(nodeHash)]
	}

	// 3. æœ€åä»å­˜å‚¨è¯»å–ï¼ˆä½¿ç”¨ Worker å¤ç”¨çš„äº‹åŠ¡è¯»å–å™¨ï¼‰
	if !found {
		var err error
		nodeData, err = reader(nodeHash, version)
		if err != nil {
			nodeData, err = reader(nodeHash, 0)
			if err != nil {
				return nil, err
			}
		}
		// å†™å…¥æœ¬åœ°è¯»å–ç¼“å­˜ï¼Œä¾›åŒä¸€ Bucket çš„åç»­ Key ä½¿ç”¨
		if nodeData != nil {
			result.ReadCache[string(nodeHash)] = nodeData
		}
	}

	nodeType := jmt.hasher.GetNodeType(nodeData)

	switch nodeType {
	case NodeTypeLeaf:
		existingLeaf, err := jmt.hasher.ParseLeafNode(nodeData)
		if err != nil {
			return nil, err
		}

		if bytesEqual(existingLeaf.KeyHash, path) {
			// æ›´æ–°ç°æœ‰å¶å­
			newLeafHash, newLeafData := jmt.hasher.DigestLeafNode(path, valueHash)
			result.Writes = append(result.Writes, WriteOp{
				Key:     newLeafHash,
				Value:   newLeafData,
				Version: version,
			})
			result.LocalNodes[string(newLeafHash)] = newLeafData
			return newLeafHash, nil
		}

		// éœ€è¦åˆ†è£‚
		return jmt.computeLeafSplit(result, existingLeaf, path, valueHash, depth, version)

	case NodeTypeInternal:
		node, err := jmt.hasher.ParseInternalNode(nodeData)
		if err != nil {
			return nil, err
		}

		nibble := getNibbleAt(path, depth)
		childHash := node.GetChild(nibble)
		if childHash == nil {
			childHash = jmt.hasher.Placeholder()
		}

		// é€’å½’æ›´æ–°å­æ ‘
		newChildHash, err := jmt.computeSubtreeUpdate(result, path, valueHash, childHash, depth+1, version, reader)
		if err != nil {
			return nil, err
		}

		// åˆ›å»ºæ–°çš„å†…éƒ¨èŠ‚ç‚¹
		newNode := &InternalNode{
			ChildBitmap: node.ChildBitmap,
			Children:    make([][]byte, len(node.Children)),
		}
		copy(newNode.Children, node.Children)
		newNode.SetChild(nibble, newChildHash)

		newNodeHash, newNodeData := jmt.hasher.DigestInternalNodeFromNode(newNode)
		result.Writes = append(result.Writes, WriteOp{
			Key:     newNodeHash,
			Value:   newNodeData,
			Version: version,
		})
		result.LocalNodes[string(newNodeHash)] = newNodeData
		return newNodeHash, nil

	default:
		return nil, errors.New("corrupted tree: unknown node type")
	}
}

// computeLeafSplit è®¡ç®—å¶å­åˆ†è£‚ï¼ˆçº¯è®¡ç®—ï¼‰
func (jmt *JellyfishMerkleTree) computeLeafSplit(
	result *BucketResult,
	existingLeaf *LeafNode,
	newPath, newValueHash []byte,
	depth int,
	version Version,
) ([]byte, error) {
	existingPath := existingLeaf.KeyHash

	// æ‰¾åˆ°åˆ†å‰ç‚¹
	commonPrefix := countCommonNibblePrefix(existingPath, newPath)

	// åˆ›å»ºä¸¤ä¸ªå¶å­èŠ‚ç‚¹
	existingLeafHash, existingLeafData := jmt.hasher.DigestLeafNode(existingPath, existingLeaf.ValueHash)
	result.Writes = append(result.Writes, WriteOp{
		Key:     existingLeafHash,
		Value:   existingLeafData,
		Version: version,
	})
	result.LocalNodes[string(existingLeafHash)] = existingLeafData

	newLeafHash, newLeafData := jmt.hasher.DigestLeafNode(newPath, newValueHash)
	result.Writes = append(result.Writes, WriteOp{
		Key:     newLeafHash,
		Value:   newLeafData,
		Version: version,
	})
	result.LocalNodes[string(newLeafHash)] = newLeafData

	// ä»åˆ†å‰ç‚¹å‘ä¸Šæ„å»ºå†…éƒ¨èŠ‚ç‚¹
	existingNibble := getNibbleAt(existingPath, commonPrefix)
	newNibble := getNibbleAt(newPath, commonPrefix)

	// åˆ›å»ºåˆ†å‰ç‚¹çš„å†…éƒ¨èŠ‚ç‚¹
	var children [16][]byte
	for i := byte(0); i < 16; i++ {
		children[i] = jmt.hasher.Placeholder()
	}
	children[existingNibble] = existingLeafHash
	children[newNibble] = newLeafHash

	node := InternalNodeFromChildren(children, jmt.hasher.Placeholder())
	nodeHash, nodeData := jmt.hasher.DigestInternalNodeFromNode(node)
	result.Writes = append(result.Writes, WriteOp{
		Key:     nodeHash,
		Value:   nodeData,
		Version: version,
	})
	result.LocalNodes[string(nodeHash)] = nodeData

	// å¦‚æœåˆ†å‰ç‚¹æ¯”å½“å‰æ·±åº¦æ›´æ·±ï¼Œéœ€è¦åˆ›å»ºä¸­é—´èŠ‚ç‚¹
	currentHash := nodeHash
	for d := commonPrefix - 1; d >= depth; d-- {
		nibble := getNibbleAt(newPath, d)

		var children [16][]byte
		for i := byte(0); i < 16; i++ {
			children[i] = jmt.hasher.Placeholder()
		}
		children[nibble] = currentHash

		node := InternalNodeFromChildren(children, jmt.hasher.Placeholder())
		nodeHash, nodeData := jmt.hasher.DigestInternalNodeFromNode(node)
		result.Writes = append(result.Writes, WriteOp{
			Key:     nodeHash,
			Value:   nodeData,
			Version: version,
		})
		result.LocalNodes[string(nodeHash)] = nodeData
		currentHash = nodeHash
	}

	return currentHash, nil
}

// mergeResultsCollect åˆå¹¶æ‰€æœ‰ Bucket ç»“æœåˆ°æ–°çš„æ ¹èŠ‚ç‚¹ï¼ˆæ”¶é›†å†™æ“ä½œï¼‰
func (jmt *JellyfishMerkleTree) mergeResultsCollect(
	results []BucketResult,
	version Version,
) ([]byte, []WriteOp, error) {
	// æ„å»ºæ–°çš„æ ¹å†…éƒ¨èŠ‚ç‚¹
	var children [16][]byte
	allPlaceholder := true

	for i := byte(0); i < 16; i++ {
		children[i] = results[i].ChildHash
		if children[i] == nil {
			children[i] = jmt.hasher.Placeholder()
		}
		if !jmt.hasher.IsPlaceholder(children[i]) {
			allPlaceholder = false
		}
	}

	if allPlaceholder {
		return jmt.hasher.Placeholder(), nil, nil
	}

	node := InternalNodeFromChildren(children, jmt.hasher.Placeholder())
	nodeHash, nodeData := jmt.hasher.DigestInternalNodeFromNode(node)

	writes := []WriteOp{{
		Key:     nodeHash,
		Value:   nodeData,
		Version: version,
	}}

	return nodeHash, writes, nil
}

// getNodeDataLocked è·å–èŠ‚ç‚¹æ•°æ®ï¼ˆå·²æŒæœ‰é”æ—¶è°ƒç”¨ï¼‰
func (jmt *JellyfishMerkleTree) getNodeDataLocked(sess VersionedStoreSession, hash []byte, version Version) ([]byte, error) {
	// å°è¯•ç¼“å­˜
	if data := jmt.getCache(hash); data != nil {
		return data, nil
	}

	// ä»å­˜å‚¨è·å–
	var data []byte
	var err error
	if sess != nil {
		data, err = sess.Get(hash, version)
		if err != nil {
			data, err = sess.Get(hash, 0)
		}
	} else {
		data, err = jmt.store.Get(hash, version)
		if err != nil {
			data, err = jmt.store.Get(hash, 0)
		}
	}

	if err != nil {
		return nil, err
	}

	jmt.setCache(hash, data)
	return data, nil
}

// updateWithSessionInternalLocked å†…éƒ¨ä¸²è¡Œæ›´æ–°æ–¹æ³•ï¼ˆå·²æŒæœ‰é”æ—¶è°ƒç”¨ï¼‰
func (jmt *JellyfishMerkleTree) updateWithSessionInternalLocked(
	sess VersionedStoreSession,
	keys [][]byte,
	values [][]byte,
	newVersion Version,
) ([]byte, error) {
	currentRoot := jmt.root

	for i := 0; i < len(keys); i++ {
		var err error
		currentRoot, err = jmt.updateSingle(keys[i], values[i], currentRoot, newVersion, sess)
		if err != nil {
			return nil, err
		}
	}

	jmt.rootHistory[newVersion] = currentRoot
	if err := sess.Set(rootKey(newVersion), currentRoot, newVersion); err != nil {
		return nil, err
	}

	jmt.root = currentRoot
	jmt.version = newVersion

	return currentRoot, nil
}

// bytesEqual å®‰å…¨çš„å­—èŠ‚æ¯”è¾ƒ
func bytesEqual(a, b []byte) bool {
	if len(a) != len(b) {
		return false
	}
	for i := range a {
		if a[i] != b[i] {
			return false
		}
	}
	return true
}
